{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "mf_module_path = os.path.abspath(os.path.join('../python'))\n",
    "if mf_module_path not in sys.path:\n",
    "    sys.path.append(mf_module_path)\n",
    "import mf\n",
    "import mf_random\n",
    "import hpoutil\n",
    "import networkx\n",
    "import obonet\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connect to MySQL database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(host='localhost',\n",
    "                               user='mimicuser',\n",
    "                               passwd='mimic',\n",
    "                               database='mimiciiiv13',\n",
    "                              auth_plugin='mysql_native_password')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First approach to query mysql from python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that MySQL connection works properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM LABEVENTS LIMIT 5;\", mydb)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a cursor so that it can be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = mydb.cursor(buffered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explored several method to compute the synergy score for different diseases. Method 1-3 all worked but the time and space requirements are too high. See the archived file. Here, we use method 4 to compute phenotype pairwise synergies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synergy between Lab-derived Abnormalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This method relies on the power of MySQL for doing queies and joins, return a batch of phenotype profiles a time, and then use the power of Numpy to do numeric computation.\n",
    "\n",
    "Specificially, the method runs the following algorithm:\n",
    "\n",
    "    1. For one diagnosis code, specify the phenotypes to analyze--a list of HPO terms.\n",
    "    2. For a batch of patient*encounters, return a list of diagnosis codes (1 or 0)\n",
    "    3. For the same batch of patient*encounters, return a list of phenotypes.\n",
    "    4. Create a numpy array with dimension (N x P)\n",
    "    5. Perform numeric computation with Numpy:\n",
    "        outer product for ++ of PxP.T\n",
    "        outer product for +- of Px(1-P).T\n",
    "        outer product for -+ of (1-P)xP\n",
    "        outer product for -- of (1-P)x(1-P).T\n",
    "        combine the above with - and + of diagnosis value\n",
    "        stack them together as a (N x P x P x 8) matrix.\n",
    "        Step 1 - 5 are performed at each site. The resulting matrix is returned to JAX for final analyze.\n",
    "    6. Compute pairwise synergy:\n",
    "        use the multi-dimension array to calculate p(D = 1), p(D = 0), p(P1 * P2)\n",
    "        compute mutual information of each phenotype in regarding to one diagnosis I(P:D)\n",
    "        compute mutual information of two phenotypes in regarding to one diagnosis I(P:D)\n",
    "        compute pairwise synergy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: rewrite to be backward compatible\n",
    "def diagnosis_set():\n",
    "    \"\"\"Aggregate ICD9 codes with the first three digit and count how many times they appear. \n",
    "    Note this function uses encounters as the unit, meaning a code will counted twice if same patient was \n",
    "    diagnosed again at a later encounter.\"\"\"\n",
    "    diagnosis_count = pd.read_sql_query(\"SELECT SUBJECT_ID, HADM_ID, \\\n",
    "        CASE \\\n",
    "        WHEN(ICD9_CODE LIKE 'V%') THEN SUBSTRING(ICD9_CODE, 1, 3) \\\n",
    "        WHEN(ICD9_CODE LIKE 'E%') THEN SUBSTRING(ICD9_CODE, 1, 4) \\\n",
    "        ELSE SUBSTRING(ICD9_CODE, 1, 3) END AS ICD9 \\\n",
    "        FROM DIAGNOSES_ICD\", mydb)\n",
    "    diagnosisSet = diagnosis_count.drop_duplicates().groupby('ICD9').size().sort_values(ascending=False)\n",
    "    return diagnosisSet\n",
    "\n",
    "#TODO: rewrite to be backward compatible\n",
    "def createAbnormalPhenotypeTable(threshold, include_inferred=True, force_update=True):\n",
    "    \"\"\"\n",
    "    This is the abnormal phenotypes. \n",
    "    @include_inferred whether to include inferred HPO. Default true.\n",
    "    @force_update whether current table, if present, should be forced to update\n",
    "    \"\"\"\n",
    "    if force_update:\n",
    "        cursor.execute('''DROP TEMPORARY TABLE IF EXISTS p''')\n",
    "    if include_inferred:\n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS p\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, LabHpo.MAP_TO\n",
    "                        FROM \n",
    "                            LABEVENTS \n",
    "                        JOIN LabHpo on LABEVENTS.ROW_ID = LabHpo.ROW_ID\n",
    "                        WHERE LabHpo.NEGATED = 'F'\n",
    "                        \n",
    "                        UNION ALL\n",
    "                        \n",
    "                        SELECT \n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, INFERRED_LABHPO.INFERRED_TO AS MAP_TO \n",
    "                        FROM \n",
    "                            INFERRED_LABHPO \n",
    "                        JOIN \n",
    "                            LABEVENTS ON INFERRED_LABHPO.LABEVENT_ROW_ID = LABEVENTS.ROW_ID\n",
    "                        )\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    HAVING COUNT(*) > {}\n",
    "                    -- parameter to control how to define an abnormal phenotype is present.\n",
    "                '''.format(threshold))\n",
    "    else:       \n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS p\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, LabHpo.MAP_TO\n",
    "                        FROM \n",
    "                            LABEVENTS \n",
    "                        JOIN LabHpo on LABEVENTS.ROW_ID = LabHpo.ROW_ID\n",
    "                        WHERE LabHpo.NEGATED = 'F')\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    HAVING COUNT(*) > {}\n",
    "                    -- parameter to control how to define an abnormal phenotype is present.\n",
    "                '''.format(threshold))\n",
    "    cursor.execute('CREATE INDEX p_idx01 ON p (SUBJECT_ID, HADM_ID)')\n",
    "    cursor.execute('CREATE INDEX p_idx02 ON p (MAP_TO);')\n",
    "\n",
    "\n",
    "#TODO: rewrite to be backward compatible\n",
    "def encountersWithDiagnosis(diagnosis):\n",
    "    cursor.execute('''DROP TEMPORARY TABLE IF EXISTS d''')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE IF NOT EXISTS d\n",
    "        SELECT \n",
    "            DISTINCT SUBJECT_ID, HADM_ID, 1 AS DIAGNOSIS\n",
    "        FROM \n",
    "            DIAGNOSES_ICD \n",
    "        WHERE ICD9_CODE LIKE '{}%'\n",
    "        -- This is encounters with positive diagnosis\n",
    "    '''.format(diagnosis))\n",
    "    cursor.execute('CREATE INDEX d_idx01 ON d(SUBJECT_ID, HADM_ID)')\n",
    "\n",
    "    \n",
    "def createPhenotypeSet(diagnosis, threshold=1000):\n",
    "    \"\"\"\n",
    "    Create the phenotypes that we should analyze. Exemely less frequently observed phenotypes are excluded.\n",
    "    \"\"\"\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS ps')\n",
    "    cursor.execute('''\n",
    "            CREATE TEMPORARY TABLE ps\n",
    "            WITH pd AS(\n",
    "                SELECT p.*\n",
    "                FROM \n",
    "                    p JOIN (SELECT \n",
    "                                DISTINCT SUBJECT_ID, HADM_ID, 1 AS DIAGNOSIS\n",
    "                            FROM \n",
    "                                DIAGNOSES_ICD \n",
    "                            WHERE ICD9_CODE LIKE '{}%') AS d\n",
    "                    ON p.SUBJECT_ID = d.SUBJECT_ID AND p.HADM_ID = d.HADM_ID)\n",
    "            SELECT \n",
    "                MAP_TO, COUNT(*) AS N, 1 AS PHENOTYPE\n",
    "            FROM pd\n",
    "            GROUP BY MAP_TO\n",
    "            HAVING N > {}\n",
    "            ORDER BY N DESC'''.format(diagnosis, threshold))\n",
    "    phenoSet = pd.read_sql_query('SELECT * FROM ps', mydb)\n",
    "    return phenoSet\n",
    "\n",
    "\n",
    "def batch_query(start_index, end_index):\n",
    "    batch_size_actual = pd.read_sql_query('''\n",
    "                SELECT \n",
    "                    COUNT(DISTINCT SUBJECT_ID, HADM_ID) \n",
    "                FROM admissions \n",
    "                WHERE SUBJECT_ID BETWEEN {} AND {}\n",
    "                '''.format(start_index, end_index), mydb).iloc[0,0]\n",
    "    # create diagnosis table\n",
    "    diagnosisList = pd.read_sql_query('''\n",
    "                WITH a AS (\n",
    "                    SELECT DISTINCT SUBJECT_ID, HADM_ID \n",
    "                    FROM admissions \n",
    "                    WHERE SUBJECT_ID BETWEEN {} AND {})\n",
    "                SELECT \n",
    "                    a.SUBJECT_ID, a.HADM_ID, IF(d.DIAGNOSIS IS NULL, 0, 1) AS DIAGNOSIS\n",
    "                FROM \n",
    "                    a\n",
    "                LEFT JOIN\n",
    "                    d ON a.SUBJECT_ID = d.SUBJECT_ID AND a.HADM_ID = d.HADM_ID         \n",
    "                '''.format(start_index, end_index), mydb)\n",
    "    # create phenotype profile table\n",
    "    phenotyle_profile = pd.read_sql_query('''\n",
    "        WITH \n",
    "            a AS (\n",
    "                    SELECT \n",
    "                        DISTINCT SUBJECT_ID, HADM_ID \n",
    "                    FROM \n",
    "                        admissions \n",
    "                    WHERE SUBJECT_ID BETWEEN {} AND {}), \n",
    "            c as (\n",
    "                SELECT a.*, ps.MAP_TO\n",
    "                FROM a\n",
    "                JOIN ps),\n",
    "                -- cross product of all patient*encounter and phenotypes list\n",
    "            pp as (\n",
    "                SELECT p.*, 1 AS PHENOTYPE \n",
    "                FROM p RIGHT JOIN a \n",
    "                ON p.SUBJECT_ID = a.SUBJECT_ID AND p.HADM_ID = a.HADM_ID)\n",
    "\n",
    "        SELECT c.SUBJECT_ID, c.HADM_ID, c.MAP_TO, IF(pp.PHENOTYPE IS NULL, 0, 1) AS PHENOTYPE \n",
    "        FROM pp \n",
    "        RIGHT JOIN c ON pp.SUBJECT_ID = c.SUBJECT_ID and pp.HADM_ID = c.HADM_ID AND pp.MAP_TO = c.MAP_TO\n",
    "        '''.format(start_index, end_index), mydb)\n",
    "    return batch_size_actual, diagnosisList, phenotyle_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_in_batch(logger):\n",
    "    logger.info('starting iterate_in_batch()')\n",
    "    batch_size = 100\n",
    "    # find the set of diagnosis that are worthy to analyze\n",
    "    diagnosisSet = diagnosis_set()\n",
    "    logger.info('diagnosis set completed')\n",
    "\n",
    "    # create a temp table for abnormal phenotypes of each patient*encounter that met the threshold\n",
    "    #createAbnormalPhenotypeTable(threshold=1, force_update=True)\n",
    "    logger.info('createAbnormalPhenotypeTable() completed')\n",
    "    \n",
    "    synergies = {}\n",
    "    \n",
    "    for diagnosis in diagnosisSet.keys():\n",
    "        if (diagnosisSet[diagnosis] > 5000):\n",
    "            # create a temp table for diagnosis of all patient*encouter to analyze\n",
    "            encountersWithDiagnosis(diagnosis)\n",
    "            logger.info('encountersWithDiagnosis() completed')\n",
    "\n",
    "            ## create a list of phenotypes that we want to analyze for the specified disease and preset threshold\n",
    "            phenoSet = createPhenotypeSet(diagnosis, threshold=100)\n",
    "            logger.info('phenoSet completed')\n",
    "            P_SIZE = len(phenoSet)\n",
    "\n",
    "            ## find the start and end ROW_ID for patient*encounter\n",
    "            ADM_ID_START, ADM_ID_END = pd.read_sql_query('SELECT MIN(ROW_ID) AS min, MAX(ROW_ID) AS max FROM admissions', mydb).iloc[0]\n",
    "            batch_N = ADM_ID_END - ADM_ID_START + 1\n",
    "            TOTAL_BATCH = math.ceil(batch_N / batch_size) # total number of batches\n",
    "            synergies[diagnosis] = mf.SynergyWithinSet(diagnosis, phenoSet.MAP_TO)\n",
    "            logger.info('starting batch queries for {}'.format(diagnosis))\n",
    "            for i in np.arange(TOTAL_BATCH):\n",
    "                start_index = i * batch_size + ADM_ID_START\n",
    "                if i < TOTAL_BATCH - 1:\n",
    "                    end_index = start_index + batch_size - 1\n",
    "                else:\n",
    "                    end_index = batch_N\n",
    "                \n",
    "                batch_size_actual, diagnosisList, phenotyle_profile = batch_query(start_index, end_index)\n",
    "                \n",
    "                if batch_size_actual > 0 :\n",
    "                    diagnosisVector = diagnosisList.DIAGNOSIS\n",
    "                    phenotypeProfileMatrix = phenotyle_profile.PHENOTYPE.values.reshape([batch_size_actual, P_SIZE])\n",
    "                    if i % 100 == 0:\n",
    "                        logger.info('new batch: start_index={}, end_index={}, batch_size= {}, phenotype_size = {}'.format(start_index, end_index, batch_size_actual, len(phenoSet)))\n",
    "                    synergies[diagnosis].add_batch(phenotypeProfileMatrix, diagnosisVector)\n",
    "    \n",
    "    return synergies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes about 10 minutes to set up the phenotype table (p). Afterward, each disease takes about 10 minutes to complete the summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s',level=logging.DEBUG, stream=sys.stdout)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "synergies = iterate_in_batch(logger)\n",
    "   \n",
    "end = datetime.datetime.now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('running time: {}s'.format((end - start).total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('synergies.obj', 'wb') as synergies_file:\n",
    "    pickle.dump(synergies, synergies_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "close database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "mydb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Synergy between lab-derived and radiology report-derived Abnormalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm is about the same with the Method 3 in mutual_info_archive. Briefly, \n",
    "\n",
    "    * Select encounterOfInterest, temp table: JAX_encounterOfInterest(SUBJECT_ID, HADM_ID)\n",
    "    * Init diagnosisProfile: temp table: JAX_diagnosisProfile(SUBJECT_ID, HADM_ID, ICD, N)\n",
    "    * Init textHpoProfile: temp table: JAX_textHpoProfile(SUBJECT_ID, HADM_ID, MAP_TO, N)\n",
    "    * Init labHpoProfile: temp table: JAX_labHpoProfile(SUBJECT_ID, HADM_ID, MAP_TO, N)\n",
    "    \n",
    "    * Rank ICD frequency, temp table: JAX_diagFrequencyRank(ICD, N)\n",
    "      select diagOfInterest\n",
    "    * Rank textHPO frequency, temp table: JAX_textHpoFrequencyRank(MAP_TO, N)\n",
    "      select textHpoOfInterest\n",
    "    * Rank labHPO frequency, temp table: JAX_labHpoFrequencyRank(MAP_TO, N)\n",
    "      select labHpoOfInterest\n",
    "    \n",
    "    * Iteratation\n",
    "      for diagnosis in diagOfInterest\n",
    "          for textHpo in textHpoOfInterest\n",
    "              for labHpo in labHpoOfInterest\n",
    "                 Assign diagnosis value: assignDiagnosis(), table: (SUBJECT_ID, HADM_ID, DIAGNOSIS)\n",
    "                 Assign text2hpo phenotype value: table: SUBJECT_ID, HADM_ID, PHEN_TEXT\n",
    "                 Assign lab2hpo phenotype value: table: SUBJECT_ID, HADM_ID, PHEN_LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define encounters of interest\n",
    "def encounterOfInterest(debug=False):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_encounterOfInterest')\n",
    "    if debug:\n",
    "        limit = 'LIMIT 100'\n",
    "    else:\n",
    "        limit = ''\n",
    "    # This is admissions that we want to analyze, 'LIMIT 100' in debug mode\n",
    "    cursor.execute('''\n",
    "                CREATE TEMPORARY TABLE IF NOT EXISTS JAX_encounterOfInterest \n",
    "                SELECT \n",
    "                    DISTINCT SUBJECT_ID, HADM_ID \n",
    "                FROM admissions\n",
    "                {}\n",
    "                '''.format(limit))\n",
    "    \n",
    "def indexEncounterOfInterest():\n",
    "    cursor.execute('CREATE INDEX JAX_encounterOfInterest_idx01 ON JAX_encounterOfInterest (SUBJECT_ID, HADM_ID)')\n",
    "    \n",
    "def diagnosisProfile():\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_diagnosisProfile')\n",
    "    cursor.execute('''\n",
    "                CREATE TEMPORARY TABLE IF NOT EXISTS JAX_diagnosisProfile\n",
    "                SELECT \n",
    "                    DIAGNOSES_ICD.SUBJECT_ID, DIAGNOSES_ICD.HADM_ID, DIAGNOSES_ICD.ICD9_CODE\n",
    "                FROM\n",
    "                    DIAGNOSES_ICD\n",
    "                RIGHT JOIN\n",
    "                    JAX_encounterOfInterest\n",
    "                ON \n",
    "                    DIAGNOSES_ICD.SUBJECT_ID = JAX_encounterOfInterest.SUBJECT_ID \n",
    "                    AND \n",
    "                    DIAGNOSES_ICD.HADM_ID = JAX_encounterOfInterest.HADM_ID\n",
    "                ''')\n",
    "    \n",
    "def textHpoProfile(include_inferred=True, threshold=1):\n",
    "    if include_inferred:\n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS JAX_textHpoProfile\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            NOTEEVENTS.SUBJECT_ID, NOTEEVENTS.HADM_ID, NoteHpoClinPhen.MAP_TO\n",
    "                        FROM \n",
    "                            NOTEEVENTS \n",
    "                        JOIN NoteHpoClinPhen on NOTEEVENTS.ROW_ID = NoteHpoClinPhen.NOTES_ROW_ID\n",
    "                        \n",
    "                        UNION ALL\n",
    "                        \n",
    "                        SELECT\n",
    "                            NOTEEVENTS.SUBJECT_ID, NOTEEVENTS.HADM_ID, Inferred_NoteHpo.INFERRED_TO AS MAP_TO\n",
    "                        FROM \n",
    "                            NOTEEVENTS \n",
    "                        JOIN Inferred_NoteHpo on NOTEEVENTS.ROW_ID = Inferred_NoteHpo.NOTEEVENT_ROW_ID\n",
    "                        )\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO, 1 AS dummy\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    HAVING COUNT(*) > {}\n",
    "                    -- parameter to control how to define an abnormal phenotype is present.\n",
    "                '''.format(threshold))\n",
    "        \n",
    "    else:\n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS JAX_p_text\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            NOTEEVENTS.SUBJECT_ID, NOTEEVENTS.HADM_ID, NoteHpoClinPhen.MAP_TO\n",
    "                        FROM \n",
    "                            NOTEEVENTS \n",
    "                        JOIN NoteHpoClinPhen on NOTEEVENTS.ROW_ID = NoteHpoClinPhen.NOTES_ROW_ID)\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO, 1 AS dummy\n",
    "                    HAVING COUNT(*) > {}\n",
    "                    -- parameter to control how to define an abnormal phenotype is present.\n",
    "                '''.format(threshold))\n",
    "        \n",
    "def indexTextHpoProfile():\n",
    "    cursor.execute('CREATE INDEX JAX_textHpoProfile_idx01 ON JAX_textHpoProfile (SUBJECT_ID, HADM_ID)')\n",
    "    cursor.execute('CREATE INDEX JAX_textHpoProfile_idx02 ON JAX_textHpoProfile (MAP_TO);')\n",
    "    cursor.execute('CREATE INDEX JAX_textHpoProfile_idx03 ON JAX_textHpoProfile (SUBJECT_ID, HADM_ID, MAP_TO)')\n",
    "    \n",
    "def labHpoProfile(threshold, include_inferred=True, force_update=True):\n",
    "    # TODO: refactor the method \n",
    "    #createAbnormalPhenotypeTable(threshold, include_inferred=True, force_update=True)\n",
    "    \n",
    "    if force_update:\n",
    "        cursor.execute('''DROP TEMPORARY TABLE IF EXISTS JAX_labHpoProfile''')\n",
    "    if include_inferred:\n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS JAX_labHpoProfile\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, LabHpo.MAP_TO\n",
    "                        FROM \n",
    "                            LABEVENTS \n",
    "                        JOIN LabHpo on LABEVENTS.ROW_ID = LabHpo.ROW_ID\n",
    "                        WHERE LabHpo.NEGATED = 'F'\n",
    "                        \n",
    "                        UNION ALL\n",
    "                        \n",
    "                        SELECT \n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, INFERRED_LABHPO.INFERRED_TO AS MAP_TO \n",
    "                        FROM \n",
    "                            INFERRED_LABHPO \n",
    "                        JOIN \n",
    "                            LABEVENTS ON INFERRED_LABHPO.LABEVENT_ROW_ID = LABEVENTS.ROW_ID\n",
    "                        )\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO, 1 AS dummy\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    HAVING COUNT(*) > {}\n",
    "                    -- parameter to control how to define an abnormal phenotype is present.\n",
    "                '''.format(threshold))\n",
    "    else:       \n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS JAX_labHpoProfile\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, LabHpo.MAP_TO\n",
    "                        FROM \n",
    "                            LABEVENTS \n",
    "                        JOIN LabHpo on LABEVENTS.ROW_ID = LabHpo.ROW_ID\n",
    "                        WHERE LabHpo.NEGATED = 'F')\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO, 1 AS dummy\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    HAVING COUNT(*) > {}\n",
    "                    -- parameter to control how to define an abnormal phenotype is present.\n",
    "                '''.format(threshold))\n",
    "\n",
    "def indexLabHpoProfile():\n",
    "    cursor.execute('CREATE INDEX JAX_labHpoProfile_idx01 ON JAX_labHpoProfile (SUBJECT_ID, HADM_ID)')\n",
    "    cursor.execute('CREATE INDEX JAX_labHpoProfile_idx02 ON JAX_labHpoProfile (MAP_TO);')\n",
    "    cursor.execute('CREATE INDEX JAX_labHpoProfile_idx03 ON JAX_labHpoProfile (SUBJECT_ID, HADM_ID, MAP_TO)')\n",
    "    \n",
    "def rankICD():\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_diagFrequencyRank')\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TEMPORARY TABLE IF NOT EXISTS JAX_diagFrequencyRank\n",
    "        WITH JAX_temp_diag AS (\n",
    "            SELECT DISTINCT SUBJECT_ID, HADM_ID, \n",
    "                CASE \n",
    "                    WHEN(ICD9_CODE LIKE 'V%') THEN SUBSTRING(ICD9_CODE, 1, 3) \n",
    "                    WHEN(ICD9_CODE LIKE 'E%') THEN SUBSTRING(ICD9_CODE, 1, 4) \n",
    "                ELSE \n",
    "                    SUBSTRING(ICD9_CODE, 1, 3) END AS ICD9_CODE \n",
    "            FROM JAX_diagnosisProfile)\n",
    "        SELECT \n",
    "            ICD9_CODE, COUNT(*) AS N\n",
    "        FROM\n",
    "            JAX_temp_diag\n",
    "        GROUP BY \n",
    "            ICD9_CODE\n",
    "        ORDER BY N\n",
    "        DESC\n",
    "        \"\"\")\n",
    "\n",
    "def rankHpoFromText(diagnosis):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_textHpoFrequencyRank')\n",
    "    cursor.execute('''\n",
    "            CREATE TEMPORARY TABLE JAX_textHpoFrequencyRank            \n",
    "            WITH pd AS(\n",
    "                SELECT \n",
    "                    JAX_textHpoProfile.*\n",
    "                FROM \n",
    "                    JAX_textHpoProfile \n",
    "                JOIN (\n",
    "                    SELECT \n",
    "                        DISTINCT SUBJECT_ID, HADM_ID\n",
    "                    FROM \n",
    "                        JAX_diagnosisProfile \n",
    "                    WHERE \n",
    "                        ICD9_CODE LIKE '{}%') AS d\n",
    "                ON \n",
    "                    JAX_textHpoProfile.SUBJECT_ID = d.SUBJECT_ID AND JAX_textHpoProfile.HADM_ID = d.HADM_ID)\n",
    "            SELECT \n",
    "                MAP_TO, COUNT(*) AS N, 1 AS PHENOTYPE\n",
    "            FROM pd\n",
    "            GROUP BY MAP_TO\n",
    "            ORDER BY N DESC'''.format(diagnosis))\n",
    "    \n",
    "def rankHpoFromLab(diagnosis):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_labHpoFrequencyRank')\n",
    "    cursor.execute('''\n",
    "            CREATE TEMPORARY TABLE JAX_labHpoFrequencyRank            \n",
    "            WITH pd AS(\n",
    "                SELECT \n",
    "                    JAX_labHpoProfile.*\n",
    "                FROM \n",
    "                    JAX_labHpoProfile \n",
    "                JOIN (\n",
    "                    SELECT \n",
    "                        DISTINCT SUBJECT_ID, HADM_ID\n",
    "                    FROM \n",
    "                        JAX_diagnosisProfile \n",
    "                    WHERE \n",
    "                        ICD9_CODE LIKE '{}%') AS d\n",
    "                ON \n",
    "                    JAX_labHpoProfile.SUBJECT_ID = d.SUBJECT_ID AND JAX_labHpoProfile.HADM_ID = d.HADM_ID)\n",
    "            SELECT \n",
    "                MAP_TO, COUNT(*) AS N, 1 AS PHENOTYPE\n",
    "            FROM pd\n",
    "            GROUP BY MAP_TO\n",
    "            ORDER BY N DESC'''.format(diagnosis))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign 0 or 1 to each encouter whether a diagnosis is observed\n",
    "def createDiagnosisTable(diagnosis):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag')\n",
    "    cursor.execute('''\n",
    "                CREATE TEMPORARY TABLE IF NOT EXISTS JAX_mf_diag \n",
    "                WITH \n",
    "                    d AS (\n",
    "                        SELECT \n",
    "                            DISTINCT SUBJECT_ID, HADM_ID, '1' AS DIAGNOSIS\n",
    "                        FROM \n",
    "                            JAX_diagnosisProfile \n",
    "                        WHERE ICD9_CODE LIKE '{}%')\n",
    "                    -- This is encounters with positive diagnosis\n",
    "\n",
    "                SELECT \n",
    "                    DISTINCT a.SUBJECT_ID, a.HADM_ID, IF(d.DIAGNOSIS IS NULL, '0', '1') AS DIAGNOSIS\n",
    "                FROM \n",
    "                    JAX_encounterOfInterest AS a\n",
    "                LEFT JOIN\n",
    "                    d ON a.SUBJECT_ID = d.SUBJECT_ID AND a.HADM_ID = d.HADM_ID       \n",
    "                /* -- This is the first join for diagnosis (0, or 1) */    \n",
    "                '''.format(diagnosis))\n",
    "    cursor.execute('CREATE INDEX JAX_mf_diag_idx01 ON JAX_mf_diag (SUBJECT_ID, HADM_ID)')\n",
    "\n",
    "# assign 0 or 1 to each encounter whether a phenotype is observed from radiology reports\n",
    "def diagnosisTextHpo(phenotype):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_textHpo')\n",
    "    \"\"\"\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_textHpo\n",
    "        SELECT \n",
    "            L.*, IF(R.MAP_TO IS NULL, '0', '1') AS PHEN_TXT\n",
    "        FROM JAX_mf_diag AS L \n",
    "        LEFT JOIN \n",
    "            (SELECT * \n",
    "            FROM JAX_textHpoProfile \n",
    "            WHERE JAX_textHpoProfile.MAP_TO = '{}') AS R \n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID \n",
    "    '''.format(phenotype))\n",
    "    \"\"\"\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_textHpo\n",
    "        WITH L AS (SELECT JAX_mf_diag.*, '{}' AS PHEN_TXT FROM JAX_mf_diag)\n",
    "        SELECT \n",
    "            L.*, IF(R.dummy IS NULL, '0', '1') AS PHEN_TXT_VALUE\n",
    "        FROM L \n",
    "        LEFT JOIN \n",
    "            JAX_textHpoProfile AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.PHEN_TXT = R.MAP_TO\n",
    "    '''.format(phenotype))\n",
    "    cursor.execute('CREATE INDEX JAX_mf_diag_textHpo_idx01 ON JAX_mf_diag_textHpo (SUBJECT_ID, HADM_ID)')\n",
    "\n",
    "def diagnosisAllTextHpo(threshold_min, threshold_max):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_allTextHpo')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_allTextHpo\n",
    "        WITH \n",
    "            P AS (SELECT MAP_TO AS PHEN_TXT FROM JAX_textHpoFrequencyRank WHERE N BETWEEN {} AND {}),\n",
    "            L AS (SELECT * FROM JAX_mf_diag JOIN P)\n",
    "        SELECT \n",
    "            L.*, IF(R.dummy IS NULL, '0', '1') AS PHEN_TXT_VALUE\n",
    "        FROM L \n",
    "        LEFT JOIN \n",
    "            JAX_textHpoProfile AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.PHEN_TXT = R.MAP_TO\n",
    "    '''.format(threshold_min, threshold_max))\n",
    "    cursor.execute('CREATE INDEX JAX_mf_diag_allTextHpo_idx01 ON JAX_mf_diag_allTextHpo (SUBJECT_ID, HADM_ID, PHEN_TXT)')\n",
    "    \n",
    "def diagnosisLabHpo(phenotype):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_labHpo')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_labHpo\n",
    "        WITH L AS (SELECT JAX_mf_diag.*, '{}' AS PHEN_LAB FROM JAX_mf_diag)\n",
    "        SELECT \n",
    "            L.*, IF(R.dummy IS NULL, '0', '1') AS PHEN_LAB_VALUE\n",
    "        FROM L \n",
    "        LEFT JOIN \n",
    "             JAX_labHpoProfile AS R \n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.PHEN_LAB = R.MAP_TO\n",
    "    '''.format(phenotype))\n",
    "    cursor.execute('CREATE INDEX JAX_mf_diag_labHpo_idx01 ON JAX_mf_diag_labHpo (SUBJECT_ID, HADM_ID)')\n",
    "    \n",
    "def diagnosisAllLabHpo(threshold_min, threshold_max):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_allLabHpo')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_allLabHpo\n",
    "        WITH \n",
    "            P AS (SELECT MAP_TO AS PHEN_LAB FROM JAX_labHpoFrequencyRank WHERE N BETWEEN {} AND {}),\n",
    "            L AS (SELECT * FROM JAX_mf_diag JOIN P)\n",
    "        SELECT \n",
    "            L.*, IF(R.dummy IS NULL, '0', '1') AS PHEN_LAB_VALUE\n",
    "        FROM L \n",
    "        LEFT JOIN \n",
    "             JAX_labHpoProfile AS R \n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.PHEN_LAB = R.MAP_TO\n",
    "    '''.format(threshold_min, threshold_max))\n",
    "    cursor.execute('CREATE INDEX JAX_mf_diag_allLabHpo_idx01 ON JAX_mf_diag_allLabHpo (SUBJECT_ID, HADM_ID)')\n",
    "\n",
    "def diagnosisTextLab(phenotype):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_txtHpo_labHpo')\n",
    "    result = cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_txtHpo_labHpo \n",
    "        WITH L AS (SELECT JAX_mf_diag_textHpo.*, '{}' AS PHEN_LAB FROM JAX_mf_diag_textHpo)\n",
    "        SELECT L.*, IF(R.dummy IS NULL, '0', '1') AS PHEN_LAB_VALUE\n",
    "        FROM L \n",
    "        LEFT JOIN \n",
    "            JAX_labHpoProfile AS R \n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.PHEN_LAB = R.MAP_TO\n",
    "    '''.format(phenotype))\n",
    "    \n",
    "    \n",
    "def diagnosisAllTextAllLab():\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_allTxtHpo_allLabHpo')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_allTxtHpo_allLabHpo \n",
    "        SELECT L.SUBJECT_ID, L.HADM_ID, L.DIAGNOSIS, L.PHEN_TXT, L.PHEN_TXT_VALUE, R.PHEN_LAB, R.PHEN_LAB_VALUE \n",
    "        FROM JAX_mf_diag_allTextHpo AS L \n",
    "        JOIN JAX_mf_diag_allLabHpo AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID\n",
    "    ''')\n",
    "    \n",
    "\n",
    "def initSummaryStatisticTables():\n",
    "    # define empty columns to store summary statistics\n",
    "    summary_statistics1_radiology = pd.DataFrame(data={'DIAGNOSIS_CODE':[], \n",
    "                       'PHENOTYPE':[], \n",
    "                       'DIAGNOSIS_VALUE':[], \n",
    "                       'PHENOTYPE_VALUE':[], \n",
    "                       'N':[]},\n",
    "                columns = ['DIAGNOSIS_CODE', 'PHENOTYPE', 'DIAGNOSIS_VALUE', 'PHENOTYPE_VALUE', 'N'])\n",
    "    \n",
    "    summary_statistics1_lab = pd.DataFrame(data={'DIAGNOSIS_CODE':[], \n",
    "                       'PHENOTYPE':[], \n",
    "                       'DIAGNOSIS_VALUE':[], \n",
    "                       'PHENOTYPE_VALUE':[], \n",
    "                       'N':[]},\n",
    "                columns = ['DIAGNOSIS_CODE', 'PHENOTYPE', 'DIAGNOSIS_VALUE', 'PHENOTYPE_VALUE', 'N'])\n",
    "\n",
    "    summary_statistics2 = pd.DataFrame(data={'DIAGNOSIS_CODE':[], \n",
    "                       'PHEN_TXT':[], \n",
    "                       'PHEN_LAB':[], \n",
    "                       'DIAGNOSIS_VALUE':[], \n",
    "                       'PHEN_TXT_VALUE':[], \n",
    "                       'PHEN_LAB_VALUE':[], \n",
    "                       'N':[]},\n",
    "                columns = ['DIAGNOSIS_CODE', 'PHEN_TXT', 'PHEN_LAB', 'DIAGNOSIS_VALUE', 'PHEN_TXT_VALUE', 'PHEN_LAB_VALUE', 'N']) \n",
    "\n",
    "    return summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2\n",
    "\n",
    "def initTables(debug=False):\n",
    "    \"\"\"\n",
    "    This combines LabHpo and Inferred_LabHpo, and combines TextHpo and Inferred_TextHpo. \n",
    "    Only need to run once. For efficiency consideration, the tables can also be created as perminent. \n",
    "    It is time-consuming, so call it with caution. \n",
    "    \"\"\"\n",
    "    #init textHpoProfile and index it\n",
    "    #I create perminant tables to save time; other users should enable them\n",
    "    #textHpoProfile(include_inferred=True, threshold=1)\n",
    "    #indexTextHpoProfile()\n",
    "    #init labHpoProfile and index it\n",
    "    #labHpoProfile(threshold=1, include_inferred=True, force_update=True)\n",
    "    #indexLabHpoProfile()\n",
    "    \n",
    "    #define encounters to analyze\n",
    "    encounterOfInterest(debug)\n",
    "    indexEncounterOfInterest()\n",
    "    #init diagnosisProfile\n",
    "    diagnosisProfile()\n",
    "    \n",
    "\n",
    "def iterate(diagnosis_threshold_min, textHpo_threshold_min, labHpo_threshold_min, logger): \n",
    "    logger.info('starting iterating...................................')\n",
    "    N = pd.read_sql_query(\"SELECT count(*) FROM JAX_encounterOfInterest\", mydb)\n",
    "    # init empty tables to hold summary statistics\n",
    "    summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 = initSummaryStatisticTables()\n",
    "    \n",
    "    # define a set of diseases that we want to analyze\n",
    "    rankICD()\n",
    "    \n",
    "    diseaseOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_diagFrequencyRank WHERE N > {}\".format(diagnosis_threshold_min), mydb).ICD9_CODE.values\n",
    "    diseaseOfInterest = ['428']\n",
    "    # define encounters to analyze\n",
    "    logger.info('diseases of interest established: {}'.format(len(diseaseOfInterest)))\n",
    "    for diagnosis in diseaseOfInterest:\n",
    "        logger.info(\"start analyzing disease {}\".format(diagnosis))\n",
    "        \n",
    "        # assign each encounter whether a diagnosis code is observed\n",
    "        # create a table j1 (joint 1)\n",
    "        createDiagnosisTable(diagnosis)\n",
    "        # for every diagnosis, find phenotypes of interest to look at from radiology reports\n",
    "        # for every diagnosis, find phenotypes of interest to look at from laboratory tests\n",
    "        rankHpoFromText(diagnosis)\n",
    "        rankHpoFromLab(diagnosis)\n",
    "        \n",
    "        textHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_textHpoFrequencyRank WHERE N > {}\".format(textHpo_threshold_min), mydb).MAP_TO.values\n",
    "        labHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_labHpoFrequencyRank WHERE N > {}\".format(labHpo_threshold_min), mydb).MAP_TO.values\n",
    "        logger.info(\"TextHpo of interest established, size: {}\".format(len(textHpoOfInterest)))\n",
    "        logger.info(\"LabHpo of interest established, size: {}\".format(len(labHpoOfInterest)))\n",
    "        for textHpo in textHpoOfInterest:\n",
    "            logger.info(\"iteration: TextHpo--{}\".format(textHpo))\n",
    "            # assign each encounter whether a phenotype is observed from radiology reports\n",
    "            diagnosisTextHpo(textHpo)            \n",
    "            result1_text = pd.read_sql_query('''\n",
    "                SELECT \n",
    "                    '{}' AS DIAGNOSIS_CODE, '{}' AS PHENOTYPE, DIAGNOSIS AS DIAGNOSIS_VALUE, PHEN_TXT_VALUE AS PHENOTYPE_VALUE, COUNT(*) AS N \n",
    "                FROM JAX_mf_diag_textHpo \n",
    "                GROUP BY \n",
    "                    DIAGNOSIS, PHEN_TXT_VALUE\n",
    "            '''.format(diagnosis, textHpo), mydb)\n",
    "            summary_statistics1_radiology = summary_statistics1_radiology.append(result1_text)\n",
    "            # summary statistics for p1\n",
    "            # calculate I(p1;D)\n",
    "            for labHpo in labHpoOfInterest:\n",
    "                logger.info(\".........LabHpo--{}\".format(labHpo))\n",
    "                diagnosisLabHpo(labHpo)\n",
    "                result1_lab = pd.read_sql_query('''\n",
    "                    SELECT \n",
    "                        '{}' AS DIAGNOSIS_CODE, '{}' AS PHENOTYPE, DIAGNOSIS AS DIAGNOSIS_VALUE, PHEN_LAB_VALUE AS PHENOTYPE_VALUE, COUNT(*) AS N \n",
    "                    FROM \n",
    "                        JAX_mf_diag_labHpo \n",
    "                    GROUP BY DIAGNOSIS, PHEN_LAB_VALUE\n",
    "                '''.format(diagnosis, labHpo), mydb)\n",
    "                summary_statistics1_lab = summary_statistics1_lab.append(result1_lab)\n",
    "            \n",
    "                # assign each encounter whether a phenotype is observed from lab tests\n",
    "                diagnosisTextLab(labHpo)\n",
    "                result2 = pd.read_sql_query('''\n",
    "                    SELECT \n",
    "                        '{}' AS DIAGNOSIS_CODE, \n",
    "                        '{}' AS PHEN_TXT, \n",
    "                        '{}' AS PHEN_LAB,  \n",
    "                        DIAGNOSIS AS DIAGNOSIS_VALUE, \n",
    "                        PHEN_TXT_VALUE, \n",
    "                        PHEN_LAB_VALUE, \n",
    "                        COUNT(*) AS N\n",
    "                    FROM JAX_mf_diag_txtHpo_labHpo \n",
    "                    GROUP BY DIAGNOSIS, PHEN_TXT_VALUE, PHEN_LAB_VALUE\n",
    "                '''.format(diagnosis, textHpo, labHpo), mydb)\n",
    "                summary_statistics2 = summary_statistics2.append(result2)\n",
    "    logger.info('end iterating.....................................')            \n",
    "    return N, summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 \n",
    "\n",
    "\n",
    "def iterate_batch(diagnosis_threshold_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max, logger): \n",
    "    logger.info('starting iterating...................................')\n",
    "    N = pd.read_sql_query(\"SELECT count(*) FROM JAX_encounterOfInterest\", mydb)\n",
    "    # init empty tables to hold summary statistics\n",
    "    summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 = initSummaryStatisticTables()\n",
    "    \n",
    "    # define a set of diseases that we want to analyze\n",
    "    rankICD()\n",
    "    \n",
    "    diseaseOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_diagFrequencyRank WHERE N > {}\".format(diagnosis_threshold_min), mydb).ICD9_CODE.values\n",
    "    diseaseOfInterest = ['428']\n",
    "    logger.info('diseases of interest established: {}'.format(len(diseaseOfInterest)))\n",
    "    \n",
    "    for diagnosis in diseaseOfInterest:\n",
    "        logger.info(\"start analyzing disease {}\".format(diagnosis))\n",
    "        \n",
    "        logger.info(\".......assigning values of diagnosis\")\n",
    "        # assign each encounter whether a diagnosis code is observed\n",
    "        # create a table j1 (joint 1)\n",
    "        createDiagnosisTable(diagnosis)\n",
    "        # for every diagnosis, find phenotypes of interest to look at from radiology reports\n",
    "        # for every diagnosis, find phenotypes of interest to look at from laboratory tests\n",
    "        rankHpoFromText(diagnosis)\n",
    "        rankHpoFromLab(diagnosis)\n",
    "        logger.info(\"..............diagnosis values found\")\n",
    "        \n",
    "        logger.info(\".......assigning values of TextHpo\")\n",
    "        diagnosisAllTextHpo(textHpo_threshold_min, textHpo_threshold_max)\n",
    "        result1_text = pd.read_sql_query(\"\"\"\n",
    "            SELECT '{}' AS DIAGNOSIS_CODE, \n",
    "                PHEN_TXT AS PHENOTYPE, \n",
    "                DIAGNOSIS AS DIAGNOSIS_VALUE, \n",
    "                PHEN_TXT_VALUE AS PHENOTYPE_VALUE, \n",
    "                COUNT(*) AS N \n",
    "            FROM JAX_mf_diag_allTextHpo \n",
    "            GROUP BY DIAGNOSIS, PHEN_TXT, PHEN_TXT_VALUE\n",
    "        \"\"\".format(diagnosis), mydb)\n",
    "        logger.info(\"..............TextHpo values found\")\n",
    "        summary_statistics1_radiology = summary_statistics1_radiology.append(result1_text)\n",
    "\n",
    "        \n",
    "        logger.info(\".......assigning values of LabHpo\")\n",
    "        diagnosisAllLabHpo(labHpo_threshold_min, labHpo_threshold_max)\n",
    "        result1_lab = pd.read_sql_query(\"\"\"\n",
    "            SELECT \n",
    "                '{}' AS DIAGNOSIS_CODE, \n",
    "                PHEN_LAB AS PHENOTYPE, \n",
    "                DIAGNOSIS AS DIAGNOSIS_VALUE, \n",
    "                PHEN_LAB_VALUE AS PHENOTYPE_VALUE, \n",
    "                COUNT(*) AS N \n",
    "            FROM JAX_mf_diag_allLabHpo \n",
    "            GROUP BY DIAGNOSIS, PHEN_LAB, PHEN_LAB_VALUE\n",
    "        \"\"\".format(diagnosis), mydb)\n",
    "        logger.info(\"..............LabHpo values found\")\n",
    "        summary_statistics1_lab = summary_statistics1_lab.append(result1_lab)\n",
    "\n",
    "        logger.info(\".......building diagnosis-TextHpo-LabHpo joint distribution\")\n",
    "        diagnosisAllTextAllLab()\n",
    "        result2 = pd.read_sql_query(\"\"\"\n",
    "            SELECT \n",
    "                '{}' AS DIAGNOSIS_CODE, \n",
    "                PHEN_TXT, \n",
    "                PHEN_LAB, \n",
    "                DIAGNOSIS AS DIAGNOSIS_VALUE,\n",
    "                PHEN_TXT_VALUE, \n",
    "                PHEN_LAB_VALUE, \n",
    "                COUNT(*) AS N \n",
    "            FROM JAX_mf_diag_allTxtHpo_allLabHpo \n",
    "            GROUP BY DIAGNOSIS, PHEN_LAB, PHEN_LAB_VALUE, PHEN_TXT, PHEN_TXT_VALUE\n",
    "        \"\"\".format(diagnosis) , mydb)\n",
    "        logger.info(\"..............diagnosis-TextHpo-LabHpo joint distribution built\")\n",
    "        summary_statistics2 = summary_statistics2.append(result2)\n",
    "\n",
    "    logger.info('end iterating.....................................')            \n",
    "    return N, summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to run this\n",
    "# Again, it take either too long or too much memory space to run\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# 1. build the temp tables for Lab converted HPO, Text convert HPO\n",
    "# Read the comments within the method!\n",
    "initTables(debug=False)\n",
    "# 2. iterate the database t (for debug, use parameter values: 0, 10, 15, for production, use parameter values: 0, 10000, 10000\n",
    "#N, summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 = iterate(diagnosis_threshold_min=0, textHpo_threshold_min=10, labHpo_threshold_min=15, logger=logger)\n",
    "#N, summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 = iterate(diagnosis_threshold_min=0, textHpo_threshold_min=1000, labHpo_threshold_min=1000, logger=logger)\n",
    "\n",
    "# 2b. use the batch method\n",
    "#N2, summary_statistics1_radiology2, summary_statistics1_lab2, summary_statistics22 = iterate_batch(diagnosis_threshold_min=0, textHpo_threshold_min=0, textHpo_threshold_max=100, labHpo_threshold_min=0, labHpo_threshold_max=100, logger=logger)\n",
    "N2, summary_statistics1_radiology2, summary_statistics1_lab2, summary_statistics22 = iterate_batch(diagnosis_threshold_min=0, textHpo_threshold_min=1000, textHpo_threshold_max=100000, labHpo_threshold_min=1000, labHpo_threshold_max=100000, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_statistics1_radiology.head()\n",
    "#summary_statistics1_radiology\n",
    "#summary_statistics1_radiology2.groupby('PHENOTYPE').agg({'N': sum})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_statistics1_radiology2.head()\n",
    "summary_statistics1_radiology.merge(summary_statistics1_radiology2, on = ['DIAGNOSIS_CODE', 'PHENOTYPE', 'DIAGNOSIS_VALUE', 'PHENOTYPE_VALUE'])\n",
    "c =summary_statistics1_lab.merge(summary_statistics1_lab2, on = ['DIAGNOSIS_CODE', 'PHENOTYPE', 'DIAGNOSIS_VALUE', 'PHENOTYPE_VALUE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary_statistics2.groupby(['PHEN_TXT', 'PHEN_LAB']).agg({'N': sum})\n",
    "c = summary_statistics2.merge(summary_statistics22, on = ['DIAGNOSIS_CODE', 'PHEN_TXT', 'PHEN_LAB', 'DIAGNOSIS_VALUE', 'PHEN_TXT_VALUE', 'PHEN_LAB_VALUE'] )\n",
    "#summary_statistics2.head()\n",
    "c.loc[c.N_x != c.N_y, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexDiagnosisTable():\n",
    "    cursor.execute(\"ALTER TABLE JAX_mf_diag ADD COLUMN ROW_ID INT AUTO_INCREMENT PRIMARY KEY;\")\n",
    "    \n",
    "def batch_query(start_index, end_index, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max):\n",
    "    \n",
    "    diagnosisVector = pd.read_sql_query('''\n",
    "        SELECT DIAGNOSIS FROM JAX_mf_diag WHERE ROW_ID BETWEEN {} AND {}\n",
    "    '''.format(start_index, end_index), mydb).reset_index().DIAGNOSIS.values.astype(int)\n",
    "    \n",
    "    textHpoFlat = pd.read_sql_query('''\n",
    "        WITH encounters AS (\n",
    "            SELECT SUBJECT_ID, HADM_ID\n",
    "            FROM JAX_mf_diag \n",
    "            WHERE ROW_ID BETWEEN {} AND {}\n",
    "        ), \n",
    "        textHpoOfInterest AS (\n",
    "            SELECT MAP_TO \n",
    "            FROM JAX_textHpoFrequencyRank \n",
    "            WHERE N BETWEEN {} AND {}\n",
    "        ), \n",
    "        joint as (\n",
    "            SELECT *\n",
    "            FROM encounters \n",
    "            JOIN textHpoOfInterest)\n",
    "        \n",
    "        SELECT IF(R.dummy IS NULL, 0, 1) AS VALUE\n",
    "        FROM joint as L\n",
    "        LEFT JOIN JAX_textHpoProfile AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.MAP_TO = R.MAP_TO\n",
    "    '''.format(start_index, end_index, textHpo_threshold_min, textHpo_threshold_max), mydb)\n",
    "    \n",
    "    labHpoFlat = pd.read_sql_query('''\n",
    "        WITH encounters AS (\n",
    "            SELECT SUBJECT_ID, HADM_ID\n",
    "            FROM JAX_mf_diag \n",
    "            WHERE ROW_ID BETWEEN {} AND {}\n",
    "        ), \n",
    "        labHpoOfInterest AS (\n",
    "            SELECT MAP_TO \n",
    "            FROM JAX_labHpoFrequencyRank \n",
    "            WHERE N BETWEEN {} AND {}\n",
    "        ), \n",
    "        joint as (\n",
    "            SELECT *\n",
    "            FROM encounters \n",
    "            JOIN labHpoOfInterest)\n",
    "        \n",
    "        SELECT IF(R.dummy IS NULL, 0, 1) AS VALUE\n",
    "        FROM joint as L\n",
    "        LEFT JOIN JAX_labHpoProfile AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.MAP_TO = R.MAP_TO\n",
    "    '''.format(start_index, end_index, labHpo_threshold_min, labHpo_threshold_max), mydb)\n",
    "    \n",
    "    return diagnosisVector, textHpoFlat.iloc[:,0].values.astype(int), labHpoFlat.iloc[:, 0].values.astype(int)\n",
    "\n",
    "def iterate_in_batch(diagnosis_threshold_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max, logger):\n",
    "    logger.info('starting iterate_in_batch()')\n",
    "    batch_size = 100\n",
    "    \n",
    "    # define a set of diseases that we want to analyze\n",
    "    rankICD()\n",
    "    \n",
    "    diseaseOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_diagFrequencyRank WHERE N > {}\".format(diagnosis_threshold_min), mydb).ICD9_CODE.values\n",
    "    #diseaseOfInterest = ['428']\n",
    "    logger.info('diagnosis of interest: {}'.format(len(diseaseOfInterest)))\n",
    "    \n",
    "    synergies = {}\n",
    "    \n",
    "    for diagnosis in diseaseOfInterest:\n",
    "        logger.info(\"start analyzing disease {}\".format(diagnosis))\n",
    "        \n",
    "        logger.info(\".......assigning values of diagnosis\")\n",
    "        # assign each encounter whether a diagnosis code is observed\n",
    "        # create a table j1 (joint 1)\n",
    "        createDiagnosisTable(diagnosis)\n",
    "        indexDiagnosisTable()\n",
    "        # for every diagnosis, find phenotypes of interest to look at from radiology reports\n",
    "        # for every diagnosis, find phenotypes of interest to look at from laboratory tests\n",
    "        rankHpoFromText(diagnosis)\n",
    "        rankHpoFromLab(diagnosis)\n",
    "        logger.info(\"..............diagnosis values found\")\n",
    "        \n",
    "        textHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_textHpoFrequencyRank WHERE N BETWEEN {} AND {}\".format(textHpo_threshold_min, textHpo_threshold_max), mydb).MAP_TO.values\n",
    "        labHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_labHpoFrequencyRank WHERE N BETWEEN {} AND {}\".format(labHpo_threshold_min, labHpo_threshold_max), mydb).MAP_TO.values\n",
    "        logger.info(\"TextHpo of interest established, size: {}\".format(len(textHpoOfInterest)))\n",
    "        logger.info(\"LabHpo of interest established, size: {}\".format(len(labHpoOfInterest)))\n",
    "\n",
    "        ## find the start and end ROW_ID for patient*encounter\n",
    "        ADM_ID_START, ADM_ID_END = pd.read_sql_query('SELECT MIN(ROW_ID) AS min, MAX(ROW_ID) AS max FROM JAX_mf_diag', mydb).iloc[0]\n",
    "        batch_N = ADM_ID_END - ADM_ID_START + 1\n",
    "        TOTAL_BATCH = math.ceil(batch_N / batch_size) # total number of batches\n",
    "        \n",
    "        synergies[diagnosis] = mf.Synergy(diagnosis, textHpoOfInterest, labHpoOfInterest)\n",
    "        \n",
    "        logger.info('starting batch queries for {}'.format(diagnosis))\n",
    "        for i in np.arange(TOTAL_BATCH):\n",
    "            start_index = i * batch_size + ADM_ID_START\n",
    "            if i < TOTAL_BATCH - 1:\n",
    "                end_index = start_index + batch_size - 1\n",
    "            else:\n",
    "                end_index = batch_N\n",
    "\n",
    "            diagnosisVector, textHpoFlat, labHpoFlat =  batch_query(start_index, end_index, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max)\n",
    "\n",
    "            batch_size_actual = len(diagnosisVector)\n",
    "            textHpoOfInterest_size = len(textHpoOfInterest)\n",
    "            labHpoOfInterest_size = len(labHpoOfInterest)\n",
    "            assert(len(textHpoFlat) == batch_size_actual * textHpoOfInterest_size)\n",
    "            assert(len(labHpoFlat) == batch_size_actual * labHpoOfInterest_size)\n",
    "            \n",
    "            if batch_size_actual > 0 :\n",
    "                textHpoMatrix = textHpoFlat.reshape([batch_size_actual, textHpoOfInterest_size])\n",
    "                labHpoMatrix = labHpoFlat.reshape([batch_size_actual, labHpoOfInterest_size])\n",
    "                if i % 100 == 0:\n",
    "                    logger.info('new batch: start_index={}, end_index={}, batch_size= {}, textHpo_size = {}, labHpo_size = {}'.format(start_index, end_index, batch_size_actual, textHpoMatrix.shape[0], labHpoMatrix.shape[0]))\n",
    "                synergies[diagnosis].add_batch(textHpoMatrix,labHpoMatrix, diagnosisVector)\n",
    "    \n",
    "    return synergies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to run this\n",
    "# Again, it take either too long or too much memory space to run\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# 1. build the temp tables for Lab converted HPO, Text convert HPO\n",
    "# Read the comments within the method!\n",
    "initTables(debug=False)\n",
    "\n",
    "# 2. iterate throw the dataset\n",
    "diagnosis_threshold_min = 3000\n",
    "textHpo_threshold_min, textHpo_threshold_max = 500, 100000\n",
    "labHpo_threshold_min, labHpo_threshold_max = 1000, 100000\n",
    "# for test only\n",
    "#diagnosis_threshold_min = 5\n",
    "#textHpo_threshold_min, textHpo_threshold_max = 10, 100\n",
    "#labHpo_threshold_min, labHpo_threshold_max = 10, 100\n",
    "\n",
    "logger = logger\n",
    "synergies = iterate_in_batch(diagnosis_threshold_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('synergies_radiology_lab.obj', 'wb') as synergies_file:\n",
    "    pickle.dump(synergies, synergies_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_attack = synergies['584']\n",
    "heart_attack.pairwise_synergy_labeled().head(n = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encounterOfInterest(debug=False)\n",
    "indexEncounterOfInterest()\n",
    "diagnosisProfile()\n",
    "rankICD()\n",
    "diagnosis = '401'\n",
    "rankHpoFromText(diagnosis)\n",
    "rankHpoFromLab(diagnosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"SELECT * FROM JAX_diagFrequencyRank WHERE N > 10000\", mydb)\n",
    "#pd.read_sql_query(\"SELECT count(*) FROM JAX_diagnosisProfile LIMIT 4\", mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"SELECT * FROM JAX_labHpoFrequencyRank LIMIT 4\", mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"SELECT * FROM JAX_textHpoFrequencyRank LIMIT 4\", mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createDiagnosisTable(diagnosis)\n",
    "pd.read_sql_query(\"SELECT * FROM JAX_mf_diag\", mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexDiagnosisTable()\n",
    "pd.read_sql_query(\"SELECT * FROM JAX_mf_diag\", mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('''\n",
    "        SELECT DIAGNOSIS FROM JAX_mf_diag WHERE ROW_ID BETWEEN {} AND {}\n",
    "    '''.format(1, 25), mydb).reset_index().DIAGNOSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index, end_index, labHpo_threshold_min, labHpo_threshold_max = 0, 100, 0, 100\n",
    "pd.read_sql_query('''\n",
    "        WITH encounters AS (\n",
    "            SELECT SUBJECT_ID, HADM_ID\n",
    "            FROM JAX_mf_diag \n",
    "            WHERE ROW_ID BETWEEN {} AND {}\n",
    "        ), \n",
    "        labHpoOfInterest AS (\n",
    "            SELECT MAP_TO \n",
    "            FROM JAX_labHpoFrequencyRank \n",
    "            WHERE N BETWEEN {} AND {}\n",
    "        ), \n",
    "        joint as (\n",
    "            SELECT *\n",
    "            FROM encounters \n",
    "            JOIN labHpoOfInterest)\n",
    "        \n",
    "        SELECT IF(R.dummy IS NULL, 0, 1) AS VALUE\n",
    "        FROM joint as L\n",
    "        LEFT JOIN JAX_labHpoProfile AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.MAP_TO = R.MAP_TO\n",
    "    '''.format(start_index, end_index, labHpo_threshold_min, labHpo_threshold_max), mydb).iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosisTextHpo(phenotype='HP:0002086')\n",
    "result = pd.read_sql_query(\"SELECT '{}' AS DIAGNOSIS_CODE, '{}' AS PHENOTYPE, DIAGNOSIS AS DIAGNOSIS_VALUE, PHEN_TXT_VALUE AS PHENOTYPE_VALUE, COUNT(*) AS N FROM JAX_mf_diag_textHpo GROUP BY DIAGNOSIS, PHEN_TXT_VALUE\", mydb)\n",
    "result.head()\n",
    "#result.groupby(['DIAGNOSIS', 'PHEN_TXT_VALUE'])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosisAllTextHpo(0, 100)\n",
    "pd.read_sql_query(\"SELECT * FROM JAX_mf_diag_allTextHpo WHERE PHEN_TXT_VALUE = 1 LIMIT 5\", mydb)\n",
    "#result = pd.read_sql_query(\"SELECT '{}' AS DIAGNOSIS_CODE, PHEN_TXT AS PHENOTYPE, DIAGNOSIS AS DIAGNOSIS_VALUE, PHEN_TXT_VALUE AS PHENOTYPE_VALUE, COUNT(*) AS N FROM JAX_mf_diag_allTextHpo GROUP BY DIAGNOSIS, PHEN_TXT, PHEN_TXT_VALUE\", mydb)\n",
    "#result.groupby(['PHENOTYPE']).agg({'N':sum})\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "mydb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
