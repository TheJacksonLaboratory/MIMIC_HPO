{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "mf_module_path = os.path.abspath(os.path.join('../python'))\n",
    "if mf_module_path not in sys.path:\n",
    "    sys.path.append(mf_module_path)\n",
    "import mf\n",
    "import mf_random\n",
    "import hpoutil\n",
    "import networkx\n",
    "import obonet\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connect to MySQL database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(host='localhost',\n",
    "                               user='mimicuser',\n",
    "                               passwd='mimic',\n",
    "                               database='mimiciiiv13',\n",
    "                              auth_plugin='mysql_native_password')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First approach to query mysql from python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that MySQL connection works properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ITEMID</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>VALUENUM</th>\n",
       "      <th>VALUEUOM</th>\n",
       "      <th>FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>51143</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>51144</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>51146</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>51200</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>51221</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>%</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID  SUBJECT_ID  HADM_ID  ITEMID           CHARTTIME  VALUE  VALUENUM  \\\n",
       "0       1           2   163353   51143 2138-07-17 20:48:00      0       0.0   \n",
       "1       2           2   163353   51144 2138-07-17 20:48:00      0       0.0   \n",
       "2       3           2   163353   51146 2138-07-17 20:48:00      0       0.0   \n",
       "3       4           2   163353   51200 2138-07-17 20:48:00      0       0.0   \n",
       "4       5           2   163353   51221 2138-07-17 20:48:00      0       0.0   \n",
       "\n",
       "  VALUEUOM      FLAG  \n",
       "0        %      None  \n",
       "1        %      None  \n",
       "2        %      None  \n",
       "3        %      None  \n",
       "4        %  abnormal  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM LABEVENTS LIMIT 5;\", mydb)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a cursor so that it can be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = mydb.cursor(buffered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explored several method to compute the synergy score for different diseases. Method 1-3 all worked but the time and space requirements are too high. See the archived file. Here, we use method 4 to compute phenotype pairwise synergies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synergy between Lab-derived Abnormalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This method relies on the power of MySQL for doing queies and joins, return a batch of phenotype profiles a time, and then use the power of Numpy to do numeric computation.\n",
    "\n",
    "Specificially, the method runs the following algorithm:\n",
    "\n",
    "    1. For one diagnosis code, specify the phenotypes to analyze--a list of HPO terms.\n",
    "    2. For a batch of patient*encounters, return a list of diagnosis codes (1 or 0)\n",
    "    3. For the same batch of patient*encounters, return a list of phenotypes.\n",
    "    4. Create a numpy array with dimension (N x P)\n",
    "    5. Perform numeric computation with Numpy:\n",
    "        outer product for ++ of PxP.T\n",
    "        outer product for +- of Px(1-P).T\n",
    "        outer product for -+ of (1-P)xP\n",
    "        outer product for -- of (1-P)x(1-P).T\n",
    "        combine the above with - and + of diagnosis value\n",
    "        stack them together as a (N x P x P x 8) matrix.\n",
    "        Step 1 - 5 are performed at each site. The resulting matrix is returned to JAX for final analyze.\n",
    "    6. Compute pairwise synergy:\n",
    "        use the multi-dimension array to calculate p(D = 1), p(D = 0), p(P1 * P2)\n",
    "        compute mutual information of each phenotype in regarding to one diagnosis I(P:D)\n",
    "        compute mutual information of two phenotypes in regarding to one diagnosis I(P:D)\n",
    "        compute pairwise synergy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: rewrite to be backward compatible\n",
    "def diagnosis_set():\n",
    "    \"\"\"Aggregate ICD9 codes with the first three digit and count how many times they appear. \n",
    "    Note this function uses encounters as the unit, meaning a code will counted twice if same patient was \n",
    "    diagnosed again at a later encounter.\"\"\"\n",
    "    diagnosis_count = pd.read_sql_query(\"SELECT SUBJECT_ID, HADM_ID, \\\n",
    "        CASE \\\n",
    "        WHEN(ICD9_CODE LIKE 'V%') THEN SUBSTRING(ICD9_CODE, 1, 3) \\\n",
    "        WHEN(ICD9_CODE LIKE 'E%') THEN SUBSTRING(ICD9_CODE, 1, 4) \\\n",
    "        ELSE SUBSTRING(ICD9_CODE, 1, 3) END AS ICD9 \\\n",
    "        FROM DIAGNOSES_ICD\", mydb)\n",
    "    diagnosisSet = diagnosis_count.drop_duplicates().groupby('ICD9').size().sort_values(ascending=False)\n",
    "    return diagnosisSet\n",
    "\n",
    "#TODO: rewrite to be backward compatible\n",
    "def createAbnormalPhenotypeTable(threshold, include_inferred=True, force_update=True):\n",
    "    \"\"\"\n",
    "    This is the abnormal phenotypes. \n",
    "    @include_inferred whether to include inferred HPO. Default true.\n",
    "    @force_update whether current table, if present, should be forced to update\n",
    "    \"\"\"\n",
    "    if force_update:\n",
    "        cursor.execute('''DROP TEMPORARY TABLE IF EXISTS p''')\n",
    "    if include_inferred:\n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS p\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, LabHpo.MAP_TO\n",
    "                        FROM \n",
    "                            LABEVENTS \n",
    "                        JOIN LabHpo on LABEVENTS.ROW_ID = LabHpo.ROW_ID\n",
    "                        WHERE LabHpo.NEGATED = 'F'\n",
    "                        \n",
    "                        UNION ALL\n",
    "                        \n",
    "                        SELECT \n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, INFERRED_LABHPO.INFERRED_TO AS MAP_TO \n",
    "                        FROM \n",
    "                            INFERRED_LABHPO \n",
    "                        JOIN \n",
    "                            LABEVENTS ON INFERRED_LABHPO.LABEVENT_ROW_ID = LABEVENTS.ROW_ID\n",
    "                        )\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    HAVING COUNT(*) > {}\n",
    "                    -- parameter to control how to define an abnormal phenotype is present.\n",
    "                '''.format(threshold))\n",
    "    else:       \n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS p\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, LabHpo.MAP_TO\n",
    "                        FROM \n",
    "                            LABEVENTS \n",
    "                        JOIN LabHpo on LABEVENTS.ROW_ID = LabHpo.ROW_ID\n",
    "                        WHERE LabHpo.NEGATED = 'F')\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    HAVING COUNT(*) > {}\n",
    "                    -- parameter to control how to define an abnormal phenotype is present.\n",
    "                '''.format(threshold))\n",
    "    cursor.execute('CREATE INDEX p_idx01 ON p (SUBJECT_ID, HADM_ID)')\n",
    "    cursor.execute('CREATE INDEX p_idx02 ON p (MAP_TO);')\n",
    "\n",
    "\n",
    "#TODO: rewrite to be backward compatible\n",
    "def encountersWithDiagnosis(diagnosis):\n",
    "    cursor.execute('''DROP TEMPORARY TABLE IF EXISTS d''')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE IF NOT EXISTS d\n",
    "        SELECT \n",
    "            DISTINCT SUBJECT_ID, HADM_ID, 1 AS DIAGNOSIS\n",
    "        FROM \n",
    "            DIAGNOSES_ICD \n",
    "        WHERE ICD9_CODE LIKE '{}%'\n",
    "        -- This is encounters with positive diagnosis\n",
    "    '''.format(diagnosis))\n",
    "    cursor.execute('CREATE INDEX d_idx01 ON d(SUBJECT_ID, HADM_ID)')\n",
    "\n",
    "    \n",
    "def createPhenotypeSet(diagnosis, threshold=1000):\n",
    "    \"\"\"\n",
    "    Create the phenotypes that we should analyze. Exemely less frequently observed phenotypes are excluded.\n",
    "    \"\"\"\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS ps')\n",
    "    cursor.execute('''\n",
    "            CREATE TEMPORARY TABLE ps\n",
    "            WITH pd AS(\n",
    "                SELECT p.*\n",
    "                FROM \n",
    "                    p JOIN (SELECT \n",
    "                                DISTINCT SUBJECT_ID, HADM_ID, 1 AS DIAGNOSIS\n",
    "                            FROM \n",
    "                                DIAGNOSES_ICD \n",
    "                            WHERE ICD9_CODE LIKE '{}%') AS d\n",
    "                    ON p.SUBJECT_ID = d.SUBJECT_ID AND p.HADM_ID = d.HADM_ID)\n",
    "            SELECT \n",
    "                MAP_TO, COUNT(*) AS N, 1 AS PHENOTYPE\n",
    "            FROM pd\n",
    "            GROUP BY MAP_TO\n",
    "            HAVING N > {}\n",
    "            ORDER BY N DESC'''.format(diagnosis, threshold))\n",
    "    phenoSet = pd.read_sql_query('SELECT * FROM ps', mydb)\n",
    "    return phenoSet\n",
    "\n",
    "\n",
    "def batch_query(start_index, end_index):\n",
    "    batch_size_actual = pd.read_sql_query('''\n",
    "                SELECT \n",
    "                    COUNT(DISTINCT SUBJECT_ID, HADM_ID) \n",
    "                FROM admissions \n",
    "                WHERE SUBJECT_ID BETWEEN {} AND {}\n",
    "                '''.format(start_index, end_index), mydb).iloc[0,0]\n",
    "    # create diagnosis table\n",
    "    diagnosisList = pd.read_sql_query('''\n",
    "                WITH a AS (\n",
    "                    SELECT DISTINCT SUBJECT_ID, HADM_ID \n",
    "                    FROM admissions \n",
    "                    WHERE SUBJECT_ID BETWEEN {} AND {})\n",
    "                SELECT \n",
    "                    a.SUBJECT_ID, a.HADM_ID, IF(d.DIAGNOSIS IS NULL, 0, 1) AS DIAGNOSIS\n",
    "                FROM \n",
    "                    a\n",
    "                LEFT JOIN\n",
    "                    d ON a.SUBJECT_ID = d.SUBJECT_ID AND a.HADM_ID = d.HADM_ID         \n",
    "                '''.format(start_index, end_index), mydb)\n",
    "    # create phenotype profile table\n",
    "    phenotyle_profile = pd.read_sql_query('''\n",
    "        WITH \n",
    "            a AS (\n",
    "                    SELECT \n",
    "                        DISTINCT SUBJECT_ID, HADM_ID \n",
    "                    FROM \n",
    "                        admissions \n",
    "                    WHERE SUBJECT_ID BETWEEN {} AND {}), \n",
    "            c as (\n",
    "                SELECT a.*, ps.MAP_TO\n",
    "                FROM a\n",
    "                JOIN ps),\n",
    "                -- cross product of all patient*encounter and phenotypes list\n",
    "            pp as (\n",
    "                SELECT p.*, 1 AS PHENOTYPE \n",
    "                FROM p RIGHT JOIN a \n",
    "                ON p.SUBJECT_ID = a.SUBJECT_ID AND p.HADM_ID = a.HADM_ID)\n",
    "\n",
    "        SELECT c.SUBJECT_ID, c.HADM_ID, c.MAP_TO, IF(pp.PHENOTYPE IS NULL, 0, 1) AS PHENOTYPE \n",
    "        FROM pp \n",
    "        RIGHT JOIN c ON pp.SUBJECT_ID = c.SUBJECT_ID and pp.HADM_ID = c.HADM_ID AND pp.MAP_TO = c.MAP_TO\n",
    "        '''.format(start_index, end_index), mydb)\n",
    "    return batch_size_actual, diagnosisList, phenotyle_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_in_batch(logger):\n",
    "    logger.info('starting iterate_in_batch()')\n",
    "    batch_size = 100\n",
    "    # find the set of diagnosis that are worthy to analyze\n",
    "    diagnosisSet = diagnosis_set()\n",
    "    logger.info('diagnosis set completed')\n",
    "\n",
    "    # create a temp table for abnormal phenotypes of each patient*encounter that met the threshold\n",
    "    #createAbnormalPhenotypeTable(threshold=1, force_update=True)\n",
    "    logger.info('createAbnormalPhenotypeTable() completed')\n",
    "    \n",
    "    synergies = {}\n",
    "    \n",
    "    for diagnosis in diagnosisSet.keys():\n",
    "        if (diagnosisSet[diagnosis] > 5000):\n",
    "            # create a temp table for diagnosis of all patient*encouter to analyze\n",
    "            encountersWithDiagnosis(diagnosis)\n",
    "            logger.info('encountersWithDiagnosis() completed')\n",
    "\n",
    "            ## create a list of phenotypes that we want to analyze for the specified disease and preset threshold\n",
    "            phenoSet = createPhenotypeSet(diagnosis, threshold=100)\n",
    "            logger.info('phenoSet completed')\n",
    "            P_SIZE = len(phenoSet)\n",
    "\n",
    "            ## find the start and end ROW_ID for patient*encounter\n",
    "            ADM_ID_START, ADM_ID_END = pd.read_sql_query('SELECT MIN(ROW_ID) AS min, MAX(ROW_ID) AS max FROM admissions', mydb).iloc[0]\n",
    "            batch_N = ADM_ID_END - ADM_ID_START + 1\n",
    "            TOTAL_BATCH = math.ceil(batch_N / batch_size) # total number of batches\n",
    "            synergies[diagnosis] = mf.Synergy(diagnosis, phenoSet.MAP_TO)\n",
    "            logger.info('starting batch queries for {}'.format(diagnosis))\n",
    "            for i in np.arange(TOTAL_BATCH):\n",
    "                start_index = i * batch_size + ADM_ID_START\n",
    "                if i < TOTAL_BATCH - 1:\n",
    "                    end_index = start_index + batch_size - 1\n",
    "                else:\n",
    "                    end_index = batch_N\n",
    "                \n",
    "                batch_size_actual, diagnosisList, phenotyle_profile = batch_query(start_index, end_index)\n",
    "                \n",
    "                if batch_size_actual > 0 :\n",
    "                    diagnosisVector = diagnosisList.DIAGNOSIS\n",
    "                    phenotypeProfileMatrix = phenotyle_profile.PHENOTYPE.values.reshape([batch_size_actual, P_SIZE])\n",
    "                    if i % 100 == 0:\n",
    "                        logger.info('new batch: start_index={}, end_index={}, batch_size= {}, phenotype_size = {}'.format(start_index, end_index, batch_size_actual, len(phenoSet)))\n",
    "                    synergies[diagnosis].add_batch(phenotypeProfileMatrix, diagnosisVector)\n",
    "    \n",
    "    return synergies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes about 10 minutes to set up the phenotype table (p). Afterward, each disease takes about 10 minutes to complete the summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s',level=logging.DEBUG, stream=sys.stdout)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "synergies = iterate_in_batch(logger)\n",
    "   \n",
    "end = datetime.datetime.now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('running time: {}s'.format((end - start).total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('synergies.obj', 'wb') as synergies_file:\n",
    "    pickle.dump(synergies, synergies_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "close database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "mydb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Synergy between lab-derived and radiology report-derived Abnormalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm is about the same with the Method 3 in mutual_info_archive. Briefly, \n",
    "\n",
    "    * Select encounterOfInterest, temp table: JAX_encounterOfInterest(SUBJECT_ID, HADM_ID)\n",
    "    * Init diagnosisProfile: temp table: JAX_diagnosisProfile(SUBJECT_ID, HADM_ID, ICD, N)\n",
    "    * Init textHpoProfile: temp table: JAX_textHpoProfile(SUBJECT_ID, HADM_ID, MAP_TO, N)\n",
    "    * Init labHpoProfile: temp table: JAX_labHpoProfile(SUBJECT_ID, HADM_ID, MAP_TO, N)\n",
    "    \n",
    "    * Rank ICD frequency, temp table: JAX_diagFrequencyRank(ICD, N)\n",
    "      select diagOfInterest\n",
    "    * Rank textHPO frequency, temp table: JAX_textHpoFrequencyRank(MAP_TO, N)\n",
    "      select textHpoOfInterest\n",
    "    * Rank labHPO frequency, temp table: JAX_labHpoFrequencyRank(MAP_TO, N)\n",
    "      select labHpoOfInterest\n",
    "    \n",
    "    * Iteratation\n",
    "      for diagnosis in diagOfInterest\n",
    "          for textHpo in textHpoOfInterest\n",
    "              for labHpo in labHpoOfInterest\n",
    "                 Assign diagnosis value: assignDiagnosis(), table: (SUBJECT_ID, HADM_ID, DIAGNOSIS)\n",
    "                 Assign text2hpo phenotype value: table: SUBJECT_ID, HADM_ID, PHEN_TEXT\n",
    "                 Assign lab2hpo phenotype value: table: SUBJECT_ID, HADM_ID, PHEN_LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define encounters of interest\n",
    "def encounterOfInterest(debug=False):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_encounterOfInterest')\n",
    "    if debug:\n",
    "        limit = 'LIMIT 100'\n",
    "    else:\n",
    "        limit = ''\n",
    "    # This is admissions that we want to analyze, 'LIMIT 100' in debug mode\n",
    "    cursor.execute('''\n",
    "                CREATE TEMPORARY TABLE IF NOT EXISTS JAX_encounterOfInterest \n",
    "                SELECT \n",
    "                    DISTINCT SUBJECT_ID, HADM_ID \n",
    "                FROM admissions\n",
    "                {}\n",
    "                '''.format(limit))\n",
    "    \n",
    "def indexEncounterOfInterest():\n",
    "    cursor.execute('CREATE INDEX JAX_encounterOfInterest_idx01 ON JAX_encounterOfInterest (SUBJECT_ID, HADM_ID)')\n",
    "    \n",
    "def diagnosisProfile():\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_diagnosisProfile')\n",
    "    cursor.execute('''\n",
    "                CREATE TEMPORARY TABLE IF NOT EXISTS JAX_diagnosisProfile\n",
    "                SELECT \n",
    "                    DIAGNOSES_ICD.SUBJECT_ID, DIAGNOSES_ICD.HADM_ID, DIAGNOSES_ICD.ICD9_CODE\n",
    "                FROM\n",
    "                    DIAGNOSES_ICD\n",
    "                RIGHT JOIN\n",
    "                    JAX_encounterOfInterest\n",
    "                ON \n",
    "                    DIAGNOSES_ICD.SUBJECT_ID = JAX_encounterOfInterest.SUBJECT_ID \n",
    "                    AND \n",
    "                    DIAGNOSES_ICD.HADM_ID = JAX_encounterOfInterest.HADM_ID\n",
    "                ''')\n",
    "    \n",
    "def textHpoProfile(include_inferred=True, threshold=1):\n",
    "    if include_inferred:\n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS JAX_textHpoProfile\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            NOTEEVENTS.SUBJECT_ID, NOTEEVENTS.HADM_ID, NoteHpoClinPhen.MAP_TO\n",
    "                        FROM \n",
    "                            NOTEEVENTS \n",
    "                        JOIN NoteHpoClinPhen on NOTEEVENTS.ROW_ID = NoteHpoClinPhen.NOTES_ROW_ID\n",
    "                        \n",
    "                        UNION ALL\n",
    "                        \n",
    "                        SELECT\n",
    "                            NOTEEVENTS.SUBJECT_ID, NOTEEVENTS.HADM_ID, Inferred_NoteHpo.INFERRED_TO AS MAP_TO\n",
    "                        FROM \n",
    "                            NOTEEVENTS \n",
    "                        JOIN Inferred_NoteHpo on NOTEEVENTS.ROW_ID = Inferred_NoteHpo.NOTEEVENT_ROW_ID\n",
    "                        )\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO, 1 AS dummy\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    HAVING COUNT(*) > {}\n",
    "                    -- parameter to control how to define an abnormal phenotype is present.\n",
    "                '''.format(threshold))\n",
    "        \n",
    "    else:\n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS JAX_p_text\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            NOTEEVENTS.SUBJECT_ID, NOTEEVENTS.HADM_ID, NoteHpoClinPhen.MAP_TO\n",
    "                        FROM \n",
    "                            NOTEEVENTS \n",
    "                        JOIN NoteHpoClinPhen on NOTEEVENTS.ROW_ID = NoteHpoClinPhen.NOTES_ROW_ID)\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO, 1 AS dummy\n",
    "                    HAVING COUNT(*) > {}\n",
    "                    -- parameter to control how to define an abnormal phenotype is present.\n",
    "                '''.format(threshold))\n",
    "        \n",
    "def indexTextHpoProfile():\n",
    "    cursor.execute('CREATE INDEX JAX_textHpoProfile_idx01 ON JAX_textHpoProfile (SUBJECT_ID, HADM_ID)')\n",
    "    cursor.execute('CREATE INDEX JAX_textHpoProfile_idx02 ON JAX_textHpoProfile (MAP_TO);')\n",
    "    cursor.execute('CREATE INDEX JAX_textHpoProfile_idx03 ON JAX_textHpoProfile (SUBJECT_ID, HADM_ID, MAP_TO)')\n",
    "    \n",
    "def labHpoProfile(threshold, include_inferred=True, force_update=True):\n",
    "    # TODO: refactor the method \n",
    "    #createAbnormalPhenotypeTable(threshold, include_inferred=True, force_update=True)\n",
    "    \n",
    "    if force_update:\n",
    "        cursor.execute('''DROP TEMPORARY TABLE IF EXISTS JAX_labHpoProfile''')\n",
    "    if include_inferred:\n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS JAX_labHpoProfile\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, LabHpo.MAP_TO\n",
    "                        FROM \n",
    "                            LABEVENTS \n",
    "                        JOIN LabHpo on LABEVENTS.ROW_ID = LabHpo.ROW_ID\n",
    "                        WHERE LabHpo.NEGATED = 'F'\n",
    "                        \n",
    "                        UNION ALL\n",
    "                        \n",
    "                        SELECT \n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, INFERRED_LABHPO.INFERRED_TO AS MAP_TO \n",
    "                        FROM \n",
    "                            INFERRED_LABHPO \n",
    "                        JOIN \n",
    "                            LABEVENTS ON INFERRED_LABHPO.LABEVENT_ROW_ID = LABEVENTS.ROW_ID\n",
    "                        )\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO, 1 AS dummy\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    HAVING COUNT(*) > {}\n",
    "                    -- parameter to control how to define an abnormal phenotype is present.\n",
    "                '''.format(threshold))\n",
    "    else:       \n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS JAX_labHpoProfile\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, LabHpo.MAP_TO\n",
    "                        FROM \n",
    "                            LABEVENTS \n",
    "                        JOIN LabHpo on LABEVENTS.ROW_ID = LabHpo.ROW_ID\n",
    "                        WHERE LabHpo.NEGATED = 'F')\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO, 1 AS dummy\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    HAVING COUNT(*) > {}\n",
    "                    -- parameter to control how to define an abnormal phenotype is present.\n",
    "                '''.format(threshold))\n",
    "\n",
    "def indexLabHpoProfile():\n",
    "    cursor.execute('CREATE INDEX JAX_labHpoProfile_idx01 ON JAX_labHpoProfile (SUBJECT_ID, HADM_ID)')\n",
    "    cursor.execute('CREATE INDEX JAX_labHpoProfile_idx02 ON JAX_labHpoProfile (MAP_TO);')\n",
    "    cursor.execute('CREATE INDEX JAX_labHpoProfile_idx03 ON JAX_labHpoProfile (SUBJECT_ID, HADM_ID, MAP_TO)')\n",
    "    \n",
    "def rankICD():\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_diagFrequencyRank')\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TEMPORARY TABLE IF NOT EXISTS JAX_diagFrequencyRank\n",
    "        WITH JAX_temp_diag AS (\n",
    "            SELECT DISTINCT SUBJECT_ID, HADM_ID, \n",
    "                CASE \n",
    "                    WHEN(ICD9_CODE LIKE 'V%') THEN SUBSTRING(ICD9_CODE, 1, 3) \n",
    "                    WHEN(ICD9_CODE LIKE 'E%') THEN SUBSTRING(ICD9_CODE, 1, 4) \n",
    "                ELSE \n",
    "                    SUBSTRING(ICD9_CODE, 1, 3) END AS ICD9_CODE \n",
    "            FROM JAX_diagnosisProfile)\n",
    "        SELECT \n",
    "            ICD9_CODE, COUNT(*) AS N\n",
    "        FROM\n",
    "            JAX_temp_diag\n",
    "        GROUP BY \n",
    "            ICD9_CODE\n",
    "        ORDER BY N\n",
    "        DESC\n",
    "        \"\"\")\n",
    "\n",
    "def rankHpoFromText(diagnosis):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_textHpoFrequencyRank')\n",
    "    cursor.execute('''\n",
    "            CREATE TEMPORARY TABLE JAX_textHpoFrequencyRank            \n",
    "            WITH pd AS(\n",
    "                SELECT \n",
    "                    JAX_textHpoProfile.*\n",
    "                FROM \n",
    "                    JAX_textHpoProfile \n",
    "                JOIN (\n",
    "                    SELECT \n",
    "                        DISTINCT SUBJECT_ID, HADM_ID\n",
    "                    FROM \n",
    "                        JAX_diagnosisProfile \n",
    "                    WHERE \n",
    "                        ICD9_CODE LIKE '{}%') AS d\n",
    "                ON \n",
    "                    JAX_textHpoProfile.SUBJECT_ID = d.SUBJECT_ID AND JAX_textHpoProfile.HADM_ID = d.HADM_ID)\n",
    "            SELECT \n",
    "                MAP_TO, COUNT(*) AS N, 1 AS PHENOTYPE\n",
    "            FROM pd\n",
    "            GROUP BY MAP_TO\n",
    "            ORDER BY N DESC'''.format(diagnosis))\n",
    "    \n",
    "def rankHpoFromLab(diagnosis):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_labHpoFrequencyRank')\n",
    "    cursor.execute('''\n",
    "            CREATE TEMPORARY TABLE JAX_labHpoFrequencyRank            \n",
    "            WITH pd AS(\n",
    "                SELECT \n",
    "                    JAX_labHpoProfile.*\n",
    "                FROM \n",
    "                    JAX_labHpoProfile \n",
    "                JOIN (\n",
    "                    SELECT \n",
    "                        DISTINCT SUBJECT_ID, HADM_ID\n",
    "                    FROM \n",
    "                        JAX_diagnosisProfile \n",
    "                    WHERE \n",
    "                        ICD9_CODE LIKE '{}%') AS d\n",
    "                ON \n",
    "                    JAX_labHpoProfile.SUBJECT_ID = d.SUBJECT_ID AND JAX_labHpoProfile.HADM_ID = d.HADM_ID)\n",
    "            SELECT \n",
    "                MAP_TO, COUNT(*) AS N, 1 AS PHENOTYPE\n",
    "            FROM pd\n",
    "            GROUP BY MAP_TO\n",
    "            ORDER BY N DESC'''.format(diagnosis))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign 0 or 1 to each encouter whether a diagnosis is observed\n",
    "def createDiagnosisTable(diagnosis):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag')\n",
    "    cursor.execute('''\n",
    "                CREATE TEMPORARY TABLE IF NOT EXISTS JAX_mf_diag \n",
    "                WITH \n",
    "                    d AS (\n",
    "                        SELECT \n",
    "                            DISTINCT SUBJECT_ID, HADM_ID, '1' AS DIAGNOSIS\n",
    "                        FROM \n",
    "                            JAX_diagnosisProfile \n",
    "                        WHERE ICD9_CODE LIKE '{}%')\n",
    "                    -- This is encounters with positive diagnosis\n",
    "\n",
    "                SELECT \n",
    "                    DISTINCT a.SUBJECT_ID, a.HADM_ID, IF(d.DIAGNOSIS IS NULL, '0', '1') AS DIAGNOSIS\n",
    "                FROM \n",
    "                    JAX_encounterOfInterest AS a\n",
    "                LEFT JOIN\n",
    "                    d ON a.SUBJECT_ID = d.SUBJECT_ID AND a.HADM_ID = d.HADM_ID       \n",
    "                /* -- This is the first join for diagnosis (0, or 1) */    \n",
    "                '''.format(diagnosis))\n",
    "    cursor.execute('CREATE INDEX JAX_mf_diag_idx01 ON JAX_mf_diag (SUBJECT_ID, HADM_ID)')\n",
    "\n",
    "# assign 0 or 1 to each encounter whether a phenotype is observed from radiology reports\n",
    "def diagnosisTextHpo(phenotype):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_textHpo')\n",
    "    \"\"\"\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_textHpo\n",
    "        SELECT \n",
    "            L.*, IF(R.MAP_TO IS NULL, '0', '1') AS PHEN_TXT\n",
    "        FROM JAX_mf_diag AS L \n",
    "        LEFT JOIN \n",
    "            (SELECT * \n",
    "            FROM JAX_textHpoProfile \n",
    "            WHERE JAX_textHpoProfile.MAP_TO = '{}') AS R \n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID \n",
    "    '''.format(phenotype))\n",
    "    \"\"\"\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_textHpo\n",
    "        WITH L AS (SELECT JAX_mf_diag.*, '{}' AS PHEN_TXT FROM JAX_mf_diag)\n",
    "        SELECT \n",
    "            L.*, IF(R.dummy IS NULL, '0', '1') AS PHEN_TXT_VALUE\n",
    "        FROM L \n",
    "        LEFT JOIN \n",
    "            JAX_textHpoProfile AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.PHEN_TXT = R.MAP_TO\n",
    "    '''.format(phenotype))\n",
    "    cursor.execute('CREATE INDEX JAX_mf_diag_textHpo_idx01 ON JAX_mf_diag_textHpo (SUBJECT_ID, HADM_ID)')\n",
    "\n",
    "def diagnosisAllTextHpo(threshold_min, threshold_max):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_allTextHpo')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_allTextHpo\n",
    "        WITH \n",
    "            P AS (SELECT MAP_TO AS PHEN_TXT FROM JAX_textHpoFrequencyRank WHERE N BETWEEN {} AND {}),\n",
    "            L AS (SELECT * FROM JAX_mf_diag JOIN P)\n",
    "        SELECT \n",
    "            L.*, IF(R.dummy IS NULL, '0', '1') AS PHEN_TXT_VALUE\n",
    "        FROM L \n",
    "        LEFT JOIN \n",
    "            JAX_textHpoProfile AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.PHEN_TXT = R.MAP_TO\n",
    "    '''.format(threshold_min, threshold_max))\n",
    "    cursor.execute('CREATE INDEX JAX_mf_diag_allTextHpo_idx01 ON JAX_mf_diag_allTextHpo (SUBJECT_ID, HADM_ID, PHEN_TXT)')\n",
    "    \n",
    "def diagnosisLabHpo(phenotype):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_labHpo')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_labHpo\n",
    "        WITH L AS (SELECT JAX_mf_diag.*, '{}' AS PHEN_LAB FROM JAX_mf_diag)\n",
    "        SELECT \n",
    "            L.*, IF(R.dummy IS NULL, '0', '1') AS PHEN_LAB_VALUE\n",
    "        FROM L \n",
    "        LEFT JOIN \n",
    "             JAX_labHpoProfile AS R \n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.PHEN_LAB = R.MAP_TO\n",
    "    '''.format(phenotype))\n",
    "    cursor.execute('CREATE INDEX JAX_mf_diag_labHpo_idx01 ON JAX_mf_diag_labHpo (SUBJECT_ID, HADM_ID)')\n",
    "    \n",
    "def diagnosisAllLabHpo(threshold_min, threshold_max):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_allLabHpo')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_allLabHpo\n",
    "        WITH \n",
    "            P AS (SELECT MAP_TO AS PHEN_LAB FROM JAX_labHpoFrequencyRank WHERE N BETWEEN {} AND {}),\n",
    "            L AS (SELECT * FROM JAX_mf_diag JOIN P)\n",
    "        SELECT \n",
    "            L.*, IF(R.dummy IS NULL, '0', '1') AS PHEN_LAB_VALUE\n",
    "        FROM L \n",
    "        LEFT JOIN \n",
    "             JAX_labHpoProfile AS R \n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.PHEN_LAB = R.MAP_TO\n",
    "    '''.format(threshold_min, threshold_max))\n",
    "    cursor.execute('CREATE INDEX JAX_mf_diag_allLabHpo_idx01 ON JAX_mf_diag_allLabHpo (SUBJECT_ID, HADM_ID)')\n",
    "\n",
    "def diagnosisTextLab(phenotype):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_txtHpo_labHpo')\n",
    "    result = cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_txtHpo_labHpo \n",
    "        WITH L AS (SELECT JAX_mf_diag_textHpo.*, '{}' AS PHEN_LAB FROM JAX_mf_diag_textHpo)\n",
    "        SELECT L.*, IF(R.dummy IS NULL, '0', '1') AS PHEN_LAB_VALUE\n",
    "        FROM L \n",
    "        LEFT JOIN \n",
    "            JAX_labHpoProfile AS R \n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.PHEN_LAB = R.MAP_TO\n",
    "    '''.format(phenotype))\n",
    "    \n",
    "    \n",
    "def diagnosisAllTextAllLab():\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_allTxtHpo_allLabHpo')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_allTxtHpo_allLabHpo \n",
    "        SELECT L.SUBJECT_ID, L.HADM_ID, L.DIAGNOSIS, L.PHEN_TXT, L.PHEN_TXT_VALUE, R.PHEN_LAB, R.PHEN_LAB_VALUE \n",
    "        FROM JAX_mf_diag_allTextHpo AS L \n",
    "        JOIN JAX_mf_diag_allLabHpo AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID\n",
    "    ''')\n",
    "    \n",
    "\n",
    "def initSummaryStatisticTables():\n",
    "    # define empty columns to store summary statistics\n",
    "    summary_statistics1_radiology = pd.DataFrame(data={'DIAGNOSIS_CODE':[], \n",
    "                       'PHENOTYPE':[], \n",
    "                       'DIAGNOSIS_VALUE':[], \n",
    "                       'PHENOTYPE_VALUE':[], \n",
    "                       'N':[]},\n",
    "                columns = ['DIAGNOSIS_CODE', 'PHENOTYPE', 'DIAGNOSIS_VALUE', 'PHENOTYPE_VALUE', 'N'])\n",
    "    \n",
    "    summary_statistics1_lab = pd.DataFrame(data={'DIAGNOSIS_CODE':[], \n",
    "                       'PHENOTYPE':[], \n",
    "                       'DIAGNOSIS_VALUE':[], \n",
    "                       'PHENOTYPE_VALUE':[], \n",
    "                       'N':[]},\n",
    "                columns = ['DIAGNOSIS_CODE', 'PHENOTYPE', 'DIAGNOSIS_VALUE', 'PHENOTYPE_VALUE', 'N'])\n",
    "\n",
    "    summary_statistics2 = pd.DataFrame(data={'DIAGNOSIS_CODE':[], \n",
    "                       'PHEN_TXT':[], \n",
    "                       'PHEN_LAB':[], \n",
    "                       'DIAGNOSIS_VALUE':[], \n",
    "                       'PHEN_TXT_VALUE':[], \n",
    "                       'PHEN_LAB_VALUE':[], \n",
    "                       'N':[]},\n",
    "                columns = ['DIAGNOSIS_CODE', 'PHEN_TXT', 'PHEN_LAB', 'DIAGNOSIS_VALUE', 'PHEN_TXT_VALUE', 'PHEN_LAB_VALUE', 'N']) \n",
    "\n",
    "    return summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2\n",
    "\n",
    "def initTables(debug=False):\n",
    "    \"\"\"\n",
    "    This combines LabHpo and Inferred_LabHpo, and combines TextHpo and Inferred_TextHpo. \n",
    "    Only need to run once. For efficiency consideration, the tables can also be created as perminent. \n",
    "    It is time-consuming, so call it with caution. \n",
    "    \"\"\"\n",
    "    #init textHpoProfile and index it\n",
    "    #I create perminant tables to save time; other users should enable them\n",
    "    #textHpoProfile(include_inferred=True, threshold=1)\n",
    "    #indexTextHpoProfile()\n",
    "    #init labHpoProfile and index it\n",
    "    #labHpoProfile(threshold=1, include_inferred=True, force_update=True)\n",
    "    #indexLabHpoProfile()\n",
    "    \n",
    "    #define encounters to analyze\n",
    "    encounterOfInterest(debug)\n",
    "    indexEncounterOfInterest()\n",
    "    #init diagnosisProfile\n",
    "    diagnosisProfile()\n",
    "    \n",
    "\n",
    "def iterate(diagnosis_threshold_min, textHpo_threshold_min, labHpo_threshold_min, logger): \n",
    "    logger.info('starting iterating...................................')\n",
    "    N = pd.read_sql_query(\"SELECT count(*) FROM JAX_encounterOfInterest\", mydb)\n",
    "    # init empty tables to hold summary statistics\n",
    "    summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 = initSummaryStatisticTables()\n",
    "    \n",
    "    # define a set of diseases that we want to analyze\n",
    "    rankICD()\n",
    "    \n",
    "    diseaseOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_diagFrequencyRank WHERE N > {}\".format(diagnosis_threshold_min), mydb).ICD9_CODE.values\n",
    "    diseaseOfInterest = ['428']\n",
    "    # define encounters to analyze\n",
    "    logger.info('diseases of interest established: {}'.format(len(diseaseOfInterest)))\n",
    "    for diagnosis in diseaseOfInterest:\n",
    "        logger.info(\"start analyzing disease {}\".format(diagnosis))\n",
    "        \n",
    "        # assign each encounter whether a diagnosis code is observed\n",
    "        # create a table j1 (joint 1)\n",
    "        createDiagnosisTable(diagnosis)\n",
    "        # for every diagnosis, find phenotypes of interest to look at from radiology reports\n",
    "        # for every diagnosis, find phenotypes of interest to look at from laboratory tests\n",
    "        rankHpoFromText(diagnosis)\n",
    "        rankHpoFromLab(diagnosis)\n",
    "        \n",
    "        textHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_textHpoFrequencyRank WHERE N > {}\".format(textHpo_threshold_min), mydb).MAP_TO.values\n",
    "        labHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_labHpoFrequencyRank WHERE N > {}\".format(labHpo_threshold_min), mydb).MAP_TO.values\n",
    "        logger.info(\"TextHpo of interest established, size: {}\".format(len(textHpoOfInterest)))\n",
    "        logger.info(\"LabHpo of interest established, size: {}\".format(len(labHpoOfInterest)))\n",
    "        for textHpo in textHpoOfInterest:\n",
    "            logger.info(\"iteration: TextHpo--{}\".format(textHpo))\n",
    "            # assign each encounter whether a phenotype is observed from radiology reports\n",
    "            diagnosisTextHpo(textHpo)            \n",
    "            result1_text = pd.read_sql_query('''\n",
    "                SELECT \n",
    "                    '{}' AS DIAGNOSIS_CODE, '{}' AS PHENOTYPE, DIAGNOSIS AS DIAGNOSIS_VALUE, PHEN_TXT_VALUE AS PHENOTYPE_VALUE, COUNT(*) AS N \n",
    "                FROM JAX_mf_diag_textHpo \n",
    "                GROUP BY \n",
    "                    DIAGNOSIS, PHEN_TXT_VALUE\n",
    "            '''.format(diagnosis, textHpo), mydb)\n",
    "            summary_statistics1_radiology = summary_statistics1_radiology.append(result1_text)\n",
    "            # summary statistics for p1\n",
    "            # calculate I(p1;D)\n",
    "            for labHpo in labHpoOfInterest:\n",
    "                logger.info(\".........LabHpo--{}\".format(labHpo))\n",
    "                diagnosisLabHpo(labHpo)\n",
    "                result1_lab = pd.read_sql_query('''\n",
    "                    SELECT \n",
    "                        '{}' AS DIAGNOSIS_CODE, '{}' AS PHENOTYPE, DIAGNOSIS AS DIAGNOSIS_VALUE, PHEN_LAB_VALUE AS PHENOTYPE_VALUE, COUNT(*) AS N \n",
    "                    FROM \n",
    "                        JAX_mf_diag_labHpo \n",
    "                    GROUP BY DIAGNOSIS, PHEN_LAB_VALUE\n",
    "                '''.format(diagnosis, labHpo), mydb)\n",
    "                summary_statistics1_lab = summary_statistics1_lab.append(result1_lab)\n",
    "            \n",
    "                # assign each encounter whether a phenotype is observed from lab tests\n",
    "                diagnosisTextLab(labHpo)\n",
    "                result2 = pd.read_sql_query('''\n",
    "                    SELECT \n",
    "                        '{}' AS DIAGNOSIS_CODE, \n",
    "                        '{}' AS PHEN_TXT, \n",
    "                        '{}' AS PHEN_LAB,  \n",
    "                        DIAGNOSIS AS DIAGNOSIS_VALUE, \n",
    "                        PHEN_TXT_VALUE, \n",
    "                        PHEN_LAB_VALUE, \n",
    "                        COUNT(*) AS N\n",
    "                    FROM JAX_mf_diag_txtHpo_labHpo \n",
    "                    GROUP BY DIAGNOSIS, PHEN_TXT_VALUE, PHEN_LAB_VALUE\n",
    "                '''.format(diagnosis, textHpo, labHpo), mydb)\n",
    "                summary_statistics2 = summary_statistics2.append(result2)\n",
    "    logger.info('end iterating.....................................')            \n",
    "    return N, summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 \n",
    "\n",
    "\n",
    "def iterate_batch(diagnosis_threshold_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max, logger): \n",
    "    logger.info('starting iterating...................................')\n",
    "    N = pd.read_sql_query(\"SELECT count(*) FROM JAX_encounterOfInterest\", mydb)\n",
    "    # init empty tables to hold summary statistics\n",
    "    summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 = initSummaryStatisticTables()\n",
    "    \n",
    "    # define a set of diseases that we want to analyze\n",
    "    rankICD()\n",
    "    \n",
    "    diseaseOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_diagFrequencyRank WHERE N > {}\".format(diagnosis_threshold_min), mydb).ICD9_CODE.values\n",
    "    diseaseOfInterest = ['428']\n",
    "    logger.info('diseases of interest established: {}'.format(len(diseaseOfInterest)))\n",
    "    \n",
    "    for diagnosis in diseaseOfInterest:\n",
    "        logger.info(\"start analyzing disease {}\".format(diagnosis))\n",
    "        \n",
    "        logger.info(\".......assigning values of diagnosis\")\n",
    "        # assign each encounter whether a diagnosis code is observed\n",
    "        # create a table j1 (joint 1)\n",
    "        createDiagnosisTable(diagnosis)\n",
    "        # for every diagnosis, find phenotypes of interest to look at from radiology reports\n",
    "        # for every diagnosis, find phenotypes of interest to look at from laboratory tests\n",
    "        rankHpoFromText(diagnosis)\n",
    "        rankHpoFromLab(diagnosis)\n",
    "        logger.info(\"..............diagnosis values found\")\n",
    "        \n",
    "        logger.info(\".......assigning values of TextHpo\")\n",
    "        diagnosisAllTextHpo(textHpo_threshold_min, textHpo_threshold_max)\n",
    "        result1_text = pd.read_sql_query(\"\"\"\n",
    "            SELECT '{}' AS DIAGNOSIS_CODE, \n",
    "                PHEN_TXT AS PHENOTYPE, \n",
    "                DIAGNOSIS AS DIAGNOSIS_VALUE, \n",
    "                PHEN_TXT_VALUE AS PHENOTYPE_VALUE, \n",
    "                COUNT(*) AS N \n",
    "            FROM JAX_mf_diag_allTextHpo \n",
    "            GROUP BY DIAGNOSIS, PHEN_TXT, PHEN_TXT_VALUE\n",
    "        \"\"\".format(diagnosis), mydb)\n",
    "        logger.info(\"..............TextHpo values found\")\n",
    "        summary_statistics1_radiology = summary_statistics1_radiology.append(result1_text)\n",
    "\n",
    "        \n",
    "        logger.info(\".......assigning values of LabHpo\")\n",
    "        diagnosisAllLabHpo(labHpo_threshold_min, labHpo_threshold_max)\n",
    "        result1_lab = pd.read_sql_query(\"\"\"\n",
    "            SELECT \n",
    "                '{}' AS DIAGNOSIS_CODE, \n",
    "                PHEN_LAB AS PHENOTYPE, \n",
    "                DIAGNOSIS AS DIAGNOSIS_VALUE, \n",
    "                PHEN_LAB_VALUE AS PHENOTYPE_VALUE, \n",
    "                COUNT(*) AS N \n",
    "            FROM JAX_mf_diag_allLabHpo \n",
    "            GROUP BY DIAGNOSIS, PHEN_LAB, PHEN_LAB_VALUE\n",
    "        \"\"\".format(diagnosis), mydb)\n",
    "        logger.info(\"..............LabHpo values found\")\n",
    "        summary_statistics1_lab = summary_statistics1_lab.append(result1_lab)\n",
    "\n",
    "        logger.info(\".......building diagnosis-TextHpo-LabHpo joint distribution\")\n",
    "        diagnosisAllTextAllLab()\n",
    "        result2 = pd.read_sql_query(\"\"\"\n",
    "            SELECT \n",
    "                '{}' AS DIAGNOSIS_CODE, \n",
    "                PHEN_TXT, \n",
    "                PHEN_LAB, \n",
    "                DIAGNOSIS AS DIAGNOSIS_VALUE,\n",
    "                PHEN_TXT_VALUE, \n",
    "                PHEN_LAB_VALUE, \n",
    "                COUNT(*) AS N \n",
    "            FROM JAX_mf_diag_allTxtHpo_allLabHpo \n",
    "            GROUP BY DIAGNOSIS, PHEN_LAB, PHEN_LAB_VALUE, PHEN_TXT, PHEN_TXT_VALUE\n",
    "        \"\"\".format(diagnosis) , mydb)\n",
    "        logger.info(\"..............diagnosis-TextHpo-LabHpo joint distribution built\")\n",
    "        summary_statistics2 = summary_statistics2.append(result2)\n",
    "\n",
    "    logger.info('end iterating.....................................')            \n",
    "    return N, summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to run this\n",
    "# Again, it take either too long or too much memory space to run\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# 1. build the temp tables for Lab converted HPO, Text convert HPO\n",
    "# Read the comments within the method!\n",
    "initTables(debug=False)\n",
    "# 2. iterate the database t (for debug, use parameter values: 0, 10, 15, for production, use parameter values: 0, 10000, 10000\n",
    "#N, summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 = iterate(diagnosis_threshold_min=0, textHpo_threshold_min=10, labHpo_threshold_min=15, logger=logger)\n",
    "#N, summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 = iterate(diagnosis_threshold_min=0, textHpo_threshold_min=1000, labHpo_threshold_min=1000, logger=logger)\n",
    "\n",
    "# 2b. use the batch method\n",
    "#N2, summary_statistics1_radiology2, summary_statistics1_lab2, summary_statistics22 = iterate_batch(diagnosis_threshold_min=0, textHpo_threshold_min=0, textHpo_threshold_max=100, labHpo_threshold_min=0, labHpo_threshold_max=100, logger=logger)\n",
    "N2, summary_statistics1_radiology2, summary_statistics1_lab2, summary_statistics22 = iterate_batch(diagnosis_threshold_min=0, textHpo_threshold_min=1000, textHpo_threshold_max=100000, labHpo_threshold_min=1000, labHpo_threshold_max=100000, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_statistics1_radiology.head()\n",
    "#summary_statistics1_radiology\n",
    "#summary_statistics1_radiology2.groupby('PHENOTYPE').agg({'N': sum})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_statistics1_radiology2.head()\n",
    "summary_statistics1_radiology.merge(summary_statistics1_radiology2, on = ['DIAGNOSIS_CODE', 'PHENOTYPE', 'DIAGNOSIS_VALUE', 'PHENOTYPE_VALUE'])\n",
    "c =summary_statistics1_lab.merge(summary_statistics1_lab2, on = ['DIAGNOSIS_CODE', 'PHENOTYPE', 'DIAGNOSIS_VALUE', 'PHENOTYPE_VALUE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary_statistics2.groupby(['PHEN_TXT', 'PHEN_LAB']).agg({'N': sum})\n",
    "c = summary_statistics2.merge(summary_statistics22, on = ['DIAGNOSIS_CODE', 'PHEN_TXT', 'PHEN_LAB', 'DIAGNOSIS_VALUE', 'PHEN_TXT_VALUE', 'PHEN_LAB_VALUE'] )\n",
    "#summary_statistics2.head()\n",
    "c.loc[c.N_x != c.N_y, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexDiagnosisTable():\n",
    "    cursor.execute(\"ALTER TABLE JAX_mf_diag ADD COLUMN ROW_ID INT AUTO_INCREMENT PRIMARY KEY;\")\n",
    "    \n",
    "def batch_query(start_index, end_index, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max):\n",
    "    \n",
    "    diagnosisVector = pd.read_sql_query('''\n",
    "        SELECT DIAGNOSIS FROM JAX_mf_diag WHERE ROW_ID BETWEEN {} AND {}\n",
    "    '''.format(start_index, end_index), mydb).reset_index().DIAGNOSIS.values.astype(int)\n",
    "    \n",
    "    textHpoFlat = pd.read_sql_query('''\n",
    "        WITH encounters AS (\n",
    "            SELECT SUBJECT_ID, HADM_ID\n",
    "            FROM JAX_mf_diag \n",
    "            WHERE ROW_ID BETWEEN {} AND {}\n",
    "        ), \n",
    "        textHpoOfInterest AS (\n",
    "            SELECT MAP_TO \n",
    "            FROM JAX_textHpoFrequencyRank \n",
    "            WHERE N BETWEEN {} AND {}\n",
    "        ), \n",
    "        joint as (\n",
    "            SELECT *\n",
    "            FROM encounters \n",
    "            JOIN textHpoOfInterest)\n",
    "        \n",
    "        SELECT IF(R.dummy IS NULL, 0, 1) AS VALUE\n",
    "        FROM joint as L\n",
    "        LEFT JOIN JAX_textHpoProfile AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.MAP_TO = R.MAP_TO\n",
    "    '''.format(start_index, end_index, textHpo_threshold_min, textHpo_threshold_max), mydb)\n",
    "    \n",
    "    labHpoFlat = pd.read_sql_query('''\n",
    "        WITH encounters AS (\n",
    "            SELECT SUBJECT_ID, HADM_ID\n",
    "            FROM JAX_mf_diag \n",
    "            WHERE ROW_ID BETWEEN {} AND {}\n",
    "        ), \n",
    "        labHpoOfInterest AS (\n",
    "            SELECT MAP_TO \n",
    "            FROM JAX_labHpoFrequencyRank \n",
    "            WHERE N BETWEEN {} AND {}\n",
    "        ), \n",
    "        joint as (\n",
    "            SELECT *\n",
    "            FROM encounters \n",
    "            JOIN labHpoOfInterest)\n",
    "        \n",
    "        SELECT IF(R.dummy IS NULL, 0, 1) AS VALUE\n",
    "        FROM joint as L\n",
    "        LEFT JOIN JAX_labHpoProfile AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.MAP_TO = R.MAP_TO\n",
    "    '''.format(start_index, end_index, labHpo_threshold_min, labHpo_threshold_max), mydb)\n",
    "    \n",
    "    return diagnosisVector, textHpoFlat.iloc[:,0].values.astype(int), labHpoFlat.iloc[:, 0].values.astype(int)\n",
    "\n",
    "def iterate_in_batch(diagnosis_threshold_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max, logger):\n",
    "    logger.info('starting iterate_in_batch()')\n",
    "    batch_size = 100\n",
    "    \n",
    "    # define a set of diseases that we want to analyze\n",
    "    rankICD()\n",
    "    \n",
    "    diseaseOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_diagFrequencyRank WHERE N > {}\".format(diagnosis_threshold_min), mydb).ICD9_CODE.values\n",
    "    #diseaseOfInterest = ['428']\n",
    "    logger.info('diagnosis of interest: {}'.format(len(diseaseOfInterest)))\n",
    "    \n",
    "    synergies = {}\n",
    "    \n",
    "    for diagnosis in diseaseOfInterest:\n",
    "        logger.info(\"start analyzing disease {}\".format(diagnosis))\n",
    "        \n",
    "        logger.info(\".......assigning values of diagnosis\")\n",
    "        # assign each encounter whether a diagnosis code is observed\n",
    "        # create a table j1 (joint 1)\n",
    "        createDiagnosisTable(diagnosis)\n",
    "        indexDiagnosisTable()\n",
    "        # for every diagnosis, find phenotypes of interest to look at from radiology reports\n",
    "        # for every diagnosis, find phenotypes of interest to look at from laboratory tests\n",
    "        rankHpoFromText(diagnosis)\n",
    "        rankHpoFromLab(diagnosis)\n",
    "        logger.info(\"..............diagnosis values found\")\n",
    "        \n",
    "        textHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_textHpoFrequencyRank WHERE N BETWEEN {} AND {}\".format(textHpo_threshold_min, textHpo_threshold_max), mydb).MAP_TO.values\n",
    "        labHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_labHpoFrequencyRank WHERE N BETWEEN {} AND {}\".format(labHpo_threshold_min, labHpo_threshold_max), mydb).MAP_TO.values\n",
    "        logger.info(\"TextHpo of interest established, size: {}\".format(len(textHpoOfInterest)))\n",
    "        logger.info(\"LabHpo of interest established, size: {}\".format(len(labHpoOfInterest)))\n",
    "\n",
    "        ## find the start and end ROW_ID for patient*encounter\n",
    "        ADM_ID_START, ADM_ID_END = pd.read_sql_query('SELECT MIN(ROW_ID) AS min, MAX(ROW_ID) AS max FROM JAX_mf_diag', mydb).iloc[0]\n",
    "        batch_N = ADM_ID_END - ADM_ID_START + 1\n",
    "        TOTAL_BATCH = math.ceil(batch_N / batch_size) # total number of batches\n",
    "        \n",
    "        synergies[diagnosis] = mf.Synergy2(diagnosis, textHpoOfInterest, labHpoOfInterest)\n",
    "        \n",
    "        logger.info('starting batch queries for {}'.format(diagnosis))\n",
    "        for i in np.arange(TOTAL_BATCH):\n",
    "            start_index = i * batch_size + ADM_ID_START\n",
    "            if i < TOTAL_BATCH - 1:\n",
    "                end_index = start_index + batch_size - 1\n",
    "            else:\n",
    "                end_index = batch_N\n",
    "\n",
    "            diagnosisVector, textHpoFlat, labHpoFlat =  batch_query(start_index, end_index, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max)\n",
    "\n",
    "            batch_size_actual = len(diagnosisVector)\n",
    "            textHpoOfInterest_size = len(textHpoOfInterest)\n",
    "            labHpoOfInterest_size = len(labHpoOfInterest)\n",
    "            assert(len(textHpoFlat) == batch_size_actual * textHpoOfInterest_size)\n",
    "            assert(len(labHpoFlat) == batch_size_actual * labHpoOfInterest_size)\n",
    "            \n",
    "            if batch_size_actual > 0 :\n",
    "                textHpoMatrix = textHpoFlat.reshape([batch_size_actual, textHpoOfInterest_size])\n",
    "                labHpoMatrix = labHpoFlat.reshape([batch_size_actual, labHpoOfInterest_size])\n",
    "                if i % 100 == 0:\n",
    "                    logger.info('new batch: start_index={}, end_index={}, batch_size= {}, textHpo_size = {}, labHpo_size = {}'.format(start_index, end_index, batch_size_actual, textHpoMatrix.shape[0], labHpoMatrix.shape[0]))\n",
    "                synergies[diagnosis].add_batch(textHpoMatrix,labHpoMatrix, diagnosisVector)\n",
    "    \n",
    "    return synergies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-23 14:44:26,951 - 4342 - root - INFO - starting iterate_in_batch()\n",
      "2019-09-23 14:44:28,160 - 4342 - root - INFO - diagnosis of interest: 48\n",
      "2019-09-23 14:44:28,161 - 4342 - root - INFO - start analyzing disease 401\n",
      "2019-09-23 14:44:28,162 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 14:45:21,778 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 14:45:21,789 - 4342 - root - INFO - TextHpo of interest established, size: 95\n",
      "2019-09-23 14:45:21,789 - 4342 - root - INFO - LabHpo of interest established, size: 140\n",
      "2019-09-23 14:45:21,800 - 4342 - root - INFO - starting batch queries for 401\n",
      "2019-09-23 14:45:22,251 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 14:45:53,703 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 14:46:23,191 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 14:46:53,805 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 14:47:29,119 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 14:48:06,132 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 14:48:36,549 - 4342 - root - INFO - start analyzing disease 427\n",
      "2019-09-23 14:48:36,550 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 14:49:31,579 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 14:49:31,590 - 4342 - root - INFO - TextHpo of interest established, size: 102\n",
      "2019-09-23 14:49:31,591 - 4342 - root - INFO - LabHpo of interest established, size: 145\n",
      "2019-09-23 14:49:31,601 - 4342 - root - INFO - starting batch queries for 427\n",
      "2019-09-23 14:49:32,822 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 14:50:08,052 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 14:50:42,014 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 14:51:17,199 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 14:51:54,213 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 14:52:32,308 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 14:53:04,149 - 4342 - root - INFO - start analyzing disease 276\n",
      "2019-09-23 14:53:04,150 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 14:53:56,723 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 14:53:56,739 - 4342 - root - INFO - TextHpo of interest established, size: 107\n",
      "2019-09-23 14:53:56,740 - 4342 - root - INFO - LabHpo of interest established, size: 153\n",
      "2019-09-23 14:53:56,750 - 4342 - root - INFO - starting batch queries for 276\n",
      "2019-09-23 14:53:57,572 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 14:54:37,059 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 14:55:14,146 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 14:55:51,745 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 14:56:31,906 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 14:57:15,014 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 14:57:50,752 - 4342 - root - INFO - start analyzing disease 272\n",
      "2019-09-23 14:57:50,752 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 14:58:38,561 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 14:58:38,570 - 4342 - root - INFO - TextHpo of interest established, size: 81\n",
      "2019-09-23 14:58:38,571 - 4342 - root - INFO - LabHpo of interest established, size: 131\n",
      "2019-09-23 14:58:38,575 - 4342 - root - INFO - starting batch queries for 272\n",
      "2019-09-23 14:58:39,541 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 14:59:11,321 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 14:59:40,281 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:00:08,655 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:00:39,491 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:01:13,738 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:01:41,629 - 4342 - root - INFO - start analyzing disease 414\n",
      "2019-09-23 15:01:41,630 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 15:02:29,099 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 15:02:29,109 - 4342 - root - INFO - TextHpo of interest established, size: 82\n",
      "2019-09-23 15:02:29,110 - 4342 - root - INFO - LabHpo of interest established, size: 131\n",
      "2019-09-23 15:02:29,120 - 4342 - root - INFO - starting batch queries for 414\n",
      "2019-09-23 15:02:29,614 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:03:00,659 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:03:29,815 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:03:58,413 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:04:29,517 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:05:03,653 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:05:32,322 - 4342 - root - INFO - start analyzing disease 250\n",
      "2019-09-23 15:05:32,322 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 15:06:16,973 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 15:06:16,987 - 4342 - root - INFO - TextHpo of interest established, size: 84\n",
      "2019-09-23 15:06:16,989 - 4342 - root - INFO - LabHpo of interest established, size: 140\n",
      "2019-09-23 15:06:17,000 - 4342 - root - INFO - starting batch queries for 250\n",
      "2019-09-23 15:06:17,494 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:06:49,480 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:07:18,131 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:07:48,004 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:08:20,003 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-23 15:08:54,786 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:09:23,000 - 4342 - root - INFO - start analyzing disease 428\n",
      "2019-09-23 15:09:23,001 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 15:10:10,531 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 15:10:10,543 - 4342 - root - INFO - TextHpo of interest established, size: 90\n",
      "2019-09-23 15:10:10,544 - 4342 - root - INFO - LabHpo of interest established, size: 141\n",
      "2019-09-23 15:10:10,554 - 4342 - root - INFO - starting batch queries for 428\n",
      "2019-09-23 15:10:10,981 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:10:42,841 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:11:11,572 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:11:40,612 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:12:13,509 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:12:47,803 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:13:16,410 - 4342 - root - INFO - start analyzing disease 518\n",
      "2019-09-23 15:13:16,411 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 15:14:06,734 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 15:14:06,748 - 4342 - root - INFO - TextHpo of interest established, size: 117\n",
      "2019-09-23 15:14:06,749 - 4342 - root - INFO - LabHpo of interest established, size: 159\n",
      "2019-09-23 15:14:06,755 - 4342 - root - INFO - starting batch queries for 518\n",
      "2019-09-23 15:14:07,701 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:14:45,203 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:15:20,624 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:15:56,962 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:16:35,270 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:17:18,322 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:17:53,041 - 4342 - root - INFO - start analyzing disease 285\n",
      "2019-09-23 15:17:53,042 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 15:18:37,971 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 15:18:37,981 - 4342 - root - INFO - TextHpo of interest established, size: 89\n",
      "2019-09-23 15:18:37,982 - 4342 - root - INFO - LabHpo of interest established, size: 141\n",
      "2019-09-23 15:18:37,992 - 4342 - root - INFO - starting batch queries for 285\n",
      "2019-09-23 15:18:38,473 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:19:11,072 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:19:40,271 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:20:10,390 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:20:42,898 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:21:18,100 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:21:47,386 - 4342 - root - INFO - start analyzing disease 584\n",
      "2019-09-23 15:21:47,386 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 15:22:33,675 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 15:22:33,684 - 4342 - root - INFO - TextHpo of interest established, size: 100\n",
      "2019-09-23 15:22:33,685 - 4342 - root - INFO - LabHpo of interest established, size: 156\n",
      "2019-09-23 15:22:33,689 - 4342 - root - INFO - starting batch queries for 584\n",
      "2019-09-23 15:22:34,153 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:23:10,394 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:23:42,853 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:24:15,933 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:24:51,383 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:25:31,718 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:26:04,549 - 4342 - root - INFO - start analyzing disease V45\n",
      "2019-09-23 15:26:04,549 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 15:26:39,031 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 15:26:39,040 - 4342 - root - INFO - TextHpo of interest established, size: 76\n",
      "2019-09-23 15:26:39,041 - 4342 - root - INFO - LabHpo of interest established, size: 126\n",
      "2019-09-23 15:26:39,048 - 4342 - root - INFO - starting batch queries for V45\n",
      "2019-09-23 15:26:40,479 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:27:08,622 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:27:35,975 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:28:03,791 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:28:33,686 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:29:06,427 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:29:35,368 - 4342 - root - INFO - start analyzing disease 530\n",
      "2019-09-23 15:29:35,369 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 15:30:07,623 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 15:30:07,633 - 4342 - root - INFO - TextHpo of interest established, size: 63\n",
      "2019-09-23 15:30:07,634 - 4342 - root - INFO - LabHpo of interest established, size: 112\n",
      "2019-09-23 15:30:07,641 - 4342 - root - INFO - starting batch queries for 530\n",
      "2019-09-23 15:30:08,053 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:30:34,737 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:30:59,291 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:31:24,319 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:31:48,975 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-23 15:32:18,221 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:32:42,565 - 4342 - root - INFO - start analyzing disease 599\n",
      "2019-09-23 15:32:42,566 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 15:33:17,728 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 15:33:17,738 - 4342 - root - INFO - TextHpo of interest established, size: 78\n",
      "2019-09-23 15:33:17,739 - 4342 - root - INFO - LabHpo of interest established, size: 132\n",
      "2019-09-23 15:33:17,749 - 4342 - root - INFO - starting batch queries for 599\n",
      "2019-09-23 15:33:18,183 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:33:50,029 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:34:18,071 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:34:46,505 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:35:17,353 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:35:51,594 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:36:20,291 - 4342 - root - INFO - start analyzing disease V58\n",
      "2019-09-23 15:36:20,291 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 15:36:50,865 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 15:36:50,874 - 4342 - root - INFO - TextHpo of interest established, size: 67\n",
      "2019-09-23 15:36:50,875 - 4342 - root - INFO - LabHpo of interest established, size: 123\n",
      "2019-09-23 15:36:50,884 - 4342 - root - INFO - starting batch queries for V58\n",
      "2019-09-23 15:36:51,346 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:37:20,127 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:37:45,819 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:38:10,950 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:38:38,015 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:39:10,191 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:39:38,632 - 4342 - root - INFO - start analyzing disease 585\n",
      "2019-09-23 15:39:38,633 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 15:40:10,592 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 15:40:10,603 - 4342 - root - INFO - TextHpo of interest established, size: 75\n",
      "2019-09-23 15:40:10,604 - 4342 - root - INFO - LabHpo of interest established, size: 128\n",
      "2019-09-23 15:40:10,610 - 4342 - root - INFO - starting batch queries for 585\n",
      "2019-09-23 15:40:11,086 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:40:42,352 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:41:10,266 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:41:38,549 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:42:08,536 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:42:41,568 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:43:09,550 - 4342 - root - INFO - start analyzing disease 403\n",
      "2019-09-23 15:43:09,550 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 15:43:40,118 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 15:43:40,128 - 4342 - root - INFO - TextHpo of interest established, size: 68\n",
      "2019-09-23 15:43:40,129 - 4342 - root - INFO - LabHpo of interest established, size: 124\n",
      "2019-09-23 15:43:40,139 - 4342 - root - INFO - starting batch queries for 403\n",
      "2019-09-23 15:43:41,594 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:44:09,516 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:44:36,459 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:45:03,532 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:45:32,698 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:46:05,231 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:46:32,006 - 4342 - root - INFO - start analyzing disease V10\n",
      "2019-09-23 15:46:32,006 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 15:46:58,205 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 15:46:58,214 - 4342 - root - INFO - TextHpo of interest established, size: 58\n",
      "2019-09-23 15:46:58,215 - 4342 - root - INFO - LabHpo of interest established, size: 111\n",
      "2019-09-23 15:46:58,222 - 4342 - root - INFO - starting batch queries for V10\n",
      "2019-09-23 15:46:58,624 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:47:24,449 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:47:49,076 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:48:12,909 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:48:39,277 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:49:08,672 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:49:33,318 - 4342 - root - INFO - start analyzing disease V30\n",
      "2019-09-23 15:49:33,319 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 15:49:42,643 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 15:49:42,649 - 4342 - root - INFO - TextHpo of interest established, size: 5\n",
      "2019-09-23 15:49:42,650 - 4342 - root - INFO - LabHpo of interest established, size: 16\n",
      "2019-09-23 15:49:42,653 - 4342 - root - INFO - starting batch queries for V30\n",
      "2019-09-23 15:49:42,717 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:49:49,569 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:49:56,989 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:50:04,982 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:50:14,120 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-23 15:50:23,239 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:50:31,479 - 4342 - root - INFO - start analyzing disease 038\n",
      "2019-09-23 15:50:31,480 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 15:51:06,355 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 15:51:06,369 - 4342 - root - INFO - TextHpo of interest established, size: 83\n",
      "2019-09-23 15:51:06,370 - 4342 - root - INFO - LabHpo of interest established, size: 148\n",
      "2019-09-23 15:51:06,380 - 4342 - root - INFO - starting batch queries for 038\n",
      "2019-09-23 15:51:06,903 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:51:40,519 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:52:11,284 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:52:43,361 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:53:17,374 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:53:54,957 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:54:26,563 - 4342 - root - INFO - start analyzing disease V05\n",
      "2019-09-23 15:54:26,563 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 15:54:35,889 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 15:54:35,895 - 4342 - root - INFO - TextHpo of interest established, size: 5\n",
      "2019-09-23 15:54:35,896 - 4342 - root - INFO - LabHpo of interest established, size: 16\n",
      "2019-09-23 15:54:35,899 - 4342 - root - INFO - starting batch queries for V05\n",
      "2019-09-23 15:54:36,158 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:54:43,243 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:54:51,747 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:55:00,418 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:55:10,095 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:55:19,501 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:55:28,156 - 4342 - root - INFO - start analyzing disease V29\n",
      "2019-09-23 15:55:28,157 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 15:55:35,201 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 15:55:35,210 - 4342 - root - INFO - TextHpo of interest established, size: 5\n",
      "2019-09-23 15:55:35,211 - 4342 - root - INFO - LabHpo of interest established, size: 19\n",
      "2019-09-23 15:55:35,216 - 4342 - root - INFO - starting batch queries for V29\n",
      "2019-09-23 15:55:35,306 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:55:42,187 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:55:50,821 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:55:59,626 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:56:09,944 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:56:20,107 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:56:29,162 - 4342 - root - INFO - start analyzing disease 995\n",
      "2019-09-23 15:56:29,163 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 15:57:01,700 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 15:57:01,710 - 4342 - root - INFO - TextHpo of interest established, size: 80\n",
      "2019-09-23 15:57:01,711 - 4342 - root - INFO - LabHpo of interest established, size: 145\n",
      "2019-09-23 15:57:01,721 - 4342 - root - INFO - starting batch queries for 995\n",
      "2019-09-23 15:57:02,244 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:57:35,426 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:58:05,731 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:58:36,739 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:59:09,419 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 15:59:44,650 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:00:14,934 - 4342 - root - INFO - start analyzing disease 424\n",
      "2019-09-23 16:00:14,935 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 16:00:41,522 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 16:00:41,532 - 4342 - root - INFO - TextHpo of interest established, size: 51\n",
      "2019-09-23 16:00:41,533 - 4342 - root - INFO - LabHpo of interest established, size: 105\n",
      "2019-09-23 16:00:41,543 - 4342 - root - INFO - starting batch queries for 424\n",
      "2019-09-23 16:00:41,891 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:01:06,809 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:01:29,243 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:01:51,890 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:02:16,869 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:02:45,064 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:03:08,688 - 4342 - root - INFO - start analyzing disease 780\n",
      "2019-09-23 16:03:08,689 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 16:03:35,758 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 16:03:35,767 - 4342 - root - INFO - TextHpo of interest established, size: 59\n",
      "2019-09-23 16:03:35,768 - 4342 - root - INFO - LabHpo of interest established, size: 109\n",
      "2019-09-23 16:03:35,775 - 4342 - root - INFO - starting batch queries for 780\n",
      "2019-09-23 16:03:36,195 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:04:02,768 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:04:26,402 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:04:50,469 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:05:17,258 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-23 16:05:46,047 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:06:10,428 - 4342 - root - INFO - start analyzing disease 410\n",
      "2019-09-23 16:06:10,429 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 16:06:38,431 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 16:06:38,441 - 4342 - root - INFO - TextHpo of interest established, size: 57\n",
      "2019-09-23 16:06:38,442 - 4342 - root - INFO - LabHpo of interest established, size: 107\n",
      "2019-09-23 16:06:38,451 - 4342 - root - INFO - starting batch queries for 410\n",
      "2019-09-23 16:06:38,828 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:07:05,977 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:07:27,420 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:07:51,260 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:08:17,800 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:08:46,084 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:09:09,940 - 4342 - root - INFO - start analyzing disease 785\n",
      "2019-09-23 16:09:09,941 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 16:09:41,139 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 16:09:41,147 - 4342 - root - INFO - TextHpo of interest established, size: 74\n",
      "2019-09-23 16:09:41,147 - 4342 - root - INFO - LabHpo of interest established, size: 135\n",
      "2019-09-23 16:09:41,156 - 4342 - root - INFO - starting batch queries for 785\n",
      "2019-09-23 16:09:42,484 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:10:12,393 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:10:38,451 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:11:07,588 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:11:38,907 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:12:13,046 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:12:42,950 - 4342 - root - INFO - start analyzing disease 244\n",
      "2019-09-23 16:12:42,950 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 16:13:07,919 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 16:13:07,930 - 4342 - root - INFO - TextHpo of interest established, size: 50\n",
      "2019-09-23 16:13:07,931 - 4342 - root - INFO - LabHpo of interest established, size: 106\n",
      "2019-09-23 16:13:07,938 - 4342 - root - INFO - starting batch queries for 244\n",
      "2019-09-23 16:13:08,382 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:13:34,280 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:13:57,084 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:14:20,288 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:14:45,898 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:15:13,563 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:15:37,397 - 4342 - root - INFO - start analyzing disease 305\n",
      "2019-09-23 16:15:37,397 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 16:16:01,222 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 16:16:01,232 - 4342 - root - INFO - TextHpo of interest established, size: 48\n",
      "2019-09-23 16:16:01,233 - 4342 - root - INFO - LabHpo of interest established, size: 99\n",
      "2019-09-23 16:16:01,240 - 4342 - root - INFO - starting batch queries for 305\n",
      "2019-09-23 16:16:01,625 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:16:26,893 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:16:49,674 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:17:12,516 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:17:37,525 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:18:04,957 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:18:28,012 - 4342 - root - INFO - start analyzing disease 997\n",
      "2019-09-23 16:18:28,013 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 16:18:59,177 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 16:18:59,188 - 4342 - root - INFO - TextHpo of interest established, size: 69\n",
      "2019-09-23 16:18:59,189 - 4342 - root - INFO - LabHpo of interest established, size: 110\n",
      "2019-09-23 16:18:59,198 - 4342 - root - INFO - starting batch queries for 997\n",
      "2019-09-23 16:18:59,591 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:19:27,755 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:19:53,152 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:20:19,364 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:20:47,593 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:21:18,457 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:21:44,714 - 4342 - root - INFO - start analyzing disease 998\n",
      "2019-09-23 16:21:44,715 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 16:22:14,689 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 16:22:14,699 - 4342 - root - INFO - TextHpo of interest established, size: 61\n",
      "2019-09-23 16:22:14,700 - 4342 - root - INFO - LabHpo of interest established, size: 115\n",
      "2019-09-23 16:22:14,706 - 4342 - root - INFO - starting batch queries for 998\n",
      "2019-09-23 16:22:15,142 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:22:43,185 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:23:08,573 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:23:34,220 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:24:01,571 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-23 16:24:31,332 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:24:57,478 - 4342 - root - INFO - start analyzing disease 458\n",
      "2019-09-23 16:24:57,479 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 16:25:22,538 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 16:25:22,548 - 4342 - root - INFO - TextHpo of interest established, size: 55\n",
      "2019-09-23 16:25:22,549 - 4342 - root - INFO - LabHpo of interest established, size: 106\n",
      "2019-09-23 16:25:22,558 - 4342 - root - INFO - starting batch queries for 458\n",
      "2019-09-23 16:25:22,976 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:25:48,549 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:26:10,944 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:26:33,465 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:26:57,824 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:27:24,769 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:27:46,204 - 4342 - root - INFO - start analyzing disease 486\n",
      "2019-09-23 16:27:46,205 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 16:28:06,576 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 16:28:06,583 - 4342 - root - INFO - TextHpo of interest established, size: 64\n",
      "2019-09-23 16:28:06,584 - 4342 - root - INFO - LabHpo of interest established, size: 125\n",
      "2019-09-23 16:28:06,593 - 4342 - root - INFO - starting batch queries for 486\n",
      "2019-09-23 16:28:06,880 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:28:34,854 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:29:01,204 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:29:27,215 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:29:55,335 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:30:26,635 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:30:53,893 - 4342 - root - INFO - start analyzing disease V15\n",
      "2019-09-23 16:30:53,893 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 16:31:14,280 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 16:31:14,289 - 4342 - root - INFO - TextHpo of interest established, size: 44\n",
      "2019-09-23 16:31:14,290 - 4342 - root - INFO - LabHpo of interest established, size: 92\n",
      "2019-09-23 16:31:14,299 - 4342 - root - INFO - starting batch queries for V15\n",
      "2019-09-23 16:31:14,714 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:31:38,863 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:32:00,397 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:32:21,610 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:32:44,819 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:33:11,070 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:33:33,249 - 4342 - root - INFO - start analyzing disease 041\n",
      "2019-09-23 16:33:33,250 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 16:33:59,902 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 16:33:59,912 - 4342 - root - INFO - TextHpo of interest established, size: 67\n",
      "2019-09-23 16:33:59,912 - 4342 - root - INFO - LabHpo of interest established, size: 121\n",
      "2019-09-23 16:33:59,920 - 4342 - root - INFO - starting batch queries for 041\n",
      "2019-09-23 16:34:01,308 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:34:29,536 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:34:55,990 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:35:23,115 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:35:52,078 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:36:25,270 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:36:53,288 - 4342 - root - INFO - start analyzing disease 496\n",
      "2019-09-23 16:36:53,289 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 16:37:15,191 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 16:37:15,200 - 4342 - root - INFO - TextHpo of interest established, size: 48\n",
      "2019-09-23 16:37:15,201 - 4342 - root - INFO - LabHpo of interest established, size: 95\n",
      "2019-09-23 16:37:15,207 - 4342 - root - INFO - starting batch queries for 496\n",
      "2019-09-23 16:37:15,604 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:37:40,556 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:38:01,707 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:38:23,343 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:38:47,831 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:39:14,084 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:39:37,109 - 4342 - root - INFO - start analyzing disease 996\n",
      "2019-09-23 16:39:37,110 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 16:40:05,667 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 16:40:05,676 - 4342 - root - INFO - TextHpo of interest established, size: 59\n",
      "2019-09-23 16:40:05,677 - 4342 - root - INFO - LabHpo of interest established, size: 116\n",
      "2019-09-23 16:40:05,684 - 4342 - root - INFO - starting batch queries for 996\n",
      "2019-09-23 16:40:06,082 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:40:34,981 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:41:00,719 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:41:25,924 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:41:54,560 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-23 16:42:23,511 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:42:48,730 - 4342 - root - INFO - start analyzing disease E878\n",
      "2019-09-23 16:42:48,731 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 16:43:09,408 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 16:43:09,418 - 4342 - root - INFO - TextHpo of interest established, size: 53\n",
      "2019-09-23 16:43:09,419 - 4342 - root - INFO - LabHpo of interest established, size: 98\n",
      "2019-09-23 16:43:09,425 - 4342 - root - INFO - starting batch queries for E878\n",
      "2019-09-23 16:43:09,842 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:43:36,019 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:44:04,974 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:44:30,875 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:44:55,647 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:45:23,604 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:45:46,754 - 4342 - root - INFO - start analyzing disease 287\n",
      "2019-09-23 16:45:46,754 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 16:46:13,493 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 16:46:13,502 - 4342 - root - INFO - TextHpo of interest established, size: 53\n",
      "2019-09-23 16:46:13,503 - 4342 - root - INFO - LabHpo of interest established, size: 116\n",
      "2019-09-23 16:46:13,513 - 4342 - root - INFO - starting batch queries for 287\n",
      "2019-09-23 16:46:14,986 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:46:40,228 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:47:03,487 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:47:28,088 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:47:52,884 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:48:19,148 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:48:43,008 - 4342 - root - INFO - start analyzing disease V12\n",
      "2019-09-23 16:48:43,009 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 16:49:01,415 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 16:49:01,426 - 4342 - root - INFO - TextHpo of interest established, size: 45\n",
      "2019-09-23 16:49:01,427 - 4342 - root - INFO - LabHpo of interest established, size: 84\n",
      "2019-09-23 16:49:01,434 - 4342 - root - INFO - starting batch queries for V12\n",
      "2019-09-23 16:49:01,821 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:49:24,653 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:49:44,981 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:50:04,087 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:50:27,027 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:50:52,335 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:51:13,953 - 4342 - root - INFO - start analyzing disease 790\n",
      "2019-09-23 16:51:13,954 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 16:51:37,326 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 16:51:37,337 - 4342 - root - INFO - TextHpo of interest established, size: 50\n",
      "2019-09-23 16:51:37,338 - 4342 - root - INFO - LabHpo of interest established, size: 106\n",
      "2019-09-23 16:51:37,345 - 4342 - root - INFO - starting batch queries for 790\n",
      "2019-09-23 16:51:37,879 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:52:03,524 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:52:26,611 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:52:49,729 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:53:15,510 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:53:42,961 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:54:05,190 - 4342 - root - INFO - start analyzing disease 507\n",
      "2019-09-23 16:54:05,190 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 16:54:27,009 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 16:54:27,019 - 4342 - root - INFO - TextHpo of interest established, size: 58\n",
      "2019-09-23 16:54:27,020 - 4342 - root - INFO - LabHpo of interest established, size: 110\n",
      "2019-09-23 16:54:27,028 - 4342 - root - INFO - starting batch queries for 507\n",
      "2019-09-23 16:54:27,407 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:54:52,822 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:55:14,663 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:55:39,168 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:56:05,179 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:56:34,432 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:56:58,961 - 4342 - root - INFO - start analyzing disease 493\n",
      "2019-09-23 16:56:58,961 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 16:57:17,180 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 16:57:17,190 - 4342 - root - INFO - TextHpo of interest established, size: 36\n",
      "2019-09-23 16:57:17,191 - 4342 - root - INFO - LabHpo of interest established, size: 75\n",
      "2019-09-23 16:57:17,199 - 4342 - root - INFO - starting batch queries for 493\n",
      "2019-09-23 16:57:17,559 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:57:39,452 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:57:59,319 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:58:19,615 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:58:40,126 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-23 16:59:04,238 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 16:59:24,796 - 4342 - root - INFO - start analyzing disease 311\n",
      "2019-09-23 16:59:24,796 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 16:59:42,331 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 16:59:42,340 - 4342 - root - INFO - TextHpo of interest established, size: 36\n",
      "2019-09-23 16:59:42,341 - 4342 - root - INFO - LabHpo of interest established, size: 75\n",
      "2019-09-23 16:59:42,351 - 4342 - root - INFO - starting batch queries for 311\n",
      "2019-09-23 16:59:42,704 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:00:04,455 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:00:21,901 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:00:40,652 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:01:02,107 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:01:25,471 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:01:46,198 - 4342 - root - INFO - start analyzing disease 765\n",
      "2019-09-23 17:01:46,199 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 17:01:56,681 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 17:01:56,688 - 4342 - root - INFO - TextHpo of interest established, size: 10\n",
      "2019-09-23 17:01:56,689 - 4342 - root - INFO - LabHpo of interest established, size: 24\n",
      "2019-09-23 17:01:56,693 - 4342 - root - INFO - starting batch queries for 765\n",
      "2019-09-23 17:01:57,038 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:02:05,593 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:02:15,133 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:02:24,987 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:02:36,236 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:02:47,663 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:02:59,749 - 4342 - root - INFO - start analyzing disease 412\n",
      "2019-09-23 17:02:59,750 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 17:03:17,419 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 17:03:17,429 - 4342 - root - INFO - TextHpo of interest established, size: 35\n",
      "2019-09-23 17:03:17,431 - 4342 - root - INFO - LabHpo of interest established, size: 76\n",
      "2019-09-23 17:03:17,437 - 4342 - root - INFO - starting batch queries for 412\n",
      "2019-09-23 17:03:17,745 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:03:39,805 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:03:59,845 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:04:19,281 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:04:40,740 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:05:02,614 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:05:23,870 - 4342 - root - INFO - start analyzing disease 511\n",
      "2019-09-23 17:05:23,871 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 17:05:47,508 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 17:05:47,515 - 4342 - root - INFO - TextHpo of interest established, size: 56\n",
      "2019-09-23 17:05:47,516 - 4342 - root - INFO - LabHpo of interest established, size: 95\n",
      "2019-09-23 17:05:47,522 - 4342 - root - INFO - starting batch queries for 511\n",
      "2019-09-23 17:05:47,870 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:06:12,958 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:06:33,970 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:06:53,398 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:07:18,169 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:07:45,662 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:08:09,369 - 4342 - root - INFO - start analyzing disease 348\n",
      "2019-09-23 17:08:09,370 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 17:08:27,018 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 17:08:27,024 - 4342 - root - INFO - TextHpo of interest established, size: 50\n",
      "2019-09-23 17:08:27,025 - 4342 - root - INFO - LabHpo of interest established, size: 87\n",
      "2019-09-23 17:08:27,033 - 4342 - root - INFO - starting batch queries for 348\n",
      "2019-09-23 17:08:27,410 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:08:53,078 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:09:14,254 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:09:35,112 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:09:58,148 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:10:23,856 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:10:46,311 - 4342 - root - INFO - start analyzing disease 707\n",
      "2019-09-23 17:10:46,312 - 4342 - root - INFO - .......assigning values of diagnosis\n",
      "2019-09-23 17:11:06,994 - 4342 - root - INFO - ..............diagnosis values found\n",
      "2019-09-23 17:11:07,003 - 4342 - root - INFO - TextHpo of interest established, size: 51\n",
      "2019-09-23 17:11:07,004 - 4342 - root - INFO - LabHpo of interest established, size: 95\n",
      "2019-09-23 17:11:07,014 - 4342 - root - INFO - starting batch queries for 707\n",
      "2019-09-23 17:11:07,557 - 4342 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:11:30,527 - 4342 - root - INFO - new batch: start_index=10001, end_index=10100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:11:52,862 - 4342 - root - INFO - new batch: start_index=20001, end_index=20100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:12:15,218 - 4342 - root - INFO - new batch: start_index=30001, end_index=30100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n",
      "2019-09-23 17:12:39,304 - 4342 - root - INFO - new batch: start_index=40001, end_index=40100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-23 17:13:05,698 - 4342 - root - INFO - new batch: start_index=50001, end_index=50100, batch_size= 100, textHpo_size = 100, labHpo_size = 100\n"
     ]
    }
   ],
   "source": [
    "# how to run this\n",
    "# Again, it take either too long or too much memory space to run\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# 1. build the temp tables for Lab converted HPO, Text convert HPO\n",
    "# Read the comments within the method!\n",
    "initTables(debug=False)\n",
    "\n",
    "# 2. iterate throw the dataset\n",
    "diagnosis_threshold_min = 3000\n",
    "textHpo_threshold_min, textHpo_threshold_max = 500, 100000\n",
    "labHpo_threshold_min, labHpo_threshold_max = 1000, 100000\n",
    "# for test only\n",
    "#diagnosis_threshold_min = 5\n",
    "#textHpo_threshold_min, textHpo_threshold_max = 10, 100\n",
    "#labHpo_threshold_min, labHpo_threshold_max = 10, 100\n",
    "\n",
    "logger = logger\n",
    "synergies = iterate_in_batch(diagnosis_threshold_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('synergies_radiology_lab.obj', 'wb') as synergies_file:\n",
    "    pickle.dump(synergies, synergies_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>synergy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>HP:0012252</td>\n",
       "      <td>HP:0031851</td>\n",
       "      <td>0.000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>HP:0012639</td>\n",
       "      <td>HP:0010927</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>HP:0002103</td>\n",
       "      <td>HP:0003113</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>HP:0001438</td>\n",
       "      <td>HP:0001943</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>HP:0100763</td>\n",
       "      <td>HP:0001928</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>HP:0025033</td>\n",
       "      <td>HP:0001943</td>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>HP:0025032</td>\n",
       "      <td>HP:0032251</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>HP:0011028</td>\n",
       "      <td>HP:0012116</td>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>HP:0100790</td>\n",
       "      <td>HP:0003113</td>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>HP:0100763</td>\n",
       "      <td>HP:0003155</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>HP:0011947</td>\n",
       "      <td>HP:0001872</td>\n",
       "      <td>0.000101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>HP:0001945</td>\n",
       "      <td>HP:0410288</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>HP:0000079</td>\n",
       "      <td>HP:0004379</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>HP:0012718</td>\n",
       "      <td>HP:0032251</td>\n",
       "      <td>0.000099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>HP:0012252</td>\n",
       "      <td>HP:0001928</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>HP:0001892</td>\n",
       "      <td>HP:0032239</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>HP:0002835</td>\n",
       "      <td>HP:0020059</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>HP:0002242</td>\n",
       "      <td>HP:0001939</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>HP:0000119</td>\n",
       "      <td>HP:0004363</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>HP:0011032</td>\n",
       "      <td>HP:0001882</td>\n",
       "      <td>0.000092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            P1          P2   synergy\n",
       "0   HP:0012252  HP:0031851  0.000148\n",
       "1   HP:0012639  HP:0010927  0.000131\n",
       "2   HP:0002103  HP:0003113  0.000117\n",
       "3   HP:0001438  HP:0001943  0.000117\n",
       "4   HP:0100763  HP:0001928  0.000110\n",
       "5   HP:0025033  HP:0001943  0.000108\n",
       "6   HP:0025032  HP:0032251  0.000107\n",
       "7   HP:0011028  HP:0012116  0.000105\n",
       "8   HP:0100790  HP:0003113  0.000105\n",
       "9   HP:0100763  HP:0003155  0.000104\n",
       "10  HP:0011947  HP:0001872  0.000101\n",
       "11  HP:0001945  HP:0410288  0.000100\n",
       "12  HP:0000079  HP:0004379  0.000100\n",
       "13  HP:0012718  HP:0032251  0.000099\n",
       "14  HP:0012252  HP:0001928  0.000096\n",
       "15  HP:0001892  HP:0032239  0.000095\n",
       "16  HP:0002835  HP:0020059  0.000095\n",
       "17  HP:0002242  HP:0001939  0.000093\n",
       "18  HP:0000119  HP:0004363  0.000093\n",
       "19  HP:0011032  HP:0001882  0.000092"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_attack = synergies['584']\n",
    "heart_attack.pairwise_synergy_labeled().head(n = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 141)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "encounterOfInterest(debug=False)\n",
    "indexEncounterOfInterest()\n",
    "diagnosisProfile()\n",
    "rankICD()\n",
    "diagnosis = '401'\n",
    "rankHpoFromText(diagnosis)\n",
    "rankHpoFromLab(diagnosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>401</td>\n",
       "      <td>21305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>427</td>\n",
       "      <td>17226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>276</td>\n",
       "      <td>15101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>272</td>\n",
       "      <td>14558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>414</td>\n",
       "      <td>14410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>250</td>\n",
       "      <td>14222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>428</td>\n",
       "      <td>13608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>518</td>\n",
       "      <td>13346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>285</td>\n",
       "      <td>12606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>584</td>\n",
       "      <td>11422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ICD9_CODE      N\n",
       "0       401  21305\n",
       "1       427  17226\n",
       "2       276  15101\n",
       "3       272  14558\n",
       "4       414  14410\n",
       "5       250  14222\n",
       "6       428  13608\n",
       "7       518  13346\n",
       "8       285  12606\n",
       "9       584  11422"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query(\"SELECT * FROM JAX_diagFrequencyRank WHERE N > 10000\", mydb)\n",
    "#pd.read_sql_query(\"SELECT count(*) FROM JAX_diagnosisProfile LIMIT 4\", mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAP_TO</th>\n",
       "      <th>N</th>\n",
       "      <th>PHENOTYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>HP:0001939</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>HP:0000118</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>HP:0000001</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>HP:0001871</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MAP_TO   N  PHENOTYPE\n",
       "0  HP:0001939  30          1\n",
       "1  HP:0000118  30          1\n",
       "2  HP:0000001  30          1\n",
       "3  HP:0001871  30          1"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query(\"SELECT * FROM JAX_labHpoFrequencyRank LIMIT 4\", mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAP_TO</th>\n",
       "      <th>N</th>\n",
       "      <th>PHENOTYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>HP:0000118</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>HP:0000001</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>HP:0002086</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>HP:0002088</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MAP_TO   N  PHENOTYPE\n",
       "0  HP:0000118  31          1\n",
       "1  HP:0000001  31          1\n",
       "2  HP:0002086  23          1\n",
       "3  HP:0002088  20          1"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query(\"SELECT * FROM JAX_textHpoFrequencyRank LIMIT 4\", mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>DIAGNOSIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>185777</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>178980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>107064</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>94</td>\n",
       "      <td>140037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>94</td>\n",
       "      <td>183686</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>160891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>96</td>\n",
       "      <td>170324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>97</td>\n",
       "      <td>127870</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SUBJECT_ID  HADM_ID DIAGNOSIS\n",
       "0            2   163353         0\n",
       "1            3   145834         0\n",
       "2            4   185777         0\n",
       "3            5   178980         0\n",
       "4            6   107064         0\n",
       "..         ...      ...       ...\n",
       "95          94   140037         1\n",
       "96          94   183686         1\n",
       "97          95   160891         0\n",
       "98          96   170324         0\n",
       "99          97   127870         1\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createDiagnosisTable(diagnosis)\n",
    "pd.read_sql_query(\"SELECT * FROM JAX_mf_diag\", mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>DIAGNOSIS</th>\n",
       "      <th>ROW_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>185777</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>178980</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>107064</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>94</td>\n",
       "      <td>183686</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>94</td>\n",
       "      <td>140037</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>160891</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>96</td>\n",
       "      <td>170324</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>97</td>\n",
       "      <td>127870</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SUBJECT_ID  HADM_ID DIAGNOSIS  ROW_ID\n",
       "0            2   163353         0       1\n",
       "1            3   145834         0       2\n",
       "2            4   185777         0       3\n",
       "3            5   178980         0       4\n",
       "4            6   107064         0       5\n",
       "..         ...      ...       ...     ...\n",
       "95          94   183686         1      96\n",
       "96          94   140037         1      97\n",
       "97          95   160891         0      98\n",
       "98          96   170324         0      99\n",
       "99          97   127870         1     100\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexDiagnosisTable()\n",
    "pd.read_sql_query(\"SELECT * FROM JAX_mf_diag\", mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     1\n",
       "8     0\n",
       "9     0\n",
       "10    1\n",
       "11    1\n",
       "12    0\n",
       "13    0\n",
       "14    0\n",
       "15    1\n",
       "16    1\n",
       "17    1\n",
       "18    0\n",
       "19    0\n",
       "20    1\n",
       "21    1\n",
       "22    1\n",
       "23    0\n",
       "24    1\n",
       "Name: DIAGNOSIS, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query('''\n",
    "        SELECT DIAGNOSIS FROM JAX_mf_diag WHERE ROW_ID BETWEEN {} AND {}\n",
    "    '''.format(1, 25), mydb).reset_index().DIAGNOSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "14895    0\n",
       "14896    0\n",
       "14897    1\n",
       "14898    0\n",
       "14899    0\n",
       "Name: VALUE, Length: 14900, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_index, end_index, labHpo_threshold_min, labHpo_threshold_max = 0, 100, 0, 100\n",
    "pd.read_sql_query('''\n",
    "        WITH encounters AS (\n",
    "            SELECT SUBJECT_ID, HADM_ID\n",
    "            FROM JAX_mf_diag \n",
    "            WHERE ROW_ID BETWEEN {} AND {}\n",
    "        ), \n",
    "        labHpoOfInterest AS (\n",
    "            SELECT MAP_TO \n",
    "            FROM JAX_labHpoFrequencyRank \n",
    "            WHERE N BETWEEN {} AND {}\n",
    "        ), \n",
    "        joint as (\n",
    "            SELECT *\n",
    "            FROM encounters \n",
    "            JOIN labHpoOfInterest)\n",
    "        \n",
    "        SELECT IF(R.dummy IS NULL, 0, 1) AS VALUE\n",
    "        FROM joint as L\n",
    "        LEFT JOIN JAX_labHpoProfile AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.MAP_TO = R.MAP_TO\n",
    "    '''.format(start_index, end_index, labHpo_threshold_min, labHpo_threshold_max), mydb).iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosisTextHpo(phenotype='HP:0002086')\n",
    "result = pd.read_sql_query(\"SELECT '{}' AS DIAGNOSIS_CODE, '{}' AS PHENOTYPE, DIAGNOSIS AS DIAGNOSIS_VALUE, PHEN_TXT_VALUE AS PHENOTYPE_VALUE, COUNT(*) AS N FROM JAX_mf_diag_textHpo GROUP BY DIAGNOSIS, PHEN_TXT_VALUE\", mydb)\n",
    "result.head()\n",
    "#result.groupby(['DIAGNOSIS', 'PHEN_TXT_VALUE'])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosisAllTextHpo(0, 100)\n",
    "pd.read_sql_query(\"SELECT * FROM JAX_mf_diag_allTextHpo WHERE PHEN_TXT_VALUE = 1 LIMIT 5\", mydb)\n",
    "#result = pd.read_sql_query(\"SELECT '{}' AS DIAGNOSIS_CODE, PHEN_TXT AS PHENOTYPE, DIAGNOSIS AS DIAGNOSIS_VALUE, PHEN_TXT_VALUE AS PHENOTYPE_VALUE, COUNT(*) AS N FROM JAX_mf_diag_allTextHpo GROUP BY DIAGNOSIS, PHEN_TXT, PHEN_TXT_VALUE\", mydb)\n",
    "#result.groupby(['PHENOTYPE']).agg({'N':sum})\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "mydb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
