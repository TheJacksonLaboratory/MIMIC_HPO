{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "mf_module_path = os.path.abspath(os.path.join('../python'))\n",
    "if mf_module_path not in sys.path:\n",
    "    sys.path.append(mf_module_path)\n",
    "import mf\n",
    "import mf_random\n",
    "import hpoutil\n",
    "import networkx\n",
    "import obonet\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connect to MySQL database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(host='localhost',\n",
    "                               user='mimicuser',\n",
    "                               passwd='mimic',\n",
    "                               database='mimiciiiv13',\n",
    "                              auth_plugin='mysql_native_password')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First approach to query mysql from python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that MySQL connection works properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ITEMID</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>VALUENUM</th>\n",
       "      <th>VALUEUOM</th>\n",
       "      <th>FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>51143</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>51144</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>51146</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>51200</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>51221</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>%</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID  SUBJECT_ID  HADM_ID  ITEMID           CHARTTIME  VALUE  VALUENUM  \\\n",
       "0       1           2   163353   51143 2138-07-17 20:48:00      0       0.0   \n",
       "1       2           2   163353   51144 2138-07-17 20:48:00      0       0.0   \n",
       "2       3           2   163353   51146 2138-07-17 20:48:00      0       0.0   \n",
       "3       4           2   163353   51200 2138-07-17 20:48:00      0       0.0   \n",
       "4       5           2   163353   51221 2138-07-17 20:48:00      0       0.0   \n",
       "\n",
       "  VALUEUOM      FLAG  \n",
       "0        %      None  \n",
       "1        %      None  \n",
       "2        %      None  \n",
       "3        %      None  \n",
       "4        %  abnormal  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM LABEVENTS LIMIT 5;\", mydb)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a cursor so that it can be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = mydb.cursor(buffered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explored several method to compute the synergy score for different diseases. Method 1-3 all worked but the time and space requirements are too high. See the archived file. Here, we use method 4 to compute phenotype pairwise synergies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synergy between Lab-derived Abnormalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This method relies on the power of MySQL for doing queies and joins, return a batch of phenotype profiles a time, and then use the power of Numpy to do numeric computation.\n",
    "\n",
    "Specificially, the method runs the following algorithm:\n",
    "\n",
    "    1. For one diagnosis code, specify the phenotypes to analyze--a list of HPO terms.\n",
    "    2. For a batch of patient*encounters, return a list of diagnosis codes (1 or 0)\n",
    "    3. For the same batch of patient*encounters, return a list of phenotypes.\n",
    "    4. Create a numpy array with dimension (N x P)\n",
    "    5. Perform numeric computation with Numpy:\n",
    "        outer product for ++ of PxP.T\n",
    "        outer product for +- of Px(1-P).T\n",
    "        outer product for -+ of (1-P)xP\n",
    "        outer product for -- of (1-P)x(1-P).T\n",
    "        combine the above with - and + of diagnosis value\n",
    "        stack them together as a (N x P x P x 8) matrix.\n",
    "        Step 1 - 5 are performed at each site. The resulting matrix is returned to JAX for final analyze.\n",
    "    6. Compute pairwise synergy:\n",
    "        use the multi-dimension array to calculate p(D = 1), p(D = 0), p(P1 * P2)\n",
    "        compute mutual information of each phenotype in regarding to one diagnosis I(P:D)\n",
    "        compute mutual information of two phenotypes in regarding to one diagnosis I(P:D)\n",
    "        compute pairwise synergy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: rewrite to be backward compatible\n",
    "def diagnosis_set():\n",
    "    \"\"\"Aggregate ICD9 codes with the first three digit and count how many times they appear. \n",
    "    Note this function uses encounters as the unit, meaning a code will counted twice if same patient was \n",
    "    diagnosed again at a later encounter.\"\"\"\n",
    "    diagnosis_count = pd.read_sql_query(\"SELECT SUBJECT_ID, HADM_ID, \\\n",
    "        CASE \\\n",
    "        WHEN(ICD9_CODE LIKE 'V%') THEN SUBSTRING(ICD9_CODE, 1, 3) \\\n",
    "        WHEN(ICD9_CODE LIKE 'E%') THEN SUBSTRING(ICD9_CODE, 1, 4) \\\n",
    "        ELSE SUBSTRING(ICD9_CODE, 1, 3) END AS ICD9 \\\n",
    "        FROM DIAGNOSES_ICD\", mydb)\n",
    "    diagnosisSet = diagnosis_count.drop_duplicates().groupby('ICD9').size().sort_values(ascending=False)\n",
    "    return diagnosisSet\n",
    "\n",
    "#TODO: rewrite to be backward compatible\n",
    "def createAbnormalPhenotypeTable(threshold, include_inferred=True, force_update=True):\n",
    "    \"\"\"\n",
    "    This is the abnormal phenotypes. \n",
    "    @include_inferred whether to include inferred HPO. Default true.\n",
    "    @force_update whether current table, if present, should be forced to update\n",
    "    \"\"\"\n",
    "    if force_update:\n",
    "        cursor.execute('''DROP TEMPORARY TABLE IF EXISTS p''')\n",
    "    if include_inferred:\n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS p\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, LabHpo.MAP_TO\n",
    "                        FROM \n",
    "                            LABEVENTS \n",
    "                        JOIN LabHpo on LABEVENTS.ROW_ID = LabHpo.ROW_ID\n",
    "                        WHERE LabHpo.NEGATED = 'F'\n",
    "                        \n",
    "                        UNION ALL\n",
    "                        \n",
    "                        SELECT \n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, INFERRED_LABHPO.INFERRED_TO AS MAP_TO \n",
    "                        FROM \n",
    "                            INFERRED_LABHPO \n",
    "                        JOIN \n",
    "                            LABEVENTS ON INFERRED_LABHPO.LABEVENT_ROW_ID = LABEVENTS.ROW_ID\n",
    "                        )\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    HAVING COUNT(*) > {}\n",
    "                    -- parameter to control how to define an abnormal phenotype is present.\n",
    "                '''.format(threshold))\n",
    "    else:       \n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS p\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, LabHpo.MAP_TO\n",
    "                        FROM \n",
    "                            LABEVENTS \n",
    "                        JOIN LabHpo on LABEVENTS.ROW_ID = LabHpo.ROW_ID\n",
    "                        WHERE LabHpo.NEGATED = 'F')\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    HAVING COUNT(*) > {}\n",
    "                    -- parameter to control how to define an abnormal phenotype is present.\n",
    "                '''.format(threshold))\n",
    "    cursor.execute('CREATE INDEX p_idx01 ON p (SUBJECT_ID, HADM_ID)')\n",
    "    cursor.execute('CREATE INDEX p_idx02 ON p (MAP_TO);')\n",
    "\n",
    "\n",
    "#TODO: rewrite to be backward compatible\n",
    "def encountersWithDiagnosis(diagnosis):\n",
    "    cursor.execute('''DROP TEMPORARY TABLE IF EXISTS d''')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE IF NOT EXISTS d\n",
    "        SELECT \n",
    "            DISTINCT SUBJECT_ID, HADM_ID, 1 AS DIAGNOSIS\n",
    "        FROM \n",
    "            DIAGNOSES_ICD \n",
    "        WHERE ICD9_CODE LIKE '{}%'\n",
    "        -- This is encounters with positive diagnosis\n",
    "    '''.format(diagnosis))\n",
    "    cursor.execute('CREATE INDEX d_idx01 ON d(SUBJECT_ID, HADM_ID)')\n",
    "\n",
    "    \n",
    "def createPhenotypeSet(diagnosis, threshold=1000):\n",
    "    \"\"\"\n",
    "    Create the phenotypes that we should analyze. Exemely less frequently observed phenotypes are excluded.\n",
    "    \"\"\"\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS ps')\n",
    "    cursor.execute('''\n",
    "            CREATE TEMPORARY TABLE ps\n",
    "            WITH pd AS(\n",
    "                SELECT p.*\n",
    "                FROM \n",
    "                    p JOIN (SELECT \n",
    "                                DISTINCT SUBJECT_ID, HADM_ID, 1 AS DIAGNOSIS\n",
    "                            FROM \n",
    "                                DIAGNOSES_ICD \n",
    "                            WHERE ICD9_CODE LIKE '{}%') AS d\n",
    "                    ON p.SUBJECT_ID = d.SUBJECT_ID AND p.HADM_ID = d.HADM_ID)\n",
    "            SELECT \n",
    "                MAP_TO, COUNT(*) AS N, 1 AS PHENOTYPE\n",
    "            FROM pd\n",
    "            GROUP BY MAP_TO\n",
    "            HAVING N > {}\n",
    "            ORDER BY N DESC'''.format(diagnosis, threshold))\n",
    "    phenoSet = pd.read_sql_query('SELECT * FROM ps', mydb)\n",
    "    return phenoSet\n",
    "\n",
    "\n",
    "def batch_query(start_index, end_index):\n",
    "    batch_size_actual = pd.read_sql_query('''\n",
    "                SELECT \n",
    "                    COUNT(DISTINCT SUBJECT_ID, HADM_ID) \n",
    "                FROM admissions \n",
    "                WHERE SUBJECT_ID BETWEEN {} AND {}\n",
    "                '''.format(start_index, end_index), mydb).iloc[0,0]\n",
    "    # create diagnosis table\n",
    "    diagnosisList = pd.read_sql_query('''\n",
    "                WITH a AS (\n",
    "                    SELECT DISTINCT SUBJECT_ID, HADM_ID \n",
    "                    FROM admissions \n",
    "                    WHERE SUBJECT_ID BETWEEN {} AND {})\n",
    "                SELECT \n",
    "                    a.SUBJECT_ID, a.HADM_ID, IF(d.DIAGNOSIS IS NULL, 0, 1) AS DIAGNOSIS\n",
    "                FROM \n",
    "                    a\n",
    "                LEFT JOIN\n",
    "                    d ON a.SUBJECT_ID = d.SUBJECT_ID AND a.HADM_ID = d.HADM_ID         \n",
    "                '''.format(start_index, end_index), mydb)\n",
    "    # create phenotype profile table\n",
    "    phenotyle_profile = pd.read_sql_query('''\n",
    "        WITH \n",
    "            a AS (\n",
    "                    SELECT \n",
    "                        DISTINCT SUBJECT_ID, HADM_ID \n",
    "                    FROM \n",
    "                        admissions \n",
    "                    WHERE SUBJECT_ID BETWEEN {} AND {}), \n",
    "            c as (\n",
    "                SELECT a.*, ps.MAP_TO\n",
    "                FROM a\n",
    "                JOIN ps),\n",
    "                -- cross product of all patient*encounter and phenotypes list\n",
    "            pp as (\n",
    "                SELECT p.*, 1 AS PHENOTYPE \n",
    "                FROM p RIGHT JOIN a \n",
    "                ON p.SUBJECT_ID = a.SUBJECT_ID AND p.HADM_ID = a.HADM_ID)\n",
    "\n",
    "        SELECT c.SUBJECT_ID, c.HADM_ID, c.MAP_TO, IF(pp.PHENOTYPE IS NULL, 0, 1) AS PHENOTYPE \n",
    "        FROM pp \n",
    "        RIGHT JOIN c ON pp.SUBJECT_ID = c.SUBJECT_ID and pp.HADM_ID = c.HADM_ID AND pp.MAP_TO = c.MAP_TO\n",
    "        '''.format(start_index, end_index), mydb)\n",
    "    return batch_size_actual, diagnosisList, phenotyle_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_in_batch(logger):\n",
    "    logger.info('starting iterate_in_batch()')\n",
    "    batch_size = 100\n",
    "    # find the set of diagnosis that are worthy to analyze\n",
    "    diagnosisSet = diagnosis_set()\n",
    "    logger.info('diagnosis set completed')\n",
    "\n",
    "    # create a temp table for abnormal phenotypes of each patient*encounter that met the threshold\n",
    "    #createAbnormalPhenotypeTable(threshold=1, force_update=True)\n",
    "    logger.info('createAbnormalPhenotypeTable() completed')\n",
    "    \n",
    "    synergies = {}\n",
    "    \n",
    "    for diagnosis in diagnosisSet.keys():\n",
    "        if (diagnosisSet[diagnosis] > 5000):\n",
    "            # create a temp table for diagnosis of all patient*encouter to analyze\n",
    "            encountersWithDiagnosis(diagnosis)\n",
    "            logger.info('encountersWithDiagnosis() completed')\n",
    "\n",
    "            ## create a list of phenotypes that we want to analyze for the specified disease and preset threshold\n",
    "            phenoSet = createPhenotypeSet(diagnosis, threshold=100)\n",
    "            logger.info('phenoSet completed')\n",
    "            P_SIZE = len(phenoSet)\n",
    "\n",
    "            ## find the start and end ROW_ID for patient*encounter\n",
    "            ADM_ID_START, ADM_ID_END = pd.read_sql_query('SELECT MIN(ROW_ID) AS min, MAX(ROW_ID) AS max FROM admissions', mydb).iloc[0]\n",
    "            batch_N = ADM_ID_END - ADM_ID_START + 1\n",
    "            TOTAL_BATCH = math.ceil(batch_N / batch_size) # total number of batches\n",
    "            synergies[diagnosis] = mf.SynergyWithinSet(diagnosis, phenoSet.MAP_TO)\n",
    "            logger.info('starting batch queries for {}'.format(diagnosis))\n",
    "            for i in np.arange(TOTAL_BATCH):\n",
    "                start_index = i * batch_size + ADM_ID_START\n",
    "                if i < TOTAL_BATCH - 1:\n",
    "                    end_index = start_index + batch_size - 1\n",
    "                else:\n",
    "                    end_index = batch_N\n",
    "                \n",
    "                batch_size_actual, diagnosisList, phenotyle_profile = batch_query(start_index, end_index)\n",
    "                \n",
    "                if batch_size_actual > 0 :\n",
    "                    diagnosisVector = diagnosisList.DIAGNOSIS\n",
    "                    phenotypeProfileMatrix = phenotyle_profile.PHENOTYPE.values.reshape([batch_size_actual, P_SIZE])\n",
    "                    if i % 100 == 0:\n",
    "                        logger.info('new batch: start_index={}, end_index={}, batch_size= {}, phenotype_size = {}'.format(start_index, end_index, batch_size_actual, len(phenoSet)))\n",
    "                    synergies[diagnosis].add_batch(phenotypeProfileMatrix, diagnosisVector)\n",
    "    \n",
    "    return synergies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes about 10 minutes to set up the phenotype table (p). Afterward, each disease takes about 10 minutes to complete the summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s',level=logging.DEBUG, stream=sys.stdout)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "synergies = iterate_in_batch(logger)\n",
    "   \n",
    "end = datetime.datetime.now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('running time: {}s'.format((end - start).total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('synergies.obj', 'wb') as synergies_file:\n",
    "    pickle.dump(synergies, synergies_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "close database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "mydb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Synergy between lab-derived and radiology report-derived Abnormalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm is about the same with the Method 3 in mutual_info_archive. Briefly, \n",
    "\n",
    "    * Select encounterOfInterest, temp table: JAX_encounterOfInterest(SUBJECT_ID, HADM_ID)\n",
    "    * Init diagnosisProfile: temp table: JAX_diagnosisProfile(SUBJECT_ID, HADM_ID, ICD, N)\n",
    "    * Init textHpoProfile: temp table: JAX_textHpoProfile(SUBJECT_ID, HADM_ID, MAP_TO, N)\n",
    "    * Init labHpoProfile: temp table: JAX_labHpoProfile(SUBJECT_ID, HADM_ID, MAP_TO, N)\n",
    "    \n",
    "    * Rank ICD frequency, temp table: JAX_diagFrequencyRank(ICD, N)\n",
    "      select diagOfInterest\n",
    "    * Rank textHPO frequency, temp table: JAX_textHpoFrequencyRank(MAP_TO, N)\n",
    "      select textHpoOfInterest\n",
    "    * Rank labHPO frequency, temp table: JAX_labHpoFrequencyRank(MAP_TO, N)\n",
    "      select labHpoOfInterest\n",
    "    \n",
    "    * Iteratation\n",
    "      for diagnosis in diagOfInterest\n",
    "          for textHpo in textHpoOfInterest\n",
    "              for labHpo in labHpoOfInterest\n",
    "                 Assign diagnosis value: assignDiagnosis(), table: (SUBJECT_ID, HADM_ID, DIAGNOSIS)\n",
    "                 Assign text2hpo phenotype value: table: SUBJECT_ID, HADM_ID, PHEN_TEXT\n",
    "                 Assign lab2hpo phenotype value: table: SUBJECT_ID, HADM_ID, PHEN_LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define encounters of interest\n",
    "def encounterOfInterest(debug=False, N=100):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_encounterOfInterest')\n",
    "    if debug:\n",
    "        limit = 'LIMIT {}'.format(N)\n",
    "    else:\n",
    "        limit = ''\n",
    "    # This is admissions that we want to analyze, 'LIMIT 100' in debug mode\n",
    "    cursor.execute('''\n",
    "                CREATE TEMPORARY TABLE IF NOT EXISTS JAX_encounterOfInterest(\n",
    "                    ROW_ID MEDIUMINT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY)\n",
    "                \n",
    "                SELECT \n",
    "                    DISTINCT SUBJECT_ID, HADM_ID \n",
    "                FROM admissions\n",
    "                {}\n",
    "                '''.format(limit))\n",
    "    \n",
    "def indexEncounterOfInterest():\n",
    "    cursor.execute('CREATE INDEX JAX_encounterOfInterest_idx01 ON JAX_encounterOfInterest (SUBJECT_ID, HADM_ID)')\n",
    "    \n",
    "def diagnosisProfile():\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_diagnosisProfile')\n",
    "    cursor.execute('''\n",
    "                CREATE TEMPORARY TABLE IF NOT EXISTS JAX_diagnosisProfile\n",
    "                SELECT \n",
    "                    DIAGNOSES_ICD.SUBJECT_ID, DIAGNOSES_ICD.HADM_ID, DIAGNOSES_ICD.ICD9_CODE, DIAGNOSES_ICD.SEQ_NUM\n",
    "                FROM\n",
    "                    DIAGNOSES_ICD\n",
    "                RIGHT JOIN\n",
    "                    JAX_encounterOfInterest\n",
    "                ON \n",
    "                    DIAGNOSES_ICD.SUBJECT_ID = JAX_encounterOfInterest.SUBJECT_ID \n",
    "                    AND \n",
    "                    DIAGNOSES_ICD.HADM_ID = JAX_encounterOfInterest.HADM_ID\n",
    "                ''')\n",
    "    \n",
    "def textHpoProfile(include_inferred=True, threshold=1):\n",
    "    if include_inferred:\n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS JAX_textHpoProfile\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            NOTEEVENTS.SUBJECT_ID, NOTEEVENTS.HADM_ID, NoteHpoClinPhen.MAP_TO\n",
    "                        FROM \n",
    "                            NOTEEVENTS \n",
    "                        JOIN NoteHpoClinPhen on NOTEEVENTS.ROW_ID = NoteHpoClinPhen.NOTES_ROW_ID\n",
    "                        \n",
    "                        UNION ALL\n",
    "                        \n",
    "                        SELECT\n",
    "                            NOTEEVENTS.SUBJECT_ID, NOTEEVENTS.HADM_ID, Inferred_NoteHpo.INFERRED_TO AS MAP_TO\n",
    "                        FROM \n",
    "                            NOTEEVENTS \n",
    "                        JOIN Inferred_NoteHpo on NOTEEVENTS.ROW_ID = Inferred_NoteHpo.NOTEEVENT_ROW_ID\n",
    "                        )\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO, COUNT(*) AS OCCURRANCE, 1 AS dummy\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    HAVING COUNT(*) >= {}\n",
    "                    -- parameter to control how to define an abnormal phenotype is present.\n",
    "                '''.format(threshold))\n",
    "        \n",
    "    else:\n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS JAX_p_text\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            NOTEEVENTS.SUBJECT_ID, NOTEEVENTS.HADM_ID, NoteHpoClinPhen.MAP_TO\n",
    "                        FROM \n",
    "                            NOTEEVENTS \n",
    "                        JOIN NoteHpoClinPhen on NOTEEVENTS.ROW_ID = NoteHpoClinPhen.NOTES_ROW_ID)\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO, COUNT(*) AS OCCURRANCE, 1 AS dummy\n",
    "                    HAVING COUNT(*) >= {}\n",
    "                    -- parameter to control how to define an abnormal phenotype is present.\n",
    "                '''.format(threshold))\n",
    "        \n",
    "def indexTextHpoProfile():\n",
    "    cursor.execute('CREATE INDEX JAX_textHpoProfile_idx01 ON JAX_textHpoProfile (SUBJECT_ID, HADM_ID)')\n",
    "    cursor.execute('CREATE INDEX JAX_textHpoProfile_idx02 ON JAX_textHpoProfile (MAP_TO);')\n",
    "    cursor.execute('CREATE INDEX JAX_textHpoProfile_idx03 ON JAX_textHpoProfile (SUBJECT_ID, HADM_ID, MAP_TO)')\n",
    "    \n",
    "def labHpoProfile(threshold, include_inferred=True, force_update=True):\n",
    "    # TODO: refactor the method \n",
    "    #createAbnormalPhenotypeTable(threshold, include_inferred=True, force_update=True)\n",
    "    \n",
    "    if force_update:\n",
    "        cursor.execute('''DROP TEMPORARY TABLE IF EXISTS JAX_labHpoProfile''')\n",
    "    if include_inferred:\n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS JAX_labHpoProfile\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, LabHpo.MAP_TO\n",
    "                        FROM \n",
    "                            LABEVENTS \n",
    "                        JOIN LabHpo on LABEVENTS.ROW_ID = LabHpo.ROW_ID\n",
    "                        WHERE LabHpo.NEGATED = 'F'\n",
    "                        \n",
    "                        UNION ALL\n",
    "                        \n",
    "                        SELECT \n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, INFERRED_LABHPO.INFERRED_TO AS MAP_TO \n",
    "                        FROM \n",
    "                            INFERRED_LABHPO \n",
    "                        JOIN \n",
    "                            LABEVENTS ON INFERRED_LABHPO.LABEVENT_ROW_ID = LABEVENTS.ROW_ID\n",
    "                        )\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO, COUNT(*) AS OCCURRANCE, 1 AS dummy\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    HAVING COUNT(*) >= {}\n",
    "                    -- parameter to control how to define an abnormal phenotype is present.\n",
    "                '''.format(threshold))\n",
    "    else:       \n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS JAX_labHpoProfile\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, LabHpo.MAP_TO\n",
    "                        FROM \n",
    "                            LABEVENTS \n",
    "                        JOIN LabHpo on LABEVENTS.ROW_ID = LabHpo.ROW_ID\n",
    "                        WHERE LabHpo.NEGATED = 'F')\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO, COUNT(*) AS OCCURRANCE, 1 AS dummy\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    HAVING COUNT(*) >= {}\n",
    "                    -- parameter to control how to define an abnormal phenotype is present.\n",
    "                '''.format(threshold))\n",
    "\n",
    "def indexLabHpoProfile():\n",
    "    cursor.execute('CREATE INDEX JAX_labHpoProfile_idx01 ON JAX_labHpoProfile (SUBJECT_ID, HADM_ID)')\n",
    "    cursor.execute('CREATE INDEX JAX_labHpoProfile_idx02 ON JAX_labHpoProfile (MAP_TO);')\n",
    "    cursor.execute('CREATE INDEX JAX_labHpoProfile_idx03 ON JAX_labHpoProfile (SUBJECT_ID, HADM_ID, MAP_TO)')\n",
    "    \n",
    "def rankICD():\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_diagFrequencyRank')\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TEMPORARY TABLE IF NOT EXISTS JAX_diagFrequencyRank\n",
    "        WITH JAX_temp_diag AS (\n",
    "            SELECT DISTINCT SUBJECT_ID, HADM_ID, \n",
    "                CASE \n",
    "                    WHEN(ICD9_CODE LIKE 'V%') THEN SUBSTRING(ICD9_CODE, 1, 3) \n",
    "                    WHEN(ICD9_CODE LIKE 'E%') THEN SUBSTRING(ICD9_CODE, 1, 4) \n",
    "                ELSE \n",
    "                    SUBSTRING(ICD9_CODE, 1, 3) END AS ICD9_CODE \n",
    "            FROM JAX_diagnosisProfile)\n",
    "        SELECT \n",
    "            ICD9_CODE, COUNT(*) AS N\n",
    "        FROM\n",
    "            JAX_temp_diag\n",
    "        GROUP BY \n",
    "            ICD9_CODE\n",
    "        ORDER BY N\n",
    "        DESC\n",
    "        \"\"\")\n",
    "\n",
    "def rankHpoFromText(diagnosis):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_textHpoFrequencyRank')\n",
    "    cursor.execute('''\n",
    "            CREATE TEMPORARY TABLE JAX_textHpoFrequencyRank            \n",
    "            WITH pd AS(\n",
    "                SELECT \n",
    "                    JAX_textHpoProfile.*\n",
    "                FROM \n",
    "                    JAX_textHpoProfile \n",
    "                JOIN (\n",
    "                    SELECT \n",
    "                        DISTINCT SUBJECT_ID, HADM_ID\n",
    "                    FROM \n",
    "                        JAX_diagnosisProfile \n",
    "                    WHERE \n",
    "                        ICD9_CODE LIKE '{}%') AS d\n",
    "                ON \n",
    "                    JAX_textHpoProfile.SUBJECT_ID = d.SUBJECT_ID AND JAX_textHpoProfile.HADM_ID = d.HADM_ID)\n",
    "            SELECT \n",
    "                MAP_TO, COUNT(*) AS N, 1 AS PHENOTYPE\n",
    "            FROM pd\n",
    "            GROUP BY MAP_TO\n",
    "            ORDER BY N DESC'''.format(diagnosis))\n",
    "    \n",
    "def rankHpoFromLab(diagnosis):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_labHpoFrequencyRank')\n",
    "    cursor.execute('''\n",
    "            CREATE TEMPORARY TABLE JAX_labHpoFrequencyRank            \n",
    "            WITH pd AS(\n",
    "                SELECT \n",
    "                    JAX_labHpoProfile.*\n",
    "                FROM \n",
    "                    JAX_labHpoProfile \n",
    "                JOIN (\n",
    "                    SELECT \n",
    "                        DISTINCT SUBJECT_ID, HADM_ID\n",
    "                    FROM \n",
    "                        JAX_diagnosisProfile \n",
    "                    WHERE \n",
    "                        ICD9_CODE LIKE '{}%') AS d\n",
    "                ON \n",
    "                    JAX_labHpoProfile.SUBJECT_ID = d.SUBJECT_ID AND JAX_labHpoProfile.HADM_ID = d.HADM_ID)\n",
    "            SELECT \n",
    "                MAP_TO, COUNT(*) AS N, 1 AS PHENOTYPE\n",
    "            FROM pd\n",
    "            GROUP BY MAP_TO\n",
    "            ORDER BY N DESC'''.format(diagnosis))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign 0 or 1 to each encouter whether a diagnosis is observed\n",
    "def createDiagnosisTable(diagnosis, primary_diagnosis_only):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag')\n",
    "    if primary_diagnosis_only:\n",
    "        limit = 'AND SEQ_NUM=1'\n",
    "    else:\n",
    "        limit = ''\n",
    "    cursor.execute('''\n",
    "                CREATE TEMPORARY TABLE IF NOT EXISTS JAX_mf_diag \n",
    "                WITH \n",
    "                    d AS (\n",
    "                        SELECT \n",
    "                            DISTINCT SUBJECT_ID, HADM_ID, '1' AS DIAGNOSIS\n",
    "                        FROM \n",
    "                            JAX_diagnosisProfile \n",
    "                        WHERE ICD9_CODE LIKE '{}%' {})\n",
    "                    -- This is encounters with positive diagnosis\n",
    "\n",
    "                SELECT \n",
    "                    DISTINCT a.SUBJECT_ID, a.HADM_ID, IF(d.DIAGNOSIS IS NULL, '0', '1') AS DIAGNOSIS\n",
    "                FROM \n",
    "                    JAX_encounterOfInterest AS a\n",
    "                LEFT JOIN\n",
    "                    d ON a.SUBJECT_ID = d.SUBJECT_ID AND a.HADM_ID = d.HADM_ID       \n",
    "                /* -- This is the first join for diagnosis (0, or 1) */    \n",
    "                '''.format(diagnosis, limit))\n",
    "    cursor.execute('CREATE INDEX JAX_mf_diag_idx01 ON JAX_mf_diag (SUBJECT_ID, HADM_ID)')\n",
    "\n",
    "# assign 0 or 1 to each encounter whether a phenotype is observed from radiology reports\n",
    "def diagnosisTextHpo(phenotype):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_textHpo')\n",
    "    \"\"\"\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_textHpo\n",
    "        SELECT \n",
    "            L.*, IF(R.MAP_TO IS NULL, '0', '1') AS PHEN_TXT\n",
    "        FROM JAX_mf_diag AS L \n",
    "        LEFT JOIN \n",
    "            (SELECT * \n",
    "            FROM JAX_textHpoProfile \n",
    "            WHERE JAX_textHpoProfile.MAP_TO = '{}') AS R \n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID \n",
    "    '''.format(phenotype))\n",
    "    \"\"\"\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_textHpo\n",
    "        WITH L AS (SELECT JAX_mf_diag.*, '{}' AS PHEN_TXT FROM JAX_mf_diag)\n",
    "        SELECT \n",
    "            L.*, IF(R.dummy IS NULL, '0', '1') AS PHEN_TXT_VALUE\n",
    "        FROM L \n",
    "        LEFT JOIN \n",
    "            JAX_textHpoProfile AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.PHEN_TXT = R.MAP_TO\n",
    "    '''.format(phenotype))\n",
    "    cursor.execute('CREATE INDEX JAX_mf_diag_textHpo_idx01 ON JAX_mf_diag_textHpo (SUBJECT_ID, HADM_ID)')\n",
    "\n",
    "def diagnosisAllTextHpo(threshold_min, threshold_max):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_allTextHpo')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_allTextHpo\n",
    "        WITH \n",
    "            P AS (SELECT MAP_TO AS PHEN_TXT FROM JAX_textHpoFrequencyRank WHERE N BETWEEN {} AND {}),\n",
    "            L AS (SELECT * FROM JAX_mf_diag JOIN P)\n",
    "        SELECT \n",
    "            L.*, IF(R.dummy IS NULL, '0', '1') AS PHEN_TXT_VALUE\n",
    "        FROM L \n",
    "        LEFT JOIN \n",
    "            JAX_textHpoProfile AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.PHEN_TXT = R.MAP_TO\n",
    "    '''.format(threshold_min, threshold_max))\n",
    "    cursor.execute('CREATE INDEX JAX_mf_diag_allTextHpo_idx01 ON JAX_mf_diag_allTextHpo (SUBJECT_ID, HADM_ID, PHEN_TXT)')\n",
    "    \n",
    "def diagnosisLabHpo(phenotype):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_labHpo')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_labHpo\n",
    "        WITH L AS (SELECT JAX_mf_diag.*, '{}' AS PHEN_LAB FROM JAX_mf_diag)\n",
    "        SELECT \n",
    "            L.*, IF(R.dummy IS NULL, '0', '1') AS PHEN_LAB_VALUE\n",
    "        FROM L \n",
    "        LEFT JOIN \n",
    "             JAX_labHpoProfile AS R \n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.PHEN_LAB = R.MAP_TO\n",
    "    '''.format(phenotype))\n",
    "    cursor.execute('CREATE INDEX JAX_mf_diag_labHpo_idx01 ON JAX_mf_diag_labHpo (SUBJECT_ID, HADM_ID)')\n",
    "    \n",
    "def diagnosisAllLabHpo(threshold_min, threshold_max):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_allLabHpo')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_allLabHpo\n",
    "        WITH \n",
    "            P AS (SELECT MAP_TO AS PHEN_LAB FROM JAX_labHpoFrequencyRank WHERE N BETWEEN {} AND {}),\n",
    "            L AS (SELECT * FROM JAX_mf_diag JOIN P)\n",
    "        SELECT \n",
    "            L.*, IF(R.dummy IS NULL, '0', '1') AS PHEN_LAB_VALUE\n",
    "        FROM L \n",
    "        LEFT JOIN \n",
    "             JAX_labHpoProfile AS R \n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.PHEN_LAB = R.MAP_TO\n",
    "    '''.format(threshold_min, threshold_max))\n",
    "    cursor.execute('CREATE INDEX JAX_mf_diag_allLabHpo_idx01 ON JAX_mf_diag_allLabHpo (SUBJECT_ID, HADM_ID)')\n",
    "\n",
    "def diagnosisTextLab(phenotype):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_txtHpo_labHpo')\n",
    "    result = cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_txtHpo_labHpo \n",
    "        WITH L AS (SELECT JAX_mf_diag_textHpo.*, '{}' AS PHEN_LAB FROM JAX_mf_diag_textHpo)\n",
    "        SELECT L.*, IF(R.dummy IS NULL, '0', '1') AS PHEN_LAB_VALUE\n",
    "        FROM L \n",
    "        LEFT JOIN \n",
    "            JAX_labHpoProfile AS R \n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.PHEN_LAB = R.MAP_TO\n",
    "    '''.format(phenotype))\n",
    "    \n",
    "    \n",
    "def diagnosisAllTextAllLab():\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_allTxtHpo_allLabHpo')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_allTxtHpo_allLabHpo \n",
    "        SELECT L.SUBJECT_ID, L.HADM_ID, L.DIAGNOSIS, L.PHEN_TXT, L.PHEN_TXT_VALUE, R.PHEN_LAB, R.PHEN_LAB_VALUE \n",
    "        FROM JAX_mf_diag_allTextHpo AS L \n",
    "        JOIN JAX_mf_diag_allLabHpo AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID\n",
    "    ''')\n",
    "    \n",
    "\n",
    "def initSummaryStatisticTables():\n",
    "    # define empty columns to store summary statistics\n",
    "    summary_statistics1_radiology = pd.DataFrame(data={'DIAGNOSIS_CODE':[], \n",
    "                       'PHENOTYPE':[], \n",
    "                       'DIAGNOSIS_VALUE':[], \n",
    "                       'PHENOTYPE_VALUE':[], \n",
    "                       'N':[]},\n",
    "                columns = ['DIAGNOSIS_CODE', 'PHENOTYPE', 'DIAGNOSIS_VALUE', 'PHENOTYPE_VALUE', 'N'])\n",
    "    \n",
    "    summary_statistics1_lab = pd.DataFrame(data={'DIAGNOSIS_CODE':[], \n",
    "                       'PHENOTYPE':[], \n",
    "                       'DIAGNOSIS_VALUE':[], \n",
    "                       'PHENOTYPE_VALUE':[], \n",
    "                       'N':[]},\n",
    "                columns = ['DIAGNOSIS_CODE', 'PHENOTYPE', 'DIAGNOSIS_VALUE', 'PHENOTYPE_VALUE', 'N'])\n",
    "\n",
    "    summary_statistics2 = pd.DataFrame(data={'DIAGNOSIS_CODE':[], \n",
    "                       'PHEN_TXT':[], \n",
    "                       'PHEN_LAB':[], \n",
    "                       'DIAGNOSIS_VALUE':[], \n",
    "                       'PHEN_TXT_VALUE':[], \n",
    "                       'PHEN_LAB_VALUE':[], \n",
    "                       'N':[]},\n",
    "                columns = ['DIAGNOSIS_CODE', 'PHEN_TXT', 'PHEN_LAB', 'DIAGNOSIS_VALUE', 'PHEN_TXT_VALUE', 'PHEN_LAB_VALUE', 'N']) \n",
    "\n",
    "    return summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2\n",
    "\n",
    "def initTables(debug=False):\n",
    "    \"\"\"\n",
    "    This combines LabHpo and Inferred_LabHpo, and combines TextHpo and Inferred_TextHpo. \n",
    "    Only need to run once. For efficiency consideration, the tables can also be created as perminent. \n",
    "    It is time-consuming, so call it with caution. \n",
    "    \"\"\"\n",
    "    #init textHpoProfile and index it\n",
    "    #I create perminant tables to save time; other users should enable them\n",
    "    #textHpoProfile(include_inferred=True, threshold=1)\n",
    "    #indexTextHpoProfile()\n",
    "    #init labHpoProfile and index it\n",
    "    #labHpoProfile(threshold=1, include_inferred=True, force_update=True)\n",
    "    #indexLabHpoProfile()\n",
    "    \n",
    "    #define encounters to analyze\n",
    "    encounterOfInterest(debug)\n",
    "    indexEncounterOfInterest()\n",
    "    #init diagnosisProfile\n",
    "    diagnosisProfile()\n",
    "    \n",
    "\n",
    "def iterate(primary_diagnosis_only, diagnosis_threshold_min, textHpo_threshold_min, labHpo_threshold_min, logger): \n",
    "    logger.info('starting iterating...................................')\n",
    "    N = pd.read_sql_query(\"SELECT count(*) FROM JAX_encounterOfInterest\", mydb)\n",
    "    # init empty tables to hold summary statistics\n",
    "    summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 = initSummaryStatisticTables()\n",
    "    \n",
    "    # define a set of diseases that we want to analyze\n",
    "    rankICD()\n",
    "    \n",
    "    diseaseOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_diagFrequencyRank WHERE N > {}\".format(diagnosis_threshold_min), mydb).ICD9_CODE.values\n",
    "    diseaseOfInterest = ['428']\n",
    "    # define encounters to analyze\n",
    "    logger.info('diseases of interest established: {}'.format(len(diseaseOfInterest)))\n",
    "    for diagnosis in diseaseOfInterest:\n",
    "        logger.info(\"start analyzing disease {}\".format(diagnosis))\n",
    "        \n",
    "        # assign each encounter whether a diagnosis code is observed\n",
    "        # create a table j1 (joint 1)\n",
    "        createDiagnosisTable(diagnosis, primary_diagnosis_only)\n",
    "        # for every diagnosis, find phenotypes of interest to look at from radiology reports\n",
    "        # for every diagnosis, find phenotypes of interest to look at from laboratory tests\n",
    "        rankHpoFromText(diagnosis)\n",
    "        rankHpoFromLab(diagnosis)\n",
    "        \n",
    "        textHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_textHpoFrequencyRank WHERE N > {}\".format(textHpo_threshold_min), mydb).MAP_TO.values\n",
    "        labHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_labHpoFrequencyRank WHERE N > {}\".format(labHpo_threshold_min), mydb).MAP_TO.values\n",
    "        logger.info(\"TextHpo of interest established, size: {}\".format(len(textHpoOfInterest)))\n",
    "        logger.info(\"LabHpo of interest established, size: {}\".format(len(labHpoOfInterest)))\n",
    "        for textHpo in textHpoOfInterest:\n",
    "            logger.info(\"iteration: TextHpo--{}\".format(textHpo))\n",
    "            # assign each encounter whether a phenotype is observed from radiology reports\n",
    "            diagnosisTextHpo(textHpo)            \n",
    "            result1_text = pd.read_sql_query('''\n",
    "                SELECT \n",
    "                    '{}' AS DIAGNOSIS_CODE, '{}' AS PHENOTYPE, DIAGNOSIS AS DIAGNOSIS_VALUE, PHEN_TXT_VALUE AS PHENOTYPE_VALUE, COUNT(*) AS N \n",
    "                FROM JAX_mf_diag_textHpo \n",
    "                GROUP BY \n",
    "                    DIAGNOSIS, PHEN_TXT_VALUE\n",
    "            '''.format(diagnosis, textHpo), mydb)\n",
    "            summary_statistics1_radiology = summary_statistics1_radiology.append(result1_text)\n",
    "            # summary statistics for p1\n",
    "            # calculate I(p1;D)\n",
    "            for labHpo in labHpoOfInterest:\n",
    "                logger.info(\".........LabHpo--{}\".format(labHpo))\n",
    "                diagnosisLabHpo(labHpo)\n",
    "                result1_lab = pd.read_sql_query('''\n",
    "                    SELECT \n",
    "                        '{}' AS DIAGNOSIS_CODE, '{}' AS PHENOTYPE, DIAGNOSIS AS DIAGNOSIS_VALUE, PHEN_LAB_VALUE AS PHENOTYPE_VALUE, COUNT(*) AS N \n",
    "                    FROM \n",
    "                        JAX_mf_diag_labHpo \n",
    "                    GROUP BY DIAGNOSIS, PHEN_LAB_VALUE\n",
    "                '''.format(diagnosis, labHpo), mydb)\n",
    "                summary_statistics1_lab = summary_statistics1_lab.append(result1_lab)\n",
    "            \n",
    "                # assign each encounter whether a phenotype is observed from lab tests\n",
    "                diagnosisTextLab(labHpo)\n",
    "                result2 = pd.read_sql_query('''\n",
    "                    SELECT \n",
    "                        '{}' AS DIAGNOSIS_CODE, \n",
    "                        '{}' AS PHEN_TXT, \n",
    "                        '{}' AS PHEN_LAB,  \n",
    "                        DIAGNOSIS AS DIAGNOSIS_VALUE, \n",
    "                        PHEN_TXT_VALUE, \n",
    "                        PHEN_LAB_VALUE, \n",
    "                        COUNT(*) AS N\n",
    "                    FROM JAX_mf_diag_txtHpo_labHpo \n",
    "                    GROUP BY DIAGNOSIS, PHEN_TXT_VALUE, PHEN_LAB_VALUE\n",
    "                '''.format(diagnosis, textHpo, labHpo), mydb)\n",
    "                summary_statistics2 = summary_statistics2.append(result2)\n",
    "    logger.info('end iterating.....................................')            \n",
    "    return N, summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 \n",
    "\n",
    "\n",
    "def iterate_batch(primary_diagnosis_only, diagnosis_threshold_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max, logger): \n",
    "    logger.info('starting iterating...................................')\n",
    "    N = pd.read_sql_query(\"SELECT count(*) FROM JAX_encounterOfInterest\", mydb)\n",
    "    # init empty tables to hold summary statistics\n",
    "    summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 = initSummaryStatisticTables()\n",
    "    \n",
    "    # define a set of diseases that we want to analyze\n",
    "    rankICD()\n",
    "    \n",
    "    diseaseOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_diagFrequencyRank WHERE N > {}\".format(diagnosis_threshold_min), mydb).ICD9_CODE.values\n",
    "    diseaseOfInterest = ['428']\n",
    "    logger.info('diseases of interest established: {}'.format(len(diseaseOfInterest)))\n",
    "    \n",
    "    for diagnosis in diseaseOfInterest:\n",
    "        logger.info(\"start analyzing disease {}\".format(diagnosis))\n",
    "        \n",
    "        logger.info(\".......assigning values of diagnosis\")\n",
    "        # assign each encounter whether a diagnosis code is observed\n",
    "        # create a table j1 (joint 1)\n",
    "        createDiagnosisTable(diagnosis, primary_diagnosis_only)\n",
    "        # for every diagnosis, find phenotypes of interest to look at from radiology reports\n",
    "        # for every diagnosis, find phenotypes of interest to look at from laboratory tests\n",
    "        rankHpoFromText(diagnosis)\n",
    "        rankHpoFromLab(diagnosis)\n",
    "        logger.info(\"..............diagnosis values found\")\n",
    "        \n",
    "        logger.info(\".......assigning values of TextHpo\")\n",
    "        diagnosisAllTextHpo(textHpo_threshold_min, textHpo_threshold_max)\n",
    "        result1_text = pd.read_sql_query(\"\"\"\n",
    "            SELECT '{}' AS DIAGNOSIS_CODE, \n",
    "                PHEN_TXT AS PHENOTYPE, \n",
    "                DIAGNOSIS AS DIAGNOSIS_VALUE, \n",
    "                PHEN_TXT_VALUE AS PHENOTYPE_VALUE, \n",
    "                COUNT(*) AS N \n",
    "            FROM JAX_mf_diag_allTextHpo \n",
    "            GROUP BY DIAGNOSIS, PHEN_TXT, PHEN_TXT_VALUE\n",
    "        \"\"\".format(diagnosis), mydb)\n",
    "        logger.info(\"..............TextHpo values found\")\n",
    "        summary_statistics1_radiology = summary_statistics1_radiology.append(result1_text)\n",
    "\n",
    "        \n",
    "        logger.info(\".......assigning values of LabHpo\")\n",
    "        diagnosisAllLabHpo(labHpo_threshold_min, labHpo_threshold_max)\n",
    "        result1_lab = pd.read_sql_query(\"\"\"\n",
    "            SELECT \n",
    "                '{}' AS DIAGNOSIS_CODE, \n",
    "                PHEN_LAB AS PHENOTYPE, \n",
    "                DIAGNOSIS AS DIAGNOSIS_VALUE, \n",
    "                PHEN_LAB_VALUE AS PHENOTYPE_VALUE, \n",
    "                COUNT(*) AS N \n",
    "            FROM JAX_mf_diag_allLabHpo \n",
    "            GROUP BY DIAGNOSIS, PHEN_LAB, PHEN_LAB_VALUE\n",
    "        \"\"\".format(diagnosis), mydb)\n",
    "        logger.info(\"..............LabHpo values found\")\n",
    "        summary_statistics1_lab = summary_statistics1_lab.append(result1_lab)\n",
    "\n",
    "        logger.info(\".......building diagnosis-TextHpo-LabHpo joint distribution\")\n",
    "        diagnosisAllTextAllLab()\n",
    "        result2 = pd.read_sql_query(\"\"\"\n",
    "            SELECT \n",
    "                '{}' AS DIAGNOSIS_CODE, \n",
    "                PHEN_TXT, \n",
    "                PHEN_LAB, \n",
    "                DIAGNOSIS AS DIAGNOSIS_VALUE,\n",
    "                PHEN_TXT_VALUE, \n",
    "                PHEN_LAB_VALUE, \n",
    "                COUNT(*) AS N \n",
    "            FROM JAX_mf_diag_allTxtHpo_allLabHpo \n",
    "            GROUP BY DIAGNOSIS, PHEN_LAB, PHEN_LAB_VALUE, PHEN_TXT, PHEN_TXT_VALUE\n",
    "        \"\"\".format(diagnosis) , mydb)\n",
    "        logger.info(\"..............diagnosis-TextHpo-LabHpo joint distribution built\")\n",
    "        summary_statistics2 = summary_statistics2.append(result2)\n",
    "\n",
    "    logger.info('end iterating.....................................')            \n",
    "    return N, summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to run this\n",
    "# Again, it take either too long or too much memory space to run\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# 1. build the temp tables for Lab converted HPO, Text convert HPO\n",
    "# Read the comments within the method!\n",
    "initTables(debug=False)\n",
    "# 2. iterate the database t (for debug, use parameter values: 0, 10, 15, for production, use parameter values: 0, 10000, 10000\n",
    "#N, summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 = iterate(diagnosis_threshold_min=0, textHpo_threshold_min=10, labHpo_threshold_min=15, logger=logger)\n",
    "#N, summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 = iterate(diagnosis_threshold_min=0, textHpo_threshold_min=1000, labHpo_threshold_min=1000, logger=logger)\n",
    "\n",
    "# 2b. use the batch method\n",
    "#N2, summary_statistics1_radiology2, summary_statistics1_lab2, summary_statistics22 = iterate_batch(diagnosis_threshold_min=0, textHpo_threshold_min=0, textHpo_threshold_max=100, labHpo_threshold_min=0, labHpo_threshold_max=100, logger=logger)\n",
    "N2, summary_statistics1_radiology2, summary_statistics1_lab2, summary_statistics22 = iterate_batch(diagnosis_threshold_min=0, textHpo_threshold_min=1000, textHpo_threshold_max=100000, labHpo_threshold_min=1000, labHpo_threshold_max=100000, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_statistics1_radiology.head()\n",
    "#summary_statistics1_radiology\n",
    "#summary_statistics1_radiology2.groupby('PHENOTYPE').agg({'N': sum})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_statistics1_radiology2.head()\n",
    "summary_statistics1_radiology.merge(summary_statistics1_radiology2, on = ['DIAGNOSIS_CODE', 'PHENOTYPE', 'DIAGNOSIS_VALUE', 'PHENOTYPE_VALUE'])\n",
    "c =summary_statistics1_lab.merge(summary_statistics1_lab2, on = ['DIAGNOSIS_CODE', 'PHENOTYPE', 'DIAGNOSIS_VALUE', 'PHENOTYPE_VALUE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary_statistics2.groupby(['PHEN_TXT', 'PHEN_LAB']).agg({'N': sum})\n",
    "c = summary_statistics2.merge(summary_statistics22, on = ['DIAGNOSIS_CODE', 'PHEN_TXT', 'PHEN_LAB', 'DIAGNOSIS_VALUE', 'PHEN_TXT_VALUE', 'PHEN_LAB_VALUE'] )\n",
    "#summary_statistics2.head()\n",
    "c.loc[c.N_x != c.N_y, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexDiagnosisTable():\n",
    "    cursor.execute(\"ALTER TABLE JAX_mf_diag ADD COLUMN ROW_ID INT AUTO_INCREMENT PRIMARY KEY;\")\n",
    "    \n",
    "def batch_query(start_index, end_index, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max):\n",
    "    \n",
    "    diagnosisVector = pd.read_sql_query('''\n",
    "        SELECT * FROM JAX_mf_diag WHERE ROW_ID BETWEEN {} AND {}\n",
    "    '''.format(start_index, end_index), mydb)\n",
    "    \n",
    "    textHpoFlat = pd.read_sql_query('''\n",
    "        WITH encounters AS (\n",
    "            SELECT SUBJECT_ID, HADM_ID\n",
    "            FROM JAX_mf_diag \n",
    "            WHERE ROW_ID BETWEEN {} AND {}\n",
    "        ), \n",
    "        textHpoOfInterest AS (\n",
    "            SELECT MAP_TO \n",
    "            FROM JAX_textHpoFrequencyRank \n",
    "            WHERE N BETWEEN {} AND {}\n",
    "        ), \n",
    "        joint as (\n",
    "            SELECT *\n",
    "            FROM encounters \n",
    "            JOIN textHpoOfInterest)\n",
    "        \n",
    "        SELECT L.SUBJECT_ID, L.HADM_ID, L.MAP_TO, IF(R.dummy IS NULL, 0, 1) AS VALUE\n",
    "        FROM joint as L\n",
    "        LEFT JOIN JAX_textHpoProfile AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.MAP_TO = R.MAP_TO\n",
    "    '''.format(start_index, end_index, textHpo_threshold_min, textHpo_threshold_max), mydb)\n",
    "    \n",
    "    labHpoFlat = pd.read_sql_query('''\n",
    "        WITH encounters AS (\n",
    "            SELECT SUBJECT_ID, HADM_ID\n",
    "            FROM JAX_mf_diag \n",
    "            WHERE ROW_ID BETWEEN {} AND {}\n",
    "        ), \n",
    "        labHpoOfInterest AS (\n",
    "            SELECT MAP_TO \n",
    "            FROM JAX_labHpoFrequencyRank \n",
    "            WHERE N BETWEEN {} AND {}\n",
    "        ), \n",
    "        joint as (\n",
    "            SELECT *\n",
    "            FROM encounters \n",
    "            JOIN labHpoOfInterest)\n",
    "        \n",
    "        SELECT L.SUBJECT_ID, L.HADM_ID, L.MAP_TO, IF(R.dummy IS NULL, 0, 1) AS VALUE\n",
    "        FROM joint as L\n",
    "        LEFT JOIN JAX_labHpoProfile AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.MAP_TO = R.MAP_TO\n",
    "    '''.format(start_index, end_index, labHpo_threshold_min, labHpo_threshold_max), mydb)\n",
    "    \n",
    "    return diagnosisVector, textHpoFlat, labHpoFlat\n",
    "\n",
    "def iterate_in_batch(primary_diagnosis_only, diagnosis_threshold_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max, logger):\n",
    "    logger.info('starting iterate_in_batch()')\n",
    "    batch_size = 100\n",
    "    \n",
    "    # define a set of diseases that we want to analyze\n",
    "    rankICD()\n",
    "    \n",
    "    diseaseOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_diagFrequencyRank WHERE N > {}\".format(diagnosis_threshold_min), mydb).ICD9_CODE.values\n",
    "    diseaseOfInterest = ['428', '584', '038']\n",
    "    logger.info('diagnosis of interest: {}'.format(len(diseaseOfInterest)))\n",
    "    \n",
    "    synergies = {}\n",
    "    \n",
    "    pbar = tqdm(total=len(diseaseOfInterest))\n",
    "    for diagnosis in diseaseOfInterest:\n",
    "        logger.info(\"start analyzing disease {}\".format(diagnosis))\n",
    "        \n",
    "        logger.info(\".......assigning values of diagnosis\")\n",
    "        # assign each encounter whether a diagnosis code is observed\n",
    "        # create a table j1 (joint 1)\n",
    "        createDiagnosisTable(diagnosis, primary_diagnosis_only)\n",
    "        indexDiagnosisTable()\n",
    "        # for every diagnosis, find phenotypes of interest to look at from radiology reports\n",
    "        # for every diagnosis, find phenotypes of interest to look at from laboratory tests\n",
    "        rankHpoFromText(diagnosis)\n",
    "        rankHpoFromLab(diagnosis)\n",
    "        logger.info(\"..............diagnosis values found\")\n",
    "        \n",
    "        textHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_textHpoFrequencyRank WHERE N BETWEEN {} AND {}\".format(textHpo_threshold_min, textHpo_threshold_max), mydb).MAP_TO.values\n",
    "        labHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_labHpoFrequencyRank WHERE N BETWEEN {} AND {}\".format(labHpo_threshold_min, labHpo_threshold_max), mydb).MAP_TO.values\n",
    "        logger.info(\"TextHpo of interest established, size: {}\".format(len(textHpoOfInterest)))\n",
    "        logger.info(\"LabHpo of interest established, size: {}\".format(len(labHpoOfInterest)))\n",
    "\n",
    "        ## find the start and end ROW_ID for patient*encounter\n",
    "        ADM_ID_START, ADM_ID_END = pd.read_sql_query('SELECT MIN(ROW_ID) AS min, MAX(ROW_ID) AS max FROM JAX_mf_diag', mydb).iloc[0]\n",
    "        batch_N = ADM_ID_END - ADM_ID_START + 1\n",
    "        TOTAL_BATCH = math.ceil(batch_N / batch_size) # total number of batches\n",
    "        \n",
    "        synergies[diagnosis] = mf.MutualInfoXYz(textHpoOfInterest, labHpoOfInterest, diagnosis)\n",
    "        \n",
    "        logger.info('starting batch queries for {}'.format(diagnosis))\n",
    "        for i in np.arange(TOTAL_BATCH):\n",
    "            start_index = i * batch_size + ADM_ID_START\n",
    "            if i < TOTAL_BATCH - 1:\n",
    "                end_index = start_index + batch_size - 1\n",
    "            else:\n",
    "                end_index = batch_N\n",
    "\n",
    "            diagnosisFlat, textHpoFlat, labHpoFlat =  batch_query(start_index, end_index, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max)\n",
    "\n",
    "            batch_size_actual = len(diagnosisFlat)\n",
    "            textHpoOfInterest_size = len(textHpoOfInterest)\n",
    "            labHpoOfInterest_size = len(labHpoOfInterest)\n",
    "            assert(len(textHpoFlat) == batch_size_actual * textHpoOfInterest_size)\n",
    "            assert(len(labHpoFlat) == batch_size_actual * labHpoOfInterest_size)\n",
    "            \n",
    "            if batch_size_actual > 0:\n",
    "                diagnosisVector = diagnosisFlat.DIAGNOSIS.values.astype(int)\n",
    "                # reformat the flat vector into N x M matrix, N is batch size, i.e. number of encounters, M is the length of HPO terms  \n",
    "                textHpoMatrix = textHpoFlat.VALUE.values.astype(int).reshape([batch_size_actual, textHpoOfInterest_size], order='F')\n",
    "                labHpoMatrix = labHpoFlat.VALUE.values.astype(int).reshape([batch_size_actual, labHpoOfInterest_size], order='F')\n",
    "                # check the matrix formatting is correct\n",
    "                # disable the following 4 lines to speed things up\n",
    "                textHpoLabelsMatrix = textHpoFlat.MAP_TO.values.reshape([batch_size_actual, textHpoOfInterest_size], order='F')\n",
    "                labHpoLabelsMatrix = labHpoFlat.MAP_TO.values.reshape([batch_size_actual, labHpoOfInterest_size], order='F')\n",
    "                assert (textHpoLabelsMatrix[0, :] == textHpoOfInterest).all()\n",
    "                assert (labHpoLabelsMatrix[0, :] == labHpoOfInterest).all()\n",
    "                if i % 100 == 0:\n",
    "                    logger.info('new batch: start_index={}, end_index={}, batch_size= {}, textHpo_size = {}, labHpo_size = {}'.format(start_index, end_index, batch_size_actual, textHpoMatrix.shape[1], labHpoMatrix.shape[1]))\n",
    "                synergies[diagnosis].add_batch(textHpoMatrix,labHpoMatrix, diagnosisVector)\n",
    "         \n",
    "        pbar.update(1)\n",
    "        \n",
    "    pbar.close()\n",
    "    \n",
    "    return synergies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  --TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-04 16:09:59,274 - 10502 - root - INFO - starting iterate_in_batch()\n",
      "2019-10-04 16:09:59,279 - 10502 - root - INFO - diagnosis of interest: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-04 16:09:59,281 - 10502 - root - INFO - start analyzing disease 428\n",
      "2019-10-04 16:09:59,282 - 10502 - root - INFO - .......assigning values of diagnosis\n",
      "2019-10-04 16:09:59,292 - 10502 - root - INFO - ..............diagnosis values found\n",
      "2019-10-04 16:09:59,297 - 10502 - root - INFO - TextHpo of interest established, size: 28\n",
      "2019-10-04 16:09:59,298 - 10502 - root - INFO - LabHpo of interest established, size: 93\n",
      "2019-10-04 16:09:59,300 - 10502 - root - INFO - starting batch queries for 428\n",
      "2019-10-04 16:09:59,439 - 10502 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 28, labHpo_size = 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 1/3 [00:00<00:00,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-04 16:09:59,447 - 10502 - root - INFO - start analyzing disease 584\n",
      "2019-10-04 16:09:59,448 - 10502 - root - INFO - .......assigning values of diagnosis\n",
      "2019-10-04 16:09:59,458 - 10502 - root - INFO - ..............diagnosis values found\n",
      "2019-10-04 16:09:59,462 - 10502 - root - INFO - TextHpo of interest established, size: 9\n",
      "2019-10-04 16:09:59,463 - 10502 - root - INFO - LabHpo of interest established, size: 42\n",
      "2019-10-04 16:09:59,466 - 10502 - root - INFO - starting batch queries for 584\n",
      "2019-10-04 16:09:59,535 - 10502 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 9, labHpo_size = 42\n",
      "2019-10-04 16:09:59,537 - 10502 - root - INFO - start analyzing disease 038\n",
      "2019-10-04 16:09:59,537 - 10502 - root - INFO - .......assigning values of diagnosis\n",
      "2019-10-04 16:09:59,548 - 10502 - root - INFO - ..............diagnosis values found\n",
      "2019-10-04 16:09:59,553 - 10502 - root - INFO - TextHpo of interest established, size: 14\n",
      "2019-10-04 16:09:59,553 - 10502 - root - INFO - LabHpo of interest established, size: 54\n",
      "2019-10-04 16:09:59,556 - 10502 - root - INFO - starting batch queries for 038\n",
      "2019-10-04 16:09:59,641 - 10502 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 14, labHpo_size = 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  6.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# how to run this\n",
    "\n",
    "# Again, it take either too long or too much memory space to run\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# 1. build the temp tables for Lab converted HPO, Text convert HPO\n",
    "# Read the comments within the method!\n",
    "initTables(debug=True)\n",
    "\n",
    "# 2. iterate throw the dataset\n",
    "primary_diagnosis_only = True\n",
    "diagnosis_threshold_min = 5\n",
    "textHpo_threshold_min, textHpo_threshold_max = 7, 100\n",
    "labHpo_threshold_min, labHpo_threshold_max = 7, 100\n",
    "\n",
    "synergies = iterate_in_batch(primary_diagnosis_only, diagnosis_threshold_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max, logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --PRODUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [23:39<00:00, 466.51s/it]\n"
     ]
    }
   ],
   "source": [
    "# how to run this\n",
    "# Again, it take either too long or too much memory space to run\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.WARN)\n",
    "\n",
    "# 1. build the temp tables for Lab converted HPO, Text convert HPO\n",
    "# Read the comments within the method!\n",
    "initTables(debug=False)\n",
    "\n",
    "# 2. iterate throw the dataset\n",
    "primary_diagnosis_only = True\n",
    "diagnosis_threshold_min = 3000\n",
    "textHpo_threshold_min, textHpo_threshold_max = 500, 100000\n",
    "labHpo_threshold_min, labHpo_threshold_max = 1000, 100000\n",
    "\n",
    "synergies = iterate_in_batch(primary_diagnosis_only, diagnosis_threshold_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "if primary_diagnosis_only:\n",
    "    fName = 'synergies_radiology_lab_primary_only.obj'\n",
    "else:\n",
    "    fName = 'synergies_radiology_lab_primary_and_secondary.obj'\n",
    "\n",
    "with open(fName, 'wb') as synergies_file:\n",
    "    pickle.dump(synergies, synergies_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synergies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "encounterOfInterest(debug=True)\n",
    "indexEncounterOfInterest()\n",
    "diagnosisProfile()\n",
    "rankICD()\n",
    "diagnosis = '038'\n",
    "rankHpoFromText(diagnosis)\n",
    "rankHpoFromLab(diagnosis)\n",
    "createDiagnosisTable(diagnosis, primary_diagnosis_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COUNT(*)\n",
       "0       100"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query(\"SELECT COUNT(*) FROM JAX_encounterOfInterest\", mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count(*)\n",
       "0       778"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query(\"SELECT count(*) FROM JAX_diagnosisProfile LIMIT 4\", mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>038</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ICD9_CODE  N\n",
       "0       038  8"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query(\"SELECT * FROM JAX_diagFrequencyRank WHERE ICD9_CODE='038'\", mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAP_TO</th>\n",
       "      <th>N</th>\n",
       "      <th>PHENOTYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>HP:0003138</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>HP:0001943</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>HP:0000118</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>HP:0001881</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>HP:0011277</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>HP:0011014</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>HP:0031851</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>HP:0003074</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>HP:0002148</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>HP:0000001</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>HP:0031970</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>HP:0010987</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>HP:0000079</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>HP:0004363</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>HP:0031850</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>HP:0032251</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>HP:0000119</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>HP:0002901</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>HP:0010927</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>HP:0001877</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>HP:0002715</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>HP:0020058</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>HP:0010929</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>HP:0004364</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>HP:0001871</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>HP:0011893</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>HP:0003111</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>HP:0002157</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>HP:0020061</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>HP:0004360</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>HP:0001974</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>HP:0032180</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>HP:0100529</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>HP:0012614</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>HP:0012337</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>HP:0001939</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>HP:0003110</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>HP:0011015</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>HP:0011423</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>HP:0020062</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>HP:0011422</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>HP:0003256</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>HP:0032065</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>HP:0012085</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>HP:0032066</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>HP:0004921</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>HP:0011873</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>HP:0020060</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>HP:0001882</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>HP:0001928</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>HP:0001872</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>HP:0040088</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>HP:0020059</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>HP:0004332</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAP_TO  N  PHENOTYPE\n",
       "0   HP:0003138  8          1\n",
       "1   HP:0001943  8          1\n",
       "2   HP:0000118  8          1\n",
       "3   HP:0001881  8          1\n",
       "4   HP:0011277  8          1\n",
       "5   HP:0011014  8          1\n",
       "6   HP:0031851  8          1\n",
       "7   HP:0003074  8          1\n",
       "8   HP:0002148  8          1\n",
       "9   HP:0000001  8          1\n",
       "10  HP:0031970  8          1\n",
       "11  HP:0010987  8          1\n",
       "12  HP:0000079  8          1\n",
       "13  HP:0004363  8          1\n",
       "14  HP:0031850  8          1\n",
       "15  HP:0032251  8          1\n",
       "16  HP:0000119  8          1\n",
       "17  HP:0002901  8          1\n",
       "18  HP:0010927  8          1\n",
       "19  HP:0001877  8          1\n",
       "20  HP:0002715  8          1\n",
       "21  HP:0020058  8          1\n",
       "22  HP:0010929  8          1\n",
       "23  HP:0004364  8          1\n",
       "24  HP:0001871  8          1\n",
       "25  HP:0011893  8          1\n",
       "26  HP:0003111  8          1\n",
       "27  HP:0002157  8          1\n",
       "28  HP:0020061  8          1\n",
       "29  HP:0004360  8          1\n",
       "30  HP:0001974  8          1\n",
       "31  HP:0032180  8          1\n",
       "32  HP:0100529  8          1\n",
       "33  HP:0012614  8          1\n",
       "34  HP:0012337  8          1\n",
       "35  HP:0001939  8          1\n",
       "36  HP:0003110  8          1\n",
       "37  HP:0011015  8          1\n",
       "38  HP:0011423  7          1\n",
       "39  HP:0020062  7          1\n",
       "40  HP:0011422  7          1\n",
       "41  HP:0003256  7          1\n",
       "42  HP:0032065  7          1\n",
       "43  HP:0012085  7          1\n",
       "44  HP:0032066  7          1\n",
       "45  HP:0004921  7          1\n",
       "46  HP:0011873  7          1\n",
       "47  HP:0020060  7          1\n",
       "48  HP:0001882  7          1\n",
       "49  HP:0001928  7          1\n",
       "50  HP:0001872  7          1\n",
       "51  HP:0040088  7          1\n",
       "52  HP:0020059  7          1\n",
       "53  HP:0004332  7          1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query(\"SELECT * FROM JAX_labHpoFrequencyRank WHERE N >= 7\", mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAP_TO</th>\n",
       "      <th>N</th>\n",
       "      <th>PHENOTYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>HP:0000118</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>HP:0002088</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>HP:0001626</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>HP:0001939</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>HP:0000001</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>HP:0012252</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>HP:0002086</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>HP:0002202</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>HP:0011032</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>HP:0100750</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>HP:0000969</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>HP:0002597</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>HP:0012337</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>HP:0030680</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAP_TO  N  PHENOTYPE\n",
       "0   HP:0000118  8          1\n",
       "1   HP:0002088  8          1\n",
       "2   HP:0001626  8          1\n",
       "3   HP:0001939  8          1\n",
       "4   HP:0000001  8          1\n",
       "5   HP:0012252  8          1\n",
       "6   HP:0002086  8          1\n",
       "7   HP:0002202  7          1\n",
       "8   HP:0011032  7          1\n",
       "9   HP:0100750  7          1\n",
       "10  HP:0000969  7          1\n",
       "11  HP:0002597  7          1\n",
       "12  HP:0012337  7          1\n",
       "13  HP:0030680  7          1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query(\"SELECT * FROM JAX_textHpoFrequencyRank WHERE N >= 7\", mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#createDiagnosisTable(diagnosis, primary_diagnosis_only=False )\n",
    "pd.read_sql_query(\"SELECT * FROM JAX_mf_diag WHERE DIAGNOSIS=1\", mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#createDiagnosisTable(diagnosis, primary_diagnosis_only=True)\n",
    "pd.read_sql_query(\"SELECT * FROM JAX_mf_diag\", mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexDiagnosisTable()\n",
    "pd.read_sql_query(\"SELECT * FROM JAX_mf_diag\", mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('''\n",
    "        SELECT DIAGNOSIS FROM JAX_mf_diag WHERE ROW_ID BETWEEN {} AND {}\n",
    "    '''.format(1, 25), mydb).reset_index().DIAGNOSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SUBJECT_ID  HADM_ID DIAGNOSIS  ROW_ID\n",
      "0           2   163353         0       1\n",
      "1           3   145834         1       2\n",
      "2           4   185777         0       3\n",
      "3           5   178980         0       4\n",
      "4           6   107064         0       5\n",
      "5           7   118037         0       6\n",
      "6           8   159514         0       7\n",
      "7           9   150750         0       8\n",
      "8          10   184167         0       9\n",
      "    SUBJECT_ID  HADM_ID      MAP_TO  VALUE\n",
      "0            2   163353  HP:0000118      0\n",
      "1            3   145834  HP:0000118      1\n",
      "2            4   185777  HP:0000118      1\n",
      "3            5   178980  HP:0000118      0\n",
      "4            6   107064  HP:0000118      1\n",
      "5            7   118037  HP:0000118      0\n",
      "6            8   159514  HP:0000118      1\n",
      "7            9   150750  HP:0000118      1\n",
      "8           10   184167  HP:0000118      1\n",
      "9            2   163353  HP:0002088      0\n",
      "10           3   145834  HP:0002088      1\n",
      "11           4   185777  HP:0002088      1\n",
      "12           5   178980  HP:0002088      0\n",
      "13           6   107064  HP:0002088      1\n",
      "[['HP:0000118' 'HP:0002088' 'HP:0001626' 'HP:0001939' 'HP:0000001'\n",
      "  'HP:0012252' 'HP:0002086' 'HP:0002202' 'HP:0011032' 'HP:0100750'\n",
      "  'HP:0000969' 'HP:0002597' 'HP:0012337' 'HP:0030680']\n",
      " ['HP:0000118' 'HP:0002088' 'HP:0001626' 'HP:0001939' 'HP:0000001'\n",
      "  'HP:0012252' 'HP:0002086' 'HP:0002202' 'HP:0011032' 'HP:0100750'\n",
      "  'HP:0000969' 'HP:0002597' 'HP:0012337' 'HP:0030680']\n",
      " ['HP:0000118' 'HP:0002088' 'HP:0001626' 'HP:0001939' 'HP:0000001'\n",
      "  'HP:0012252' 'HP:0002086' 'HP:0002202' 'HP:0011032' 'HP:0100750'\n",
      "  'HP:0000969' 'HP:0002597' 'HP:0012337' 'HP:0030680']\n",
      " ['HP:0000118' 'HP:0002088' 'HP:0001626' 'HP:0001939' 'HP:0000001'\n",
      "  'HP:0012252' 'HP:0002086' 'HP:0002202' 'HP:0011032' 'HP:0100750'\n",
      "  'HP:0000969' 'HP:0002597' 'HP:0012337' 'HP:0030680']\n",
      " ['HP:0000118' 'HP:0002088' 'HP:0001626' 'HP:0001939' 'HP:0000001'\n",
      "  'HP:0012252' 'HP:0002086' 'HP:0002202' 'HP:0011032' 'HP:0100750'\n",
      "  'HP:0000969' 'HP:0002597' 'HP:0012337' 'HP:0030680']\n",
      " ['HP:0000118' 'HP:0002088' 'HP:0001626' 'HP:0001939' 'HP:0000001'\n",
      "  'HP:0012252' 'HP:0002086' 'HP:0002202' 'HP:0011032' 'HP:0100750'\n",
      "  'HP:0000969' 'HP:0002597' 'HP:0012337' 'HP:0030680']\n",
      " ['HP:0000118' 'HP:0002088' 'HP:0001626' 'HP:0001939' 'HP:0000001'\n",
      "  'HP:0012252' 'HP:0002086' 'HP:0002202' 'HP:0011032' 'HP:0100750'\n",
      "  'HP:0000969' 'HP:0002597' 'HP:0012337' 'HP:0030680']\n",
      " ['HP:0000118' 'HP:0002088' 'HP:0001626' 'HP:0001939' 'HP:0000001'\n",
      "  'HP:0012252' 'HP:0002086' 'HP:0002202' 'HP:0011032' 'HP:0100750'\n",
      "  'HP:0000969' 'HP:0002597' 'HP:0012337' 'HP:0030680']\n",
      " ['HP:0000118' 'HP:0002088' 'HP:0001626' 'HP:0001939' 'HP:0000001'\n",
      "  'HP:0012252' 'HP:0002086' 'HP:0002202' 'HP:0011032' 'HP:0100750'\n",
      "  'HP:0000969' 'HP:0002597' 'HP:0012337' 'HP:0030680']]\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 0 1 1 1 1 0 1 1 1 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 0 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 1 0 0 0 0 0 1 1 0 1]\n",
      " [1 1 0 1 1 1 1 0 1 1 1 0 1 0]\n",
      " [1 1 0 1 1 1 1 0 1 0 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "start_index, end_index, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max = 0, 9, 7, 100, 7, 100\n",
    "\n",
    "diagnosisFlat, textHpoFlat, labHpoFlat =  batch_query(start_index, end_index, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max)\n",
    "\n",
    "print(diagnosisFlat)\n",
    "print(textHpoFlat.head(14))\n",
    "print(textHpoFlat.MAP_TO.values.reshape([9, 14], order='F'))\n",
    "print(textHpoFlat.VALUE.values.reshape([9, 14], order='F'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SUBJECT_ID  HADM_ID      MAP_TO  VALUE\n",
      "0            2   163353  HP:0003138      0\n",
      "1            3   145834  HP:0003138      1\n",
      "2            4   185777  HP:0003138      0\n",
      "3            5   178980  HP:0003138      0\n",
      "4            6   107064  HP:0003138      1\n",
      "5            7   118037  HP:0003138      0\n",
      "6            8   159514  HP:0003138      0\n",
      "7            9   150750  HP:0003138      1\n",
      "8           10   184167  HP:0003138      0\n",
      "9            2   163353  HP:0001943      0\n",
      "10           3   145834  HP:0001943      1\n",
      "11           4   185777  HP:0001943      0\n",
      "12           5   178980  HP:0001943      0\n",
      "13           6   107064  HP:0001943      1\n",
      "[['HP:0003138' 'HP:0001943' 'HP:0000118' 'HP:0001881' 'HP:0011277'\n",
      "  'HP:0011014' 'HP:0031851' 'HP:0003074' 'HP:0002148' 'HP:0000001'\n",
      "  'HP:0031970' 'HP:0010987' 'HP:0000079' 'HP:0004363' 'HP:0031850'\n",
      "  'HP:0032251' 'HP:0000119' 'HP:0002901' 'HP:0010927' 'HP:0001877'\n",
      "  'HP:0002715' 'HP:0020058' 'HP:0010929' 'HP:0004364' 'HP:0001871'\n",
      "  'HP:0011893' 'HP:0003111' 'HP:0002157' 'HP:0020061' 'HP:0004360'\n",
      "  'HP:0001974' 'HP:0032180' 'HP:0100529' 'HP:0012614' 'HP:0012337'\n",
      "  'HP:0001939' 'HP:0003110' 'HP:0011015' 'HP:0011423' 'HP:0020062'\n",
      "  'HP:0011422' 'HP:0003256' 'HP:0032065' 'HP:0012085' 'HP:0032066'\n",
      "  'HP:0004921' 'HP:0011873' 'HP:0020060' 'HP:0001882' 'HP:0001928'\n",
      "  'HP:0001872' 'HP:0040088' 'HP:0020059' 'HP:0004332']\n",
      " ['HP:0003138' 'HP:0001943' 'HP:0000118' 'HP:0001881' 'HP:0011277'\n",
      "  'HP:0011014' 'HP:0031851' 'HP:0003074' 'HP:0002148' 'HP:0000001'\n",
      "  'HP:0031970' 'HP:0010987' 'HP:0000079' 'HP:0004363' 'HP:0031850'\n",
      "  'HP:0032251' 'HP:0000119' 'HP:0002901' 'HP:0010927' 'HP:0001877'\n",
      "  'HP:0002715' 'HP:0020058' 'HP:0010929' 'HP:0004364' 'HP:0001871'\n",
      "  'HP:0011893' 'HP:0003111' 'HP:0002157' 'HP:0020061' 'HP:0004360'\n",
      "  'HP:0001974' 'HP:0032180' 'HP:0100529' 'HP:0012614' 'HP:0012337'\n",
      "  'HP:0001939' 'HP:0003110' 'HP:0011015' 'HP:0011423' 'HP:0020062'\n",
      "  'HP:0011422' 'HP:0003256' 'HP:0032065' 'HP:0012085' 'HP:0032066'\n",
      "  'HP:0004921' 'HP:0011873' 'HP:0020060' 'HP:0001882' 'HP:0001928'\n",
      "  'HP:0001872' 'HP:0040088' 'HP:0020059' 'HP:0004332']\n",
      " ['HP:0003138' 'HP:0001943' 'HP:0000118' 'HP:0001881' 'HP:0011277'\n",
      "  'HP:0011014' 'HP:0031851' 'HP:0003074' 'HP:0002148' 'HP:0000001'\n",
      "  'HP:0031970' 'HP:0010987' 'HP:0000079' 'HP:0004363' 'HP:0031850'\n",
      "  'HP:0032251' 'HP:0000119' 'HP:0002901' 'HP:0010927' 'HP:0001877'\n",
      "  'HP:0002715' 'HP:0020058' 'HP:0010929' 'HP:0004364' 'HP:0001871'\n",
      "  'HP:0011893' 'HP:0003111' 'HP:0002157' 'HP:0020061' 'HP:0004360'\n",
      "  'HP:0001974' 'HP:0032180' 'HP:0100529' 'HP:0012614' 'HP:0012337'\n",
      "  'HP:0001939' 'HP:0003110' 'HP:0011015' 'HP:0011423' 'HP:0020062'\n",
      "  'HP:0011422' 'HP:0003256' 'HP:0032065' 'HP:0012085' 'HP:0032066'\n",
      "  'HP:0004921' 'HP:0011873' 'HP:0020060' 'HP:0001882' 'HP:0001928'\n",
      "  'HP:0001872' 'HP:0040088' 'HP:0020059' 'HP:0004332']\n",
      " ['HP:0003138' 'HP:0001943' 'HP:0000118' 'HP:0001881' 'HP:0011277'\n",
      "  'HP:0011014' 'HP:0031851' 'HP:0003074' 'HP:0002148' 'HP:0000001'\n",
      "  'HP:0031970' 'HP:0010987' 'HP:0000079' 'HP:0004363' 'HP:0031850'\n",
      "  'HP:0032251' 'HP:0000119' 'HP:0002901' 'HP:0010927' 'HP:0001877'\n",
      "  'HP:0002715' 'HP:0020058' 'HP:0010929' 'HP:0004364' 'HP:0001871'\n",
      "  'HP:0011893' 'HP:0003111' 'HP:0002157' 'HP:0020061' 'HP:0004360'\n",
      "  'HP:0001974' 'HP:0032180' 'HP:0100529' 'HP:0012614' 'HP:0012337'\n",
      "  'HP:0001939' 'HP:0003110' 'HP:0011015' 'HP:0011423' 'HP:0020062'\n",
      "  'HP:0011422' 'HP:0003256' 'HP:0032065' 'HP:0012085' 'HP:0032066'\n",
      "  'HP:0004921' 'HP:0011873' 'HP:0020060' 'HP:0001882' 'HP:0001928'\n",
      "  'HP:0001872' 'HP:0040088' 'HP:0020059' 'HP:0004332']\n",
      " ['HP:0003138' 'HP:0001943' 'HP:0000118' 'HP:0001881' 'HP:0011277'\n",
      "  'HP:0011014' 'HP:0031851' 'HP:0003074' 'HP:0002148' 'HP:0000001'\n",
      "  'HP:0031970' 'HP:0010987' 'HP:0000079' 'HP:0004363' 'HP:0031850'\n",
      "  'HP:0032251' 'HP:0000119' 'HP:0002901' 'HP:0010927' 'HP:0001877'\n",
      "  'HP:0002715' 'HP:0020058' 'HP:0010929' 'HP:0004364' 'HP:0001871'\n",
      "  'HP:0011893' 'HP:0003111' 'HP:0002157' 'HP:0020061' 'HP:0004360'\n",
      "  'HP:0001974' 'HP:0032180' 'HP:0100529' 'HP:0012614' 'HP:0012337'\n",
      "  'HP:0001939' 'HP:0003110' 'HP:0011015' 'HP:0011423' 'HP:0020062'\n",
      "  'HP:0011422' 'HP:0003256' 'HP:0032065' 'HP:0012085' 'HP:0032066'\n",
      "  'HP:0004921' 'HP:0011873' 'HP:0020060' 'HP:0001882' 'HP:0001928'\n",
      "  'HP:0001872' 'HP:0040088' 'HP:0020059' 'HP:0004332']\n",
      " ['HP:0003138' 'HP:0001943' 'HP:0000118' 'HP:0001881' 'HP:0011277'\n",
      "  'HP:0011014' 'HP:0031851' 'HP:0003074' 'HP:0002148' 'HP:0000001'\n",
      "  'HP:0031970' 'HP:0010987' 'HP:0000079' 'HP:0004363' 'HP:0031850'\n",
      "  'HP:0032251' 'HP:0000119' 'HP:0002901' 'HP:0010927' 'HP:0001877'\n",
      "  'HP:0002715' 'HP:0020058' 'HP:0010929' 'HP:0004364' 'HP:0001871'\n",
      "  'HP:0011893' 'HP:0003111' 'HP:0002157' 'HP:0020061' 'HP:0004360'\n",
      "  'HP:0001974' 'HP:0032180' 'HP:0100529' 'HP:0012614' 'HP:0012337'\n",
      "  'HP:0001939' 'HP:0003110' 'HP:0011015' 'HP:0011423' 'HP:0020062'\n",
      "  'HP:0011422' 'HP:0003256' 'HP:0032065' 'HP:0012085' 'HP:0032066'\n",
      "  'HP:0004921' 'HP:0011873' 'HP:0020060' 'HP:0001882' 'HP:0001928'\n",
      "  'HP:0001872' 'HP:0040088' 'HP:0020059' 'HP:0004332']\n",
      " ['HP:0003138' 'HP:0001943' 'HP:0000118' 'HP:0001881' 'HP:0011277'\n",
      "  'HP:0011014' 'HP:0031851' 'HP:0003074' 'HP:0002148' 'HP:0000001'\n",
      "  'HP:0031970' 'HP:0010987' 'HP:0000079' 'HP:0004363' 'HP:0031850'\n",
      "  'HP:0032251' 'HP:0000119' 'HP:0002901' 'HP:0010927' 'HP:0001877'\n",
      "  'HP:0002715' 'HP:0020058' 'HP:0010929' 'HP:0004364' 'HP:0001871'\n",
      "  'HP:0011893' 'HP:0003111' 'HP:0002157' 'HP:0020061' 'HP:0004360'\n",
      "  'HP:0001974' 'HP:0032180' 'HP:0100529' 'HP:0012614' 'HP:0012337'\n",
      "  'HP:0001939' 'HP:0003110' 'HP:0011015' 'HP:0011423' 'HP:0020062'\n",
      "  'HP:0011422' 'HP:0003256' 'HP:0032065' 'HP:0012085' 'HP:0032066'\n",
      "  'HP:0004921' 'HP:0011873' 'HP:0020060' 'HP:0001882' 'HP:0001928'\n",
      "  'HP:0001872' 'HP:0040088' 'HP:0020059' 'HP:0004332']\n",
      " ['HP:0003138' 'HP:0001943' 'HP:0000118' 'HP:0001881' 'HP:0011277'\n",
      "  'HP:0011014' 'HP:0031851' 'HP:0003074' 'HP:0002148' 'HP:0000001'\n",
      "  'HP:0031970' 'HP:0010987' 'HP:0000079' 'HP:0004363' 'HP:0031850'\n",
      "  'HP:0032251' 'HP:0000119' 'HP:0002901' 'HP:0010927' 'HP:0001877'\n",
      "  'HP:0002715' 'HP:0020058' 'HP:0010929' 'HP:0004364' 'HP:0001871'\n",
      "  'HP:0011893' 'HP:0003111' 'HP:0002157' 'HP:0020061' 'HP:0004360'\n",
      "  'HP:0001974' 'HP:0032180' 'HP:0100529' 'HP:0012614' 'HP:0012337'\n",
      "  'HP:0001939' 'HP:0003110' 'HP:0011015' 'HP:0011423' 'HP:0020062'\n",
      "  'HP:0011422' 'HP:0003256' 'HP:0032065' 'HP:0012085' 'HP:0032066'\n",
      "  'HP:0004921' 'HP:0011873' 'HP:0020060' 'HP:0001882' 'HP:0001928'\n",
      "  'HP:0001872' 'HP:0040088' 'HP:0020059' 'HP:0004332']\n",
      " ['HP:0003138' 'HP:0001943' 'HP:0000118' 'HP:0001881' 'HP:0011277'\n",
      "  'HP:0011014' 'HP:0031851' 'HP:0003074' 'HP:0002148' 'HP:0000001'\n",
      "  'HP:0031970' 'HP:0010987' 'HP:0000079' 'HP:0004363' 'HP:0031850'\n",
      "  'HP:0032251' 'HP:0000119' 'HP:0002901' 'HP:0010927' 'HP:0001877'\n",
      "  'HP:0002715' 'HP:0020058' 'HP:0010929' 'HP:0004364' 'HP:0001871'\n",
      "  'HP:0011893' 'HP:0003111' 'HP:0002157' 'HP:0020061' 'HP:0004360'\n",
      "  'HP:0001974' 'HP:0032180' 'HP:0100529' 'HP:0012614' 'HP:0012337'\n",
      "  'HP:0001939' 'HP:0003110' 'HP:0011015' 'HP:0011423' 'HP:0020062'\n",
      "  'HP:0011422' 'HP:0003256' 'HP:0032065' 'HP:0012085' 'HP:0032066'\n",
      "  'HP:0004921' 'HP:0011873' 'HP:0020060' 'HP:0001882' 'HP:0001928'\n",
      "  'HP:0001872' 'HP:0040088' 'HP:0020059' 'HP:0004332']]\n",
      "[[0 0 1 1 1 0 1 0 0 1 0 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 0 0 1 0 1\n",
      "  1 0 0 1 0 0 0 1 0 0 1 1 1 0 1 1 0 1]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1\n",
      "  1 1 0 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1]\n",
      " [0 0 1 1 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1\n",
      "  1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1]\n",
      " [0 0 1 1 1 0 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1\n",
      "  1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
      " [0 0 1 1 1 0 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 0 1 0 1 1 0 1 0 1\n",
      "  1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 0 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 1 0 0 1 1\n",
      "  0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(labHpoFlat.head(14))\n",
    "print(labHpoFlat.MAP_TO.values.reshape([9, 54], order='F'))\n",
    "print(labHpoFlat.VALUE.values.reshape([9, 54], order='F'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosisTextHpo(phenotype='HP:0002086')\n",
    "result = pd.read_sql_query(\"SELECT '{}' AS DIAGNOSIS_CODE, '{}' AS PHENOTYPE, DIAGNOSIS AS DIAGNOSIS_VALUE, PHEN_TXT_VALUE AS PHENOTYPE_VALUE, COUNT(*) AS N FROM JAX_mf_diag_textHpo GROUP BY DIAGNOSIS, PHEN_TXT_VALUE\", mydb)\n",
    "result.head()\n",
    "#result.groupby(['DIAGNOSIS', 'PHEN_TXT_VALUE'])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosisAllTextHpo(0, 100)\n",
    "pd.read_sql_query(\"SELECT * FROM JAX_mf_diag_allTextHpo WHERE PHEN_TXT_VALUE = 1 LIMIT 5\", mydb)\n",
    "#result = pd.read_sql_query(\"SELECT '{}' AS DIAGNOSIS_CODE, PHEN_TXT AS PHENOTYPE, DIAGNOSIS AS DIAGNOSIS_VALUE, PHEN_TXT_VALUE AS PHENOTYPE_VALUE, COUNT(*) AS N FROM JAX_mf_diag_allTextHpo GROUP BY DIAGNOSIS, PHEN_TXT, PHEN_TXT_VALUE\", mydb)\n",
    "#result.groupby(['PHENOTYPE']).agg({'N':sum})\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual information between phenotypes in radiology and lab tests\n",
    "Without considering diseases, we want to determine the mutual information between pairs of phenotypes from radiology reports and lab tests. The algorithm:\n",
    "\n",
    "    * find phenotypes of interest from radiology reports\n",
    "    * find phenotypes of interest from lab tests\n",
    "    * in batches, create a matrix of text phenotype profiles and a matrix of lab phenotype profiles, update summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_query_lab_text(start_index, end_index, textHpo_min, textHpo_max, labHpo_min, labHpo_max):\n",
    "    \n",
    "    textHpo_flat = pd.read_sql_query('''\n",
    "        WITH encounters AS (\n",
    "                SELECT *\n",
    "                FROM JAX_encounterOfInterest\n",
    "                WHERE ROW_ID BETWEEN {} AND {}),\n",
    "            phenotypes AS (\n",
    "                SELECT MAP_TO\n",
    "                FROM JAX_textHpoFrequencyRank\n",
    "                WHERE N BETWEEN {} AND {}\n",
    "            ), \n",
    "            temp AS (\n",
    "                SELECT * \n",
    "                FROM encounters \n",
    "                JOIN phenotypes)\n",
    "\n",
    "            SELECT L.SUBJECT_ID, L.HADM_ID, L.MAP_TO AS PHEN_TEXT, IF(R.dummy IS NULL, 0, 1) AS PHEN_TEXT_VALUE\n",
    "            FROM temp AS L\n",
    "            LEFT JOIN \n",
    "                JAX_textHpoProfile AS R\n",
    "            ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.MAP_TO = R.MAP_TO\n",
    "        '''.format(start_index, end_index, textHpo_min, textHpo_max), mydb)\n",
    "    \n",
    "    labHpo_flat = pd.read_sql_query('''\n",
    "        WITH encounters AS (\n",
    "                SELECT *\n",
    "                FROM JAX_encounterOfInterest\n",
    "                WHERE ROW_ID BETWEEN {} AND {}),\n",
    "            phenotypes AS (\n",
    "                SELECT MAP_TO\n",
    "                FROM JAX_labHpoFrequencyRank\n",
    "                WHERE N BETWEEN {} AND {}\n",
    "            ), \n",
    "            temp AS (\n",
    "                SELECT * \n",
    "                FROM encounters \n",
    "                JOIN phenotypes)\n",
    "\n",
    "            SELECT L.SUBJECT_ID, L.HADM_ID, L.MAP_TO AS PHEN_LAB, IF(R.dummy IS NULL, 0, 1) AS PHEN_LAB_VALUE\n",
    "            FROM temp AS L\n",
    "            LEFT JOIN \n",
    "                JAX_labHpoProfile AS R\n",
    "            ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.MAP_TO = R.MAP_TO\n",
    "        '''.format(start_index, end_index, labHpo_min, labHpo_max), mydb)\n",
    "    \n",
    "    return textHpo_flat, labHpo_flat \n",
    "    \n",
    "\n",
    "def overall_mf(batch_size, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max):\n",
    "    \n",
    "    textHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_textHpoFrequencyRank WHERE N BETWEEN {} AND {}\".format(textHpo_threshold_min, textHpo_threshold_max), mydb).MAP_TO.values\n",
    "    labHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_labHpoFrequencyRank WHERE N BETWEEN {} AND {}\".format(labHpo_threshold_min, labHpo_threshold_max), mydb).MAP_TO.values\n",
    "    M1 = len(textHpoOfInterest)\n",
    "    M2 = len(labHpoOfInterest)\n",
    "    \n",
    "    mf_rad_lab = mf.MutualInformationVectorized(textHpoOfInterest, labHpoOfInterest)\n",
    "    \n",
    "    ## find the start and end ROW_ID for patient*encounter\n",
    "    \n",
    "    ADM_ID_START, ADM_ID_END = pd.read_sql_query('SELECT MIN(ROW_ID) AS min, MAX(ROW_ID) AS max FROM JAX_encounterOfInterest', mydb).iloc[0]\n",
    "    batch_N = ADM_ID_END - ADM_ID_START + 1\n",
    "    TOTAL_BATCH = math.ceil(batch_N / batch_size) # total number of batches\n",
    "\n",
    "    print('total batches: ' + str(batch_N))\n",
    "    pbar = tqdm(total=TOTAL_BATCH)\n",
    "    for i in np.arange(TOTAL_BATCH):\n",
    "        start_index = i * batch_size + ADM_ID_START\n",
    "        if i < TOTAL_BATCH - 1:\n",
    "            end_index = start_index + batch_size - 1\n",
    "        else:\n",
    "            end_index = batch_N\n",
    "        #print('start_index = {}, end_index = {}'.format(start_index, end_index))\n",
    "        actual_batch_size = end_index - start_index + 1\n",
    "        #print('actual batch size: {}'.format(actual_batch_size))\n",
    "        textHpo, labHpo = batch_query_lab_text(start_index, end_index, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max)\n",
    "        textHpo_matrix = textHpo.PHEN_TEXT_VALUE.values.astype(int).reshape([actual_batch_size, M1], order='F')\n",
    "        labHpo_matrix = labHpo.PHEN_LAB_VALUE.values.astype(int).reshape([actual_batch_size, M2], order='F')\n",
    "        #print(textHpo)\n",
    "        #print(labHpo)\n",
    "        #print(labHpo_matrix)\n",
    "        mf_rad_lab.add_batch(textHpo_matrix, labHpo_matrix)\n",
    "        pbar.update(1)\n",
    "        \n",
    "    pbar.close()\n",
    "    \n",
    "    return mf_rad_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 133.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total batches: 100\n",
      "start_index = 1, end_index = 11\n",
      "start_index = 12, end_index = 22\n",
      "start_index = 23, end_index = 33\n",
      "start_index = 34, end_index = 44\n",
      "start_index = 45, end_index = 55\n",
      "start_index = 56, end_index = 66\n",
      "start_index = 67, end_index = 77\n",
      "start_index = 78, end_index = 88\n",
      "start_index = 89, end_index = 99\n",
      "start_index = 100, end_index = 100\n",
      "[[[59.  5. 26. 10.]\n",
      "  [58.  6. 26. 10.]\n",
      "  [61.  3. 23. 13.]\n",
      "  [53. 11. 28.  8.]\n",
      "  [53. 11. 28.  8.]\n",
      "  [53. 11. 28.  8.]\n",
      "  [61.  3. 20. 16.]\n",
      "  [53. 11. 28.  8.]\n",
      "  [53. 11. 28.  8.]\n",
      "  [46. 18. 30.  6.]\n",
      "  [57.  7. 19. 17.]\n",
      "  [58.  6. 18. 18.]\n",
      "  [57.  7. 18. 18.]\n",
      "  [57.  7. 18. 18.]]\n",
      "\n",
      " [[55.  8. 30.  7.]\n",
      "  [57.  6. 27. 10.]\n",
      "  [58.  5. 26. 11.]\n",
      "  [51. 12. 30.  7.]\n",
      "  [51. 12. 30.  7.]\n",
      "  [51. 12. 30.  7.]\n",
      "  [59.  4. 22. 15.]\n",
      "  [51. 12. 30.  7.]\n",
      "  [51. 12. 30.  7.]\n",
      "  [46. 17. 30.  7.]\n",
      "  [55.  8. 21. 16.]\n",
      "  [56.  7. 20. 17.]\n",
      "  [55.  8. 20. 17.]\n",
      "  [55.  8. 20. 17.]]\n",
      "\n",
      " [[57.  5. 28. 10.]\n",
      "  [56.  6. 28. 10.]\n",
      "  [59.  3. 25. 13.]\n",
      "  [51. 11. 30.  8.]\n",
      "  [51. 11. 30.  8.]\n",
      "  [51. 11. 30.  8.]\n",
      "  [59.  3. 22. 16.]\n",
      "  [51. 11. 30.  8.]\n",
      "  [51. 11. 30.  8.]\n",
      "  [45. 17. 31.  7.]\n",
      "  [55.  7. 21. 17.]\n",
      "  [56.  6. 20. 18.]\n",
      "  [55.  7. 20. 18.]\n",
      "  [55.  7. 20. 18.]]\n",
      "\n",
      " [[55.  5. 30. 10.]\n",
      "  [54.  6. 30. 10.]\n",
      "  [57.  3. 27. 13.]\n",
      "  [50. 10. 31.  9.]\n",
      "  [50. 10. 31.  9.]\n",
      "  [50. 10. 31.  9.]\n",
      "  [57.  3. 24. 16.]\n",
      "  [50. 10. 31.  9.]\n",
      "  [50. 10. 31.  9.]\n",
      "  [43. 17. 33.  7.]\n",
      "  [53.  7. 23. 17.]\n",
      "  [54.  6. 22. 18.]\n",
      "  [53.  7. 22. 18.]\n",
      "  [53.  7. 22. 18.]]\n",
      "\n",
      " [[56.  4. 29. 11.]\n",
      "  [55.  5. 29. 11.]\n",
      "  [57.  3. 27. 13.]\n",
      "  [52.  8. 29. 11.]\n",
      "  [52.  8. 29. 11.]\n",
      "  [52.  8. 29. 11.]\n",
      "  [57.  3. 24. 16.]\n",
      "  [52.  8. 29. 11.]\n",
      "  [52.  8. 29. 11.]\n",
      "  [41. 19. 35.  5.]\n",
      "  [54.  6. 22. 18.]\n",
      "  [54.  6. 22. 18.]\n",
      "  [53.  7. 22. 18.]\n",
      "  [53.  7. 22. 18.]]\n",
      "\n",
      " [[47.  6. 38.  9.]\n",
      "  [49.  4. 35. 12.]\n",
      "  [49.  4. 35. 12.]\n",
      "  [43. 10. 38.  9.]\n",
      "  [43. 10. 38.  9.]\n",
      "  [43. 10. 38.  9.]\n",
      "  [49.  4. 32. 15.]\n",
      "  [43. 10. 38.  9.]\n",
      "  [43. 10. 38.  9.]\n",
      "  [39. 14. 37. 10.]\n",
      "  [46.  7. 30. 17.]\n",
      "  [47.  6. 29. 18.]\n",
      "  [46.  7. 29. 18.]\n",
      "  [46.  7. 29. 18.]]\n",
      "\n",
      " [[41.  6. 44.  9.]\n",
      "  [43.  4. 41. 12.]\n",
      "  [43.  4. 41. 12.]\n",
      "  [40.  7. 41. 12.]\n",
      "  [40.  7. 41. 12.]\n",
      "  [40.  7. 41. 12.]\n",
      "  [43.  4. 38. 15.]\n",
      "  [40.  7. 41. 12.]\n",
      "  [40.  7. 41. 12.]\n",
      "  [33. 14. 43. 10.]\n",
      "  [41.  6. 35. 18.]\n",
      "  [41.  6. 35. 18.]\n",
      "  [40.  7. 35. 18.]\n",
      "  [40.  7. 35. 18.]]\n",
      "\n",
      " [[43.  3. 42. 12.]\n",
      "  [42.  4. 42. 12.]\n",
      "  [44.  2. 40. 14.]\n",
      "  [40.  6. 41. 13.]\n",
      "  [40.  6. 41. 13.]\n",
      "  [40.  6. 41. 13.]\n",
      "  [44.  2. 37. 17.]\n",
      "  [40.  6. 41. 13.]\n",
      "  [40.  6. 41. 13.]\n",
      "  [34. 12. 42. 12.]\n",
      "  [42.  4. 34. 20.]\n",
      "  [42.  4. 34. 20.]\n",
      "  [40.  6. 35. 19.]\n",
      "  [40.  6. 35. 19.]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "encounterOfInterest(debug=True)\n",
    "indexEncounterOfInterest()\n",
    "diagnosisProfile()\n",
    "rankHpoFromText('')\n",
    "rankHpoFromLab('')\n",
    "\n",
    "batch_size = 11\n",
    "textHpo_threshold_min = 45\n",
    "textHpo_threshold_max = 65\n",
    "labHpo_threshold_min = 75\n",
    "labHpo_threshold_max = 85\n",
    "\n",
    "mf_all = overall_mf(batch_size,textHpo_threshold_min,textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max)\n",
    "\n",
    "print(mf_all.m)\n",
    "#print(mf_all.X_names)\n",
    "#print(mf_all.Y_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/590 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total batches: 58976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 590/590 [14:22<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[5.4071e+04 7.5400e+02 3.7120e+03 4.3900e+02]\n",
      "  [5.4071e+04 7.5400e+02 3.7120e+03 4.3900e+02]\n",
      "  [5.3797e+04 1.0280e+03 3.5660e+03 5.8500e+02]\n",
      "  ...\n",
      "  [1.0940e+03 5.3731e+04 0.0000e+00 4.1510e+03]\n",
      "  [1.0230e+03 5.3802e+04 3.0000e+00 4.1480e+03]\n",
      "  [1.0230e+03 5.3802e+04 3.0000e+00 4.1480e+03]]\n",
      "\n",
      " [[5.4071e+04 7.5400e+02 3.7120e+03 4.3900e+02]\n",
      "  [5.4071e+04 7.5400e+02 3.7120e+03 4.3900e+02]\n",
      "  [5.3797e+04 1.0280e+03 3.5660e+03 5.8500e+02]\n",
      "  ...\n",
      "  [1.0940e+03 5.3731e+04 0.0000e+00 4.1510e+03]\n",
      "  [1.0230e+03 5.3802e+04 3.0000e+00 4.1480e+03]\n",
      "  [1.0230e+03 5.3802e+04 3.0000e+00 4.1480e+03]]\n",
      "\n",
      " [[4.8069e+04 5.0800e+02 9.7140e+03 6.8500e+02]\n",
      "  [4.8069e+04 5.0800e+02 9.7140e+03 6.8500e+02]\n",
      "  [4.7890e+04 6.8700e+02 9.4730e+03 9.2600e+02]\n",
      "  ...\n",
      "  [1.0270e+03 4.7550e+04 6.7000e+01 1.0332e+04]\n",
      "  [9.5800e+02 4.7619e+04 6.8000e+01 1.0331e+04]\n",
      "  [9.5800e+02 4.7619e+04 6.8000e+01 1.0331e+04]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[5.1000e+02 0.0000e+00 5.7273e+04 1.1930e+03]\n",
      "  [5.1000e+02 0.0000e+00 5.7273e+04 1.1930e+03]\n",
      "  [5.1000e+02 0.0000e+00 5.6853e+04 1.6130e+03]\n",
      "  ...\n",
      "  [7.0000e+00 5.0300e+02 1.0870e+03 5.7379e+04]\n",
      "  [2.2000e+01 4.8800e+02 1.0040e+03 5.7462e+04]\n",
      "  [2.2000e+01 4.8800e+02 1.0040e+03 5.7462e+04]]\n",
      "\n",
      " [[5.0400e+02 0.0000e+00 5.7279e+04 1.1930e+03]\n",
      "  [5.0400e+02 0.0000e+00 5.7279e+04 1.1930e+03]\n",
      "  [5.0300e+02 1.0000e+00 5.6860e+04 1.6120e+03]\n",
      "  ...\n",
      "  [8.0000e+00 4.9600e+02 1.0860e+03 5.7386e+04]\n",
      "  [2.6000e+01 4.7800e+02 1.0000e+03 5.7472e+04]\n",
      "  [2.6000e+01 4.7800e+02 1.0000e+03 5.7472e+04]]\n",
      "\n",
      " [[4.9800e+02 4.0000e+00 5.7285e+04 1.1890e+03]\n",
      "  [4.9800e+02 4.0000e+00 5.7285e+04 1.1890e+03]\n",
      "  [4.9600e+02 6.0000e+00 5.6867e+04 1.6070e+03]\n",
      "  ...\n",
      "  [7.0000e+00 4.9500e+02 1.0870e+03 5.7387e+04]\n",
      "  [2.5000e+01 4.7700e+02 1.0010e+03 5.7473e+04]\n",
      "  [2.5000e+01 4.7700e+02 1.0010e+03 5.7473e+04]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# production\n",
    "encounterOfInterest(debug=False)\n",
    "indexEncounterOfInterest()\n",
    "diagnosisProfile()\n",
    "rankHpoFromText('')\n",
    "rankHpoFromLab('')\n",
    "\n",
    "batch_size = 100\n",
    "textHpo_threshold_min = 500\n",
    "textHpo_threshold_max = 100000\n",
    "labHpo_threshold_min = 1000\n",
    "labHpo_threshold_max = 100000\n",
    "\n",
    "\n",
    "mf_all = overall_mf(batch_size,textHpo_threshold_min,textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max)\n",
    "\n",
    "print(mf_all.m)\n",
    "#print(mf_all.X_names)\n",
    "#print(mf_all.Y_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_all=mf_all2\n",
    "textHpo_labels = mf_all.X_names\n",
    "labHpo_labels = mf_all.Y_names\n",
    "M1 = len(mf_all.X_names)\n",
    "M2 = len(mf_all.Y_names)\n",
    "entropy_x, entropy_y = mf_all.entropies().values()\n",
    "mf_all_df = pd.DataFrame(data={'P1': np.repeat(textHpo_labels, M2), 'P2': np.tile(labHpo_labels, [M1]),'entropy_P1': np.repeat(entropy_x, M2), 'entropy_P2': np.tile(entropy_y, [M1]), 'mf_P1_P2': mf_all.mf().flat})\n",
    "mf_all_df.head()\n",
    "mf_all_df.to_csv('mutual_info_textHpo_labHpo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>entropy_P1</th>\n",
       "      <th>entropy_P2</th>\n",
       "      <th>mf_P1_P2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>HP:0000001</td>\n",
       "      <td>HP:0012337</td>\n",
       "      <td>0.367357</td>\n",
       "      <td>0.537873</td>\n",
       "      <td>0.191295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>HP:0000118</td>\n",
       "      <td>HP:0012337</td>\n",
       "      <td>0.367357</td>\n",
       "      <td>0.537873</td>\n",
       "      <td>0.191295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>HP:0000118</td>\n",
       "      <td>HP:0003111</td>\n",
       "      <td>0.367357</td>\n",
       "      <td>0.601487</td>\n",
       "      <td>0.173719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>HP:0000001</td>\n",
       "      <td>HP:0003111</td>\n",
       "      <td>0.367357</td>\n",
       "      <td>0.601487</td>\n",
       "      <td>0.173719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>HP:0000118</td>\n",
       "      <td>HP:0011015</td>\n",
       "      <td>0.367357</td>\n",
       "      <td>0.656426</td>\n",
       "      <td>0.159461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             P1          P2  entropy_P1  entropy_P2  mf_P1_P2\n",
       "8    HP:0000001  HP:0012337    0.367357    0.537873  0.191295\n",
       "228  HP:0000118  HP:0012337    0.367357    0.537873  0.191295\n",
       "230  HP:0000118  HP:0003111    0.367357    0.601487  0.173719\n",
       "10   HP:0000001  HP:0003111    0.367357    0.601487  0.173719\n",
       "236  HP:0000118  HP:0011015    0.367357    0.656426  0.159461"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_all_df.head()\n",
    "mf_all_df.sort_values(by='mf_P1_P2', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare phenotypes for machine learning tasks. For specified disease of interest, find the patient info (gender, DOB), find the diagnosis info (case or control, date), and phenotype terms.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encounterOfInterest(debug=False, N=100)\n",
    "indexEncounterOfInterest()\n",
    "diagnosisProfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = pd.read_sql_query('''\n",
    "        SELECT \n",
    "            PATIENTS.SUBJECT_ID, PATIENTS.GENDER, PATIENTS.DOB\n",
    "        FROM \n",
    "            PATIENTS\n",
    "        WHERE \n",
    "            SUBJECT_ID IN (SELECT SUBJECT_ID FROM JAX_encounterOfInterest) \n",
    "    ''', mydb)\n",
    "\n",
    "len(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createDiagnosisTable(diagnosis='038', primary_diagnosis_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_diag_time(diagnosis):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_first_diag_time')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_first_diag_time\n",
    "        WITH diag_time AS (\n",
    "            SELECT L.*, R.ADMITTIME \n",
    "            FROM JAX_mf_diag AS L\n",
    "            JOIN ADMISSIONS AS R\n",
    "            ON \n",
    "                L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID\n",
    "        ), \n",
    "        overallDiagnosis AS (\n",
    "            SELECT *, IF(SUM(DIAGNOSIS) OVER (PARTITION BY SUBJECT_ID) > 0, 1, 0) AS everDiagnosed\n",
    "            FROM diag_time\n",
    "        )\n",
    "        \n",
    "        SELECT \n",
    "            *, MIN(IF(everDiagnosed = 1, ADMITTIME, NULL) ) OVER (PARTITION BY SUBJECT_ID) AS first_diag, \n",
    "            MAX(IF(everDiagnosed = 0, ADMITTIME, NULL)) OVER (PARTITION BY SUBJECT_ID) AS last_visit_if_not_diagnosed\n",
    "        FROM \n",
    "            overallDiagnosis  \n",
    "    '''.format(diagnosis))\n",
    "\n",
    "first_diag_time('038')\n",
    "pd.read_sql_query('SELECT * FROM JAX_first_diag_time LIMIT 5', mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encountersAfterDiagnosis():\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_encounters_after_diagnosis')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_encounters_after_diagnosis\n",
    "            SELECT *, 1 AS toIgnore\n",
    "            FROM JAX_first_diag_time\n",
    "            WHERE DIAGNOSIS = 1 AND ADMITTIME > first_diag\n",
    "    ''')\n",
    "    cursor.execute('CREATE INDEX JAX_encounters_after_diagnosis_idx01 ON JAX_encounters_after_diagnosis (SUBJECT_ID, HADM_ID)')\n",
    "    \n",
    "encountersAfterDiagnosis() \n",
    "pd.read_sql_query(\"SELECT * FROM JAX_encounters_after_diagnosis LIMIT 5\", mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_vector = pd.read_sql_query('''\n",
    "        SELECT\n",
    "            SUBJECT_ID, IF(SUM(DIAGNOSIS)>0, 1, 0) AS DIAGNOSED, MAX(IF(everDiagnosed = 1, first_diag, last_visit_if_not_diagnosed)) AS LAST_VISIT\n",
    "        FROM\n",
    "            JAX_first_diag_time\n",
    "        GROUP BY SUBJECT_ID\n",
    "    ''', mydb)\n",
    "diagnosis_vector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab_phenotype_before_diagnosis():\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_phen_lab_before_diag')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_phen_lab_before_diag\n",
    "        WITH temp as (\n",
    "            SELECT L.*, W.toIgnore\n",
    "            FROM JAX_LABHPOPROFILE AS L\n",
    "            JOIN JAX_mf_diag AS R ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID\n",
    "            LEFT JOIN JAX_encounters_after_diagnosis W on  L.SUBJECT_ID = W.SUBJECT_ID AND L.HADM_ID = W.HADM_ID\n",
    "        )\n",
    "        SELECT SUBJECT_ID, MAP_TO, COUNT(*) as N\n",
    "        FROM temp\n",
    "        WHERE toIgnore IS NULL\n",
    "        GROUP BY SUBJECT_ID, MAP_TO\n",
    "    ''')\n",
    "    cursor.execute('CREATE INDEX JAX_phen_lab_before_diag_idx01 ON JAX_phen_lab_before_diag (N)')\n",
    "    \n",
    "\n",
    "def text_phenotype_before_diagnosis():\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_phen_text_before_diag')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_phen_text_before_diag\n",
    "        WITH temp as (\n",
    "            SELECT L.*, W.toIgnore\n",
    "            FROM JAX_TEXTHPOPROFILE AS L\n",
    "            JOIN JAX_mf_diag AS R ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID\n",
    "            LEFT JOIN JAX_encounters_after_diagnosis W on  L.SUBJECT_ID = W.SUBJECT_ID AND L.HADM_ID = W.HADM_ID\n",
    "        )\n",
    "        SELECT SUBJECT_ID, MAP_TO, COUNT(*) as N\n",
    "        FROM temp\n",
    "        WHERE toIgnore IS NULL\n",
    "        GROUP BY SUBJECT_ID, MAP_TO\n",
    "    ''')\n",
    "    cursor.execute('CREATE INDEX JAX_phen_text_before_diag_idx01 ON JAX_phen_text_before_diag (N)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lab_phenotype_before_diagnosis()\n",
    "lab_phenotype_vector = pd.read_sql_query('''\n",
    "    SELECT * FROM JAX_phen_lab_before_diag WHERE N >= {}\n",
    "'''.format(1), mydb)\n",
    "lab_phenotype_vector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_phenotype_before_diagnosis()\n",
    "text_phenotype_vector = pd.read_sql_query('''\n",
    "    SELECT * FROM JAX_phen_text_before_diag WHERE N >= {}\n",
    "'''.format(1), mydb)\n",
    "text_phenotype_vector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = lab_phenotype_vector.merge(text_phenotype_vector, on = ['SUBJECT_ID', 'MAP_TO'])\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(data={'x': ['a', 'b', 'c'], 'v': [1, 2, 3]}).set_index('x')\n",
    "b = pd.DataFrame(data={'x': ['a', 'c', 'd'], 'v': [4, 5, 6]}).set_index('x')\n",
    "print(a)\n",
    "print(b)\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = phenotype_vector.pivot_table(values='N', index='SUBJECT_ID', columns='MAP_TO', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = patients.merge(m, on = 'SUBJECT_ID', how = 'left').sort_values(by = 'SUBJECT_ID').set_index('SUBJECT_ID')\n",
    "X = X.drop('DOB', axis=1).fillna(value=0)\n",
    "X.head(n = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diagnosis_vector.sort_values(by = 'SUBJECT_ID').set_index('SUBJECT_ID')\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = X.dtypes == object\n",
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = pd.get_dummies(X.GENDER)\n",
    "X = X.drop('GENDER', axis=1).merge(sex, left_index=True, right_index=True).drop('F', axis=1)\n",
    "X.M = X.M.astype(float)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_test.IsDiagnosed)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "mydb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
