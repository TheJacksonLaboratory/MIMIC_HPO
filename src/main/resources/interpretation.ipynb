{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phenotype Synergy Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook contains code to interprete results from the synergy score analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "mf_module_path = os.path.abspath(os.path.join('../python'))\n",
    "if mf_module_path not in sys.path:\n",
    "    sys.path.append(mf_module_path)\n",
    "import mf\n",
    "import mf_random\n",
    "import hpoutil\n",
    "import networkx\n",
    "import obonet\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo = hpoutil.HPO('/Users/zhangx/git/human-phenotype-ontology/hp.obo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synergy among Lab-derived Abnormal Phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('synergies.obj', 'rb') as synergies_file:\n",
    "    deserialized = pickle.load(synergies_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(deserialized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the synergy scores. They are all pretty small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_failure = deserialized['428']\n",
    "plt.hist(heart_failure.pairwise_synergy().flat, bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load p values estimated from empirical distributions\n",
    "path = '/Users/zhangx/git/MIMIC_HPO/src/main/resources/p_value_map_428.obj'\n",
    "with open(path, 'rb') as f:\n",
    "    p_value_map = pickle.load(f)\n",
    "p_heart_failure = p_value_map['428']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = heart_failure.pairwise_synergy_labeled_with_p_values(p_heart_failure)\n",
    "data.reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove duplication record: (HP1, HP2) is the same to (HP2, HP1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array([hpo.has_dependency(data.P1[i], data.P2[i]) for i in np.arange(data.shape[0])])\n",
    "S_heart_failure = data.loc[np.logical_not(mask), :].sort_values(by = 'synergy', ascending=False)\n",
    "S_heart_failure = S_heart_failure.loc[S_heart_failure.P1 < S_heart_failure.P2, :]\n",
    "S_heart_failure['P1_label'] = np.array([hpo.term_id2name_map().get(termid) for termid in S_heart_failure.P1])\n",
    "S_heart_failure['P2_label'] = np.array([hpo.term_id2name_map().get(termid) for termid in S_heart_failure.P2])\n",
    "top5percent_synergy_pair_heart_failure = S_heart_failure.iloc[0:math.ceil(0.05 * len(S_heart_failure)), :]\n",
    "top5percent_synergy_pair_heart_failure.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5percent_synergy_pair_heart_failure.to_csv('top5percent_synergy_pair_heart_failure.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acute_renal_failure = deserialized['584']\n",
    "plt.hist(acute_renal_failure.pairwise_synergy().flat, bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load p values estimated from empirical distributions\n",
    "path = '/Users/zhangx/git/MIMIC_HPO/src/main/resources/p_value_map_584.obj'\n",
    "with open(path, 'rb') as f:\n",
    "    p_value_map = pickle.load(f)\n",
    "p_renal_failure = p_value_map['584']\n",
    "data = acute_renal_failure.pairwise_synergy_labeled_with_p_values(p_renal_failure)\n",
    "data.reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array([hpo.has_dependency(data.P1[i], data.P2[i]) for i in np.arange(data.shape[0])])\n",
    "S_acute_renal_failure = data.loc[np.logical_not(mask), :].sort_values(by = 'synergy', ascending=False)\n",
    "S_acute_renal_failure = S_acute_renal_failure.loc[S_acute_renal_failure.P1 < S_acute_renal_failure.P2, :]\n",
    "S_acute_renal_failure['P1_label'] = np.array([hpo.term_id2name_map().get(termid) for termid in S_acute_renal_failure.P1])\n",
    "S_acute_renal_failure['P2_label'] = np.array([hpo.term_id2name_map().get(termid) for termid in S_acute_renal_failure.P2])\n",
    "top5percent_synergy_pair_acute_renal_failure = S_acute_renal_failure.iloc[0:math.ceil(0.05 * len(S_acute_renal_failure)), :]\n",
    "top5percent_synergy_pair_acute_renal_failure.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5percent_synergy_pair_acute_renal_failure.to_csv('top5percent_synergy_pair_acute_renal_failure.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepsis = deserialized['038']\n",
    "plt.hist(sepsis.pairwise_synergy().flat, bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load p values estimated from empirical distributions\n",
    "path = '/Users/zhangx/git/MIMIC_HPO/src/main/resources/p_value_map_038.obj'\n",
    "with open(path, 'rb') as f:\n",
    "    p_value_map = pickle.load(f)\n",
    "p_sepsis = p_value_map['038']\n",
    "data = sepsis.pairwise_synergy_labeled_with_p_values(p_sepsis)\n",
    "data.reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array([hpo.has_dependency(data.P1[i], data.P2[i]) for i in np.arange(data.shape[0])])\n",
    "S_sepsis = data.loc[np.logical_not(mask), :].sort_values(by = 'synergy', ascending=False)\n",
    "S_sepsis = S_sepsis.loc[S_sepsis.P1 < S_sepsis.P2, :]\n",
    "top5percent = S_sepsis.shape[0] * 0.05\n",
    "top5percent_synergy_pair_sepsis = S_sepsis.reset_index(drop=True).iloc[0:int(top5percent), :]\n",
    "top5percent_synergy_pair_sepsis['P1_label'] = np.array([hpo.term_id2name_map().get(termid) for termid in top5percent_synergy_pair_sepsis.P1])\n",
    "top5percent_synergy_pair_sepsis['P2_label'] = np.array([hpo.term_id2name_map().get(termid) for termid in top5percent_synergy_pair_sepsis.P2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5percent_synergy_pair_sepsis.head(n = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5percent_synergy_pair_sepsis.to_csv('top5percent_synergy_pair_sepsis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Synergy between Radiology- and Lab-derived Abnormal Phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('synergies_radiology_lab_primary_and_secondary.obj', 'rb') as synergies_file:\n",
    "    synergies_rad_lab = pickle.load(synergies_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(synergies_rad_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_p_values(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        p = pickle.load(f)\n",
    "    return p\n",
    "\n",
    "def filtered_synergy_dataframe(synergy, p_values=None, percentile_cut=None):\n",
    "    if p_values is not None:\n",
    "        data = synergy.pairwise_synergy_labeled_with_p_values(p_values)\n",
    "    else:\n",
    "        data = synergy.pairwise_synergy_labeled()\n",
    "    # remove directly dependent terms \n",
    "    mask = np.array([hpo.has_dependency(data.P1[i], data.P2[i]) for i in np.arange(data.shape[0])])\n",
    "    data_filtered = data.loc[np.logical_not(mask), :].sort_values(by = 'synergy', ascending=False)\n",
    "    data_filtered = data_filtered.loc[data_filtered.P1 < data_filtered.P2, :]\n",
    "    data_filtered['P1_radiology_label'] = np.array([hpo.term_id2name_map().get(termid) for termid in data_filtered.P1])\n",
    "    data_filtered['P2_lab_label'] = np.array([hpo.term_id2name_map().get(termid) for termid in data_filtered.P2])\n",
    "    \n",
    "    \n",
    "    if (percentile_cut == None):\n",
    "        percentile = 1\n",
    "    else:\n",
    "        percentile = percentile_cut / 100\n",
    "    top_percentile = data_filtered.iloc[0:math.ceil(percentile * len(data_filtered)), :]\n",
    "    \n",
    "    \n",
    "    I, II = synergy.mutual_information()\n",
    "    Ia, Ib = I.values()\n",
    "    p1_labels, p2_labels = synergy.vars_labels.values()\n",
    "    mf_P1 = pd.DataFrame(data={'P1': p1_labels, 'mf_P1': Ia})\n",
    "    mf_P2 = pd.DataFrame(data={'P2': p2_labels, 'mf_P2': Ib})\n",
    "    mf_d_P1P2 = pd.DataFrame(data={'P1': np.repeat(p1_labels, len(p2_labels)), 'P2': np.tile(p2_labels, [len(p1_labels)]), 'mf_d_P1P2': II.flat})\n",
    "    fully_labeled = top_percentile.merge(mf_P1, on='P1').merge(mf_P2, on='P2').merge(mf_d_P1P2, on=['P1', 'P2'])\n",
    "    \n",
    "    \n",
    "    return fully_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p_values = load_p_values('p_value_428.obj')\n",
    "filtered_data = filtered_synergy_dataframe(synergies_rad_lab, icd = '428', icd_label = 'heart_failure', p_values=None, percentile_cut = 5)\n",
    "filtered_data.to_csv('synergy-radiology_labtest-428_primary_and_secondary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p_value = load_p_values('p_value_584.obj')\n",
    "filtered_data = filtered_synergy_dataframe(synergies_rad_lab, icd = '584', icd_label = 'acute_renal_failure', p_values=None, percentile_cut = 5)\n",
    "filtered_data.to_csv('synergy-radiology-labtest-584_primary_and_secondary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p_values = load_p_values('p_value_038.obj')\n",
    "filtered_data = filtered_synergy_dataframe(synergies_rad_lab, icd = '038', icd_label = 'sepsis', p_values=None, percentile_cut = 5)\n",
    "filtered_data.to_csv('synergy-radiology_labtest-038_primary_and_secondary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just look at primary diagnosis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_all = pd.read_csv('mutual_info_textHpo_labHpo.csv')\n",
    "mf_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('synergies_radiology_lab_primary_diagnosis_only_corrected.obj', 'rb') as synergies_file:\n",
    "    synergies_rad_lab_primary_only = pickle.load(synergies_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p_values = load_p_values('p_value_428_primary_only.obj')\n",
    "synergy = synergies_rad_lab_primary_only['428']\n",
    "filtered_data = filtered_synergy_dataframe(synergy, p_values=None, percentile_cut = 5)\n",
    "include_overall_mf = filtered_data.merge(mf_all, on=['P1', 'P2'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_overall_mf.sort_values(by='synergy', ascending=False).head(20)\n",
    "include_overall_mf.sort_values(by='synergy', ascending=False).to_csv('synergy-radiology_labtest_primary_only-428_corrected.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p_values = load_p_values('p_value_584_primary_only.obj')\n",
    "synergy = synergies_rad_lab_primary_only['584']\n",
    "filtered_data = filtered_synergy_dataframe(synergy, p_values=None, percentile_cut = 5)\n",
    "include_overall_mf = filtered_data.merge(mf_all, on=['P1', 'P2'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_overall_mf.sort_values(by='synergy', ascending=False).head(20)\n",
    "include_overall_mf.sort_values(by='synergy', ascending=False).to_csv('synergy-radiology_labtest_primary_only-584_corrected.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p_values = load_p_values('p_value_038_primary_only.obj')\n",
    "synergy = synergies_rad_lab_primary_only['038']\n",
    "filtered_data = filtered_synergy_dataframe(synergy, p_values=None, percentile_cut = 5)\n",
    "include_overall_mf = filtered_data.merge(mf_all, on=['P1', 'P2'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_overall_mf.sort_values(by='synergy', ascending=False).head(20)\n",
    "include_overall_mf.sort_values(by='synergy', ascending=False).to_csv('synergy-radiology_labtest_primary_only-038_corrected.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
