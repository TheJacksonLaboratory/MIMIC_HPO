{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "mf_module_path = os.path.abspath(os.path.join('../python'))\n",
    "if mf_module_path not in sys.path:\n",
    "    sys.path.append(mf_module_path)\n",
    "import mf\n",
    "import mf_random\n",
    "import synergy_tree\n",
    "from ontology import Ontology\n",
    "import pickle\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connect to MySQL database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(host='localhost',\n",
    "                               user='mimicuser',\n",
    "                               passwd='mimic',\n",
    "                               database='mimiciiiv13',\n",
    "                              auth_plugin='mysql_native_password')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First approach to query mysql from python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that MySQL connection works properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ITEMID</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>VALUENUM</th>\n",
       "      <th>VALUEUOM</th>\n",
       "      <th>FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>51143</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>51144</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>51146</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>51200</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>51221</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>%</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID  SUBJECT_ID  HADM_ID  ITEMID           CHARTTIME  VALUE  VALUENUM  \\\n",
       "0       1           2   163353   51143 2138-07-17 20:48:00      0       0.0   \n",
       "1       2           2   163353   51144 2138-07-17 20:48:00      0       0.0   \n",
       "2       3           2   163353   51146 2138-07-17 20:48:00      0       0.0   \n",
       "3       4           2   163353   51200 2138-07-17 20:48:00      0       0.0   \n",
       "4       5           2   163353   51221 2138-07-17 20:48:00      0       0.0   \n",
       "\n",
       "  VALUEUOM      FLAG  \n",
       "0        %      None  \n",
       "1        %      None  \n",
       "2        %      None  \n",
       "3        %      None  \n",
       "4        %  abnormal  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM LABEVENTS LIMIT 5;\", mydb)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a cursor so that it can be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = mydb.cursor(buffered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explored several method to compute the synergy score for different diseases. Method 1-3 all worked but the time and space requirements are too high. See the archived file. Here, we use method 4 to compute phenotype pairwise synergies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synergy between Lab-derived Abnormalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This method relies on the power of MySQL for doing queies and joins, return a batch of phenotype profiles a time, and then use the power of Numpy to do numeric computation.\n",
    "\n",
    "Specificially, the method runs the following algorithm:\n",
    "\n",
    "    1. For one diagnosis code, specify the phenotypes to analyze--a list of HPO terms.\n",
    "    2. For a batch of patient encounters, return a list of diagnosis codes (1 or 0)\n",
    "    3. For the same batch of patient*encounters, return a list of phenotypes.\n",
    "    4. Create a numpy array with dimension (N x P)\n",
    "    5. Perform numeric computation with Numpy:\n",
    "        outer product for ++ of PxP.T\n",
    "        outer product for +- of Px(1-P).T\n",
    "        outer product for -+ of (1-P)xP\n",
    "        outer product for -- of (1-P)x(1-P).T\n",
    "        combine the above with - and + of diagnosis value\n",
    "        stack them together as a (N x P x P x 8) matrix.\n",
    "        Step 1 - 5 are performed at each site. The resulting matrix is returned to JAX for final analyze.\n",
    "    6. Compute pairwise synergy:\n",
    "        use the multi-dimension array to calculate p(D = 1), p(D = 0), p(P1 * P2)\n",
    "        compute mutual information of each phenotype in regarding to one diagnosis I(P:D)\n",
    "        compute mutual information of two phenotypes in regarding to one diagnosis I(P:D)\n",
    "        compute pairwise synergy\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Synergy between lab-derived and radiology report-derived Abnormalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm is about the same. Briefly, \n",
    "\n",
    "    * Select encounterOfInterest, temp table: JAX_encounterOfInterest(SUBJECT_ID, HADM_ID)\n",
    "    * Init diagnosisProfile: temp table: JAX_diagnosisProfile(SUBJECT_ID, HADM_ID, ICD, N)\n",
    "    * Init textHpoProfile: temp table: JAX_textHpoProfile(SUBJECT_ID, HADM_ID, MAP_TO, N)\n",
    "    * Init labHpoProfile: temp table: JAX_labHpoProfile(SUBJECT_ID, HADM_ID, MAP_TO, N)\n",
    "    \n",
    "    * Rank ICD frequency, temp table: JAX_diagFrequencyRank(ICD, N)\n",
    "      select diagOfInterest\n",
    "    * Rank textHPO frequency, temp table: JAX_textHpoFrequencyRank(MAP_TO, N)\n",
    "      select textHpoOfInterest\n",
    "    * Rank labHPO frequency, temp table: JAX_labHpoFrequencyRank(MAP_TO, N)\n",
    "      select labHpoOfInterest\n",
    "    \n",
    "    * Iteratation\n",
    "      for diagnosis in diagOfInterest\n",
    "          for textHpo in textHpoOfInterest\n",
    "              for labHpo in labHpoOfInterest\n",
    "                 Assign diagnosis value: assignDiagnosis(), table: (SUBJECT_ID, HADM_ID, DIAGNOSIS)\n",
    "                 Assign text2hpo phenotype value: table: SUBJECT_ID, HADM_ID, PHEN_TEXT\n",
    "                 Assign lab2hpo phenotype value: table: SUBJECT_ID, HADM_ID, PHEN_LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm implemention\n",
    "The mutual information theory and algorithm is described in the following paper:\n",
    "\n",
    "\n",
    "    Anastassiou D, Computational analysis of the synergy among multiple\n",
    "    interacting genes. Molecular System Biology 3:83\n",
    "\n",
    "The algorithm is implemented in Python [link](https://github.com/TheJacksonLaboratory/MIMIC_HPO/blob/export_intermediate_data/src/main/python/mf.py). Python is chosen over Java because the numeric computation library (Numpy) in python is better (?) and easier to use (sure) than Java counterparts.\n",
    "\n",
    "Methods defined below are to prepare MySql database, query data, format them and call the mutual information algorithm implementation. \n",
    "\n",
    "The results are summary statistics that do not contain any PHI. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encounterOfInterest(debug=False, N=100):\n",
    "    \"\"\"\n",
    "    Define encounters of interest. The method is not finalized yet. Currently, it will use all encounters in our database. \n",
    "    @param debug: set to True to select a small subset for testing\n",
    "    @param N: limit the number of encounters when debug is set to True. If debug is set to False, N is ignored.  \n",
    "    \"\"\"\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_encounterOfInterest')\n",
    "    if debug:\n",
    "        limit = 'LIMIT {}'.format(N)\n",
    "    else:\n",
    "        limit = ''\n",
    "    # This is admissions that we want to analyze, 'LIMIT 100' in debug mode\n",
    "    cursor.execute('''\n",
    "                CREATE TEMPORARY TABLE IF NOT EXISTS JAX_encounterOfInterest(\n",
    "                    ROW_ID MEDIUMINT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY)\n",
    "                \n",
    "                SELECT \n",
    "                    DISTINCT SUBJECT_ID, HADM_ID \n",
    "                FROM admissions\n",
    "                {}\n",
    "                '''.format(limit))\n",
    "    \n",
    "def indexEncounterOfInterest():\n",
    "    \"\"\"\n",
    "    Create index on encounters table.\n",
    "    \"\"\"\n",
    "    cursor.execute('CREATE INDEX JAX_encounterOfInterest_idx01 ON JAX_encounterOfInterest (SUBJECT_ID, HADM_ID)')\n",
    "    \n",
    "def diagnosisProfile():\n",
    "    \"\"\"\n",
    "    For encounters of interest, find all of their diagnosis codes\n",
    "    \"\"\"\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_diagnosisProfile')\n",
    "    cursor.execute('''\n",
    "                CREATE TEMPORARY TABLE IF NOT EXISTS JAX_diagnosisProfile\n",
    "                SELECT \n",
    "                    DIAGNOSES_ICD.SUBJECT_ID, DIAGNOSES_ICD.HADM_ID, DIAGNOSES_ICD.ICD9_CODE, DIAGNOSES_ICD.SEQ_NUM\n",
    "                FROM\n",
    "                    DIAGNOSES_ICD\n",
    "                RIGHT JOIN\n",
    "                    JAX_encounterOfInterest\n",
    "                ON \n",
    "                    DIAGNOSES_ICD.SUBJECT_ID = JAX_encounterOfInterest.SUBJECT_ID \n",
    "                    AND \n",
    "                    DIAGNOSES_ICD.HADM_ID = JAX_encounterOfInterest.HADM_ID\n",
    "                ''')\n",
    "    \n",
    "def textHpoProfile(include_inferred=True):\n",
    "    \"\"\"\n",
    "    Set up a table for patient phenotypes from text mining. By default, merge directly mapped HPO terms and inferred terms.\n",
    "    It is currently defined as a temporary table. But in reality, it is created as a perminent table as it takes a long time to init, and it is going to be used multiple times. \n",
    "    \"\"\"\n",
    "    if include_inferred:\n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS JAX_textHpoProfile\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            NOTEEVENTS.SUBJECT_ID, NOTEEVENTS.HADM_ID, NoteHpoClinPhen.MAP_TO\n",
    "                        FROM \n",
    "                            NOTEEVENTS \n",
    "                        JOIN NoteHpoClinPhen on NOTEEVENTS.ROW_ID = NoteHpoClinPhen.NOTES_ROW_ID\n",
    "                        \n",
    "                        UNION ALL\n",
    "                        \n",
    "                        SELECT\n",
    "                            NOTEEVENTS.SUBJECT_ID, NOTEEVENTS.HADM_ID, Inferred_NoteHpo.INFERRED_TO AS MAP_TO\n",
    "                        FROM \n",
    "                            NOTEEVENTS \n",
    "                        JOIN Inferred_NoteHpo on NOTEEVENTS.ROW_ID = Inferred_NoteHpo.NOTEEVENT_ROW_ID\n",
    "                        )\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO, COUNT(*) AS OCCURRANCE, 1 AS dummy\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                ''')\n",
    "        \n",
    "    else:\n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS JAX_p_text\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            NOTEEVENTS.SUBJECT_ID, NOTEEVENTS.HADM_ID, NoteHpoClinPhen.MAP_TO\n",
    "                        FROM \n",
    "                            NOTEEVENTS \n",
    "                        JOIN NoteHpoClinPhen on NOTEEVENTS.ROW_ID = NoteHpoClinPhen.NOTES_ROW_ID)\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO, COUNT(*) AS OCCURRANCE, 1 AS dummy\n",
    "                ''')\n",
    "        \n",
    "def indexTextHpoProfile():\n",
    "    \"\"\"\n",
    "    Create indeces to speed up query\n",
    "    \"\"\"\n",
    "    #_idx01 is unnecessary if _idx3 exists\n",
    "    #cursor.execute('CREATE INDEX JAX_textHpoProfile_idx01 ON JAX_textHpoProfile (SUBJECT_ID, HADM_ID)')\n",
    "    cursor.execute('CREATE INDEX JAX_textHpoProfile_idx02 ON JAX_textHpoProfile (MAP_TO);')\n",
    "    cursor.execute('CREATE INDEX JAX_textHpoProfile_idx03 ON JAX_textHpoProfile (SUBJECT_ID, HADM_ID, MAP_TO)')\n",
    "    cursor.execute('CREATE INDEX JAX_textHpoProfile_idx04 ON JAX_textHpoProfile (OCCURRANCE)')\n",
    "    \n",
    "def labHpoProfile(include_inferred=True):\n",
    "    \"\"\"\n",
    "    Set up a table for lab tests-derived phenotypes. By default, also include phenotypes that are inferred from direct mapping.\n",
    "    Similar to textHpoProfile, this could be created as a perminent table. \n",
    "    \"\"\"\n",
    "    cursor.execute('''DROP TEMPORARY TABLE IF EXISTS JAX_labHpoProfile''')\n",
    "    if include_inferred:\n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS JAX_labHpoProfile\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, LabHpo.MAP_TO\n",
    "                        FROM \n",
    "                            LABEVENTS \n",
    "                        JOIN LabHpo on LABEVENTS.ROW_ID = LabHpo.ROW_ID\n",
    "                        WHERE LabHpo.NEGATED = 'F'\n",
    "                        \n",
    "                        UNION ALL\n",
    "                        \n",
    "                        SELECT \n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, INFERRED_LABHPO.INFERRED_TO AS MAP_TO \n",
    "                        FROM \n",
    "                            INFERRED_LABHPO \n",
    "                        JOIN \n",
    "                            LABEVENTS ON INFERRED_LABHPO.LABEVENT_ROW_ID = LABEVENTS.ROW_ID\n",
    "                        )\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO, COUNT(*) AS OCCURRANCE, 1 AS dummy\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                ''')\n",
    "    else:       \n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS JAX_labHpoProfile\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, LabHpo.MAP_TO\n",
    "                        FROM \n",
    "                            LABEVENTS \n",
    "                        JOIN LabHpo on LABEVENTS.ROW_ID = LabHpo.ROW_ID\n",
    "                        WHERE LabHpo.NEGATED = 'F')\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO, COUNT(*) AS OCCURRANCE, 1 AS dummy\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                ''')\n",
    "\n",
    "def indexLabHpoProfile():\n",
    "    #_idx01 is not necessary if _idx3 exists\n",
    "    #cursor.execute('CREATE INDEX JAX_labHpoProfile_idx01 ON JAX_labHpoProfile (SUBJECT_ID, HADM_ID)')\n",
    "    cursor.execute('CREATE INDEX JAX_labHpoProfile_idx02 ON JAX_labHpoProfile (MAP_TO);')\n",
    "    cursor.execute('CREATE INDEX JAX_labHpoProfile_idx03 ON JAX_labHpoProfile (SUBJECT_ID, HADM_ID, MAP_TO)')\n",
    "    cursor.execute('CREATE INDEX JAX_labHpoProfile_idx04 ON JAX_labHpoProfile (OCCURRANCE)')\n",
    "    \n",
    "def rankICD():\n",
    "    \"\"\"\n",
    "    Rank frequently seen ICD-9 codes (first three or four digits) among encounters of interest.\n",
    "    \"\"\"\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_diagFrequencyRank')\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TEMPORARY TABLE IF NOT EXISTS JAX_diagFrequencyRank\n",
    "        WITH JAX_temp_diag AS (\n",
    "            SELECT DISTINCT SUBJECT_ID, HADM_ID, \n",
    "                CASE \n",
    "                    WHEN(ICD9_CODE LIKE 'V%') THEN SUBSTRING(ICD9_CODE, 1, 3) \n",
    "                    WHEN(ICD9_CODE LIKE 'E%') THEN SUBSTRING(ICD9_CODE, 1, 4) \n",
    "                ELSE \n",
    "                    SUBSTRING(ICD9_CODE, 1, 3) END AS ICD9_CODE \n",
    "            FROM JAX_diagnosisProfile)\n",
    "        SELECT \n",
    "            ICD9_CODE, COUNT(*) AS N\n",
    "        FROM\n",
    "            JAX_temp_diag\n",
    "        GROUP BY \n",
    "            ICD9_CODE\n",
    "        ORDER BY N\n",
    "        DESC\n",
    "        \"\"\")\n",
    "\n",
    "def rankHpoFromText(diagnosis, hpo_min_occurrence_per_encounter):\n",
    "    \"\"\"\n",
    "    Rank frequently seen phenotypes (HPO term) from text mining among encounters of interest. \n",
    "    An encounter may have multiple occurrances of a phenotype term. A phenotype is called if its occurrance\n",
    "    meets a minimum threshold. \n",
    "    @param hpo_min_occurrence_per_encounter: threshold for a phenotype abnormality to be called. Usually use 1. \n",
    "    \"\"\"\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_textHpoFrequencyRank')\n",
    "    cursor.execute('''\n",
    "            CREATE TEMPORARY TABLE JAX_textHpoFrequencyRank            \n",
    "            WITH pd AS(\n",
    "                SELECT \n",
    "                    JAX_textHpoProfile.*\n",
    "                FROM \n",
    "                    JAX_textHpoProfile \n",
    "                JOIN (\n",
    "                    SELECT \n",
    "                        DISTINCT SUBJECT_ID, HADM_ID\n",
    "                    FROM \n",
    "                        JAX_diagnosisProfile \n",
    "                    WHERE \n",
    "                        ICD9_CODE LIKE '{}%') AS d\n",
    "                ON \n",
    "                    JAX_textHpoProfile.SUBJECT_ID = d.SUBJECT_ID AND JAX_textHpoProfile.HADM_ID = d.HADM_ID\n",
    "                WHERE \n",
    "                    OCCURRANCE >= {})\n",
    "            SELECT \n",
    "                MAP_TO, COUNT(*) AS N, 1 AS PHENOTYPE\n",
    "            FROM pd\n",
    "            GROUP BY MAP_TO\n",
    "            ORDER BY N DESC'''.format(diagnosis, hpo_min_occurrence_per_encounter))\n",
    "    \n",
    "def rankHpoFromLab(diagnosis, hpo_min_occurrence_per_encounter):\n",
    "    \"\"\"\n",
    "    Rank frequently seen phenotypes (HPO term) from lab texts among encounters of interest. \n",
    "    An encounter may have multiple occurrances of a phenotype term, such as from lab tests that are frequently ordered.\n",
    "    A phenotype is called if its occurrance meets a minimum threshold.\n",
    "    @param hpo_min_occurrence_per_encounter: threshold for a phenotype abnormality to be called. \n",
    "    For example, if the parameter is set to 3, HP:0002153 Hyperkalemia is assigned iff three or more lab tests return higher than normal values for blood potassium concentrations\n",
    "    \"\"\"\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_labHpoFrequencyRank')\n",
    "    cursor.execute('''\n",
    "            CREATE TEMPORARY TABLE JAX_labHpoFrequencyRank            \n",
    "            WITH pd AS(\n",
    "                SELECT \n",
    "                    JAX_labHpoProfile.*\n",
    "                FROM \n",
    "                    JAX_labHpoProfile \n",
    "                JOIN (\n",
    "                    SELECT \n",
    "                        DISTINCT SUBJECT_ID, HADM_ID\n",
    "                    FROM \n",
    "                        JAX_diagnosisProfile \n",
    "                    WHERE \n",
    "                        ICD9_CODE LIKE '{}%') AS d\n",
    "                ON \n",
    "                    JAX_labHpoProfile.SUBJECT_ID = d.SUBJECT_ID AND JAX_labHpoProfile.HADM_ID = d.HADM_ID\n",
    "                WHERE\n",
    "                    OCCURRANCE >= {})\n",
    "            SELECT \n",
    "                MAP_TO, COUNT(*) AS N, 1 AS PHENOTYPE\n",
    "            FROM pd\n",
    "            GROUP BY MAP_TO\n",
    "            ORDER BY N DESC'''.format(diagnosis, hpo_min_occurrence_per_encounter))  \n",
    "    \n",
    "def createDiagnosisTable(diagnosis, primary_diagnosis_only):\n",
    "    \"\"\"\n",
    "    Create a temporary table JAX_mf_diag. For encounters of interest, assign 0 or 1 to each encouter whether a diagnosis is observed.\n",
    "    @param diagnosis: diagnosis code. An encounter is considered to be 1 if same or more detailed code is called. \n",
    "    @prarm primary_diagnosis_only: an encounter may be associated with one primary diagnosis and many secondary ones. \n",
    "    if value is set true, only primary diagnosis counts.  \n",
    "    \"\"\"\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag')\n",
    "    if primary_diagnosis_only:\n",
    "        limit = 'AND SEQ_NUM=1'\n",
    "    else:\n",
    "        limit = ''\n",
    "    cursor.execute('''\n",
    "                CREATE TEMPORARY TABLE IF NOT EXISTS JAX_mf_diag \n",
    "                WITH \n",
    "                    d AS (\n",
    "                        SELECT \n",
    "                            DISTINCT SUBJECT_ID, HADM_ID, '1' AS DIAGNOSIS\n",
    "                        FROM \n",
    "                            JAX_diagnosisProfile \n",
    "                        WHERE ICD9_CODE LIKE '{}%' {})\n",
    "                    -- This is encounters with positive diagnosis\n",
    "\n",
    "                SELECT \n",
    "                    DISTINCT a.SUBJECT_ID, a.HADM_ID, IF(d.DIAGNOSIS IS NULL, '0', '1') AS DIAGNOSIS\n",
    "                FROM \n",
    "                    JAX_encounterOfInterest AS a\n",
    "                LEFT JOIN\n",
    "                    d ON a.SUBJECT_ID = d.SUBJECT_ID AND a.HADM_ID = d.HADM_ID       \n",
    "                /* -- This is the first join for diagnosis (0, or 1) */    \n",
    "                '''.format(diagnosis, limit))\n",
    "    cursor.execute('CREATE INDEX JAX_mf_diag_idx01 ON JAX_mf_diag (SUBJECT_ID, HADM_ID)')\n",
    "\n",
    "\n",
    "def initTables(debug=False):\n",
    "    \"\"\"\n",
    "    This combines LabHpo and Inferred_LabHpo, and combines TextHpo and Inferred_TextHpo. \n",
    "    Only need to run once. For efficiency consideration, the tables can also be created as perminent. \n",
    "    It is time-consuming, so call it with caution. \n",
    "    \"\"\"\n",
    "    #init textHpoProfile and index it\n",
    "    #I created perminant tables to save time; other users should enable them\n",
    "    #textHpoProfile(include_inferred=True, threshold=1)\n",
    "    #indexTextHpoProfile()\n",
    "    #init labHpoProfile and index it\n",
    "    #labHpoProfile(threshold=1, include_inferred=True, force_update=True)\n",
    "    #indexLabHpoProfile()\n",
    "    \n",
    "    #define encounters to analyze\n",
    "    encounterOfInterest(debug)\n",
    "    indexEncounterOfInterest()\n",
    "    #init diagnosisProfile\n",
    "    diagnosisProfile()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexDiagnosisTable():\n",
    "    cursor.execute(\"ALTER TABLE JAX_mf_diag ADD COLUMN ROW_ID INT AUTO_INCREMENT PRIMARY KEY;\")\n",
    "    \n",
    "def batch_query(start_index, \n",
    "                end_index, \n",
    "                textHpo_occurrance_min, \n",
    "                labHpo_occurrance_min, \n",
    "                textHpo_threshold_min, \n",
    "                textHpo_threshold_max, \n",
    "                labHpo_threshold_min, \n",
    "                labHpo_threshold_max):\n",
    "    \"\"\"\n",
    "    Queries databases in small batches, return diagnosis values, phenotypes from text data and phenotypes from lab data.\n",
    "    @param start_index: minimum row_id\n",
    "    @param end_index: maximum row_id\n",
    "    @param textHpo_occurrance_min: minimum occurrances of a phenotype from text data for it to be called in one encounter\n",
    "    @param labHpo_occurrance_max: maximum occurrances of a phenotype from lab tests for it to be called in one encounter\n",
    "    @param textHpo_threshold_min: minimum number of encounters of a phenotypes from text data for it to be analyzed\n",
    "    @param textHpo_threshold_max: maximum number of encounters of a phenotypes from text data for it to be analyzed\n",
    "    @param labHpo_threshold_min: minimum number of encounters of a phenotype from lab tests for it to be analyzed\n",
    "    @param labHpo_threshold_max: maximum number of encounters of a phenotype from lab tests for it to be analyzed\n",
    "    \"\"\"\n",
    "    diagnosisVector = pd.read_sql_query('''\n",
    "        SELECT * FROM JAX_mf_diag WHERE ROW_ID BETWEEN {} AND {}\n",
    "    '''.format(start_index, end_index), mydb)\n",
    "    \n",
    "    textHpoFlat = pd.read_sql_query('''\n",
    "        WITH encounters AS (\n",
    "            SELECT SUBJECT_ID, HADM_ID\n",
    "            FROM JAX_mf_diag \n",
    "            WHERE ROW_ID BETWEEN {} AND {}\n",
    "        ), \n",
    "        textHpoOfInterest AS (\n",
    "            SELECT MAP_TO \n",
    "            FROM JAX_textHpoFrequencyRank \n",
    "            WHERE N BETWEEN {} AND {}\n",
    "        ), \n",
    "        joint as (\n",
    "            SELECT *\n",
    "            FROM encounters \n",
    "            JOIN textHpoOfInterest),\n",
    "        JAX_textHpoProfile_filtered AS (\n",
    "            SELECT * \n",
    "            FROM JAX_textHpoProfile \n",
    "            WHERE OCCURRANCE >= {}\n",
    "        )\n",
    "        \n",
    "        SELECT L.SUBJECT_ID, L.HADM_ID, L.MAP_TO, IF(R.dummy IS NULL, 0, 1) AS VALUE\n",
    "        FROM joint as L\n",
    "        LEFT JOIN \n",
    "        JAX_textHpoProfile_filtered AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.MAP_TO = R.MAP_TO  \n",
    "    '''.format(start_index, end_index, textHpo_threshold_min, textHpo_threshold_max, textHpo_occurrance_min), mydb)\n",
    "    \n",
    "    labHpoFlat = pd.read_sql_query('''\n",
    "        WITH encounters AS (\n",
    "            SELECT SUBJECT_ID, HADM_ID\n",
    "            FROM JAX_mf_diag \n",
    "            WHERE ROW_ID BETWEEN {} AND {}\n",
    "        ), \n",
    "        labHpoOfInterest AS (\n",
    "            SELECT MAP_TO \n",
    "            FROM JAX_labHpoFrequencyRank \n",
    "            WHERE N BETWEEN {} AND {}\n",
    "        ), \n",
    "        joint as (\n",
    "            SELECT *\n",
    "            FROM encounters \n",
    "            JOIN labHpoOfInterest),\n",
    "        JAX_labHpoProfile_filtered AS (\n",
    "            SELECT * \n",
    "            FROM JAX_labHpoProfile \n",
    "            WHERE OCCURRANCE >= {}\n",
    "        )\n",
    "        \n",
    "        SELECT L.SUBJECT_ID, L.HADM_ID, L.MAP_TO, IF(R.dummy IS NULL, 0, 1) AS VALUE\n",
    "        FROM joint as L\n",
    "        LEFT JOIN \n",
    "        JAX_labHpoProfile_filtered AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.MAP_TO = R.MAP_TO\n",
    "    '''.format(start_index, end_index, labHpo_threshold_min, labHpo_threshold_max, labHpo_occurrance_min), mydb)\n",
    "    \n",
    "    return diagnosisVector, textHpoFlat, labHpoFlat\n",
    "\n",
    "def summarize_diagnosis_textHpo_labHpo(primary_diagnosis_only, \n",
    "                                       textHpo_occurrance_min, \n",
    "                                       labHpo_occurrance_min, \n",
    "                                       diagnosis_threshold_min, \n",
    "                                       textHpo_threshold_min, \n",
    "                                       textHpo_threshold_max, \n",
    "                                       labHpo_threshold_min, \n",
    "                                       labHpo_threshold_max,\n",
    "                                       disease_of_interest,\n",
    "                                       logger):\n",
    "    \"\"\"\n",
    "    Iterate database to get summary statistics. For each disease of interest, automatically determine a list of phenotypes derived from labs (labHpo) and a list of phenotypes from text mining (textHpo). For each pair of phenotypes, count the number of encounters according to whether the phenotypes and diagnosis are observated.    \n",
    "    @param primary_diagnosis_only: only primary diagnosis is analyzed\n",
    "    @param textHpo_occurrance_min: minimum occurrances of a phenotype from text data for it to be called in one encounter\n",
    "    @param labHpo_occurrance_max: maximum occurrances of a phenotype from lab tests for it to be called in one encounter\n",
    "    @param textHpo_threshold_min: minimum number of encounters of a phenotypes from text data for it to be analyzed\n",
    "    @param textHpo_threshold_max: maximum number of encounters of a phenotypes from text data for it to be analyzed\n",
    "    @param labHpo_threshold_min: minimum number of encounters of a phenotype from lab tests for it to be analyzed\n",
    "    @param labHpo_threshold_max: maximum number of encounters of a phenotype from lab tests for it to be analyzed\n",
    "    @param disease_of_interest: either set to \"calculated\", or a list of ICD-9 codes (get all possible codes from temp table JAX_diagFrequencyRank)\n",
    "    @param logger: logger for logging\n",
    "    \n",
    "    :return: three dictionaries of summary statistics, of which the keys are diagnosis codes and the values are instances of the SummaryXYz class. \n",
    "    First dictionary, X (a list of phenotype variables) are from textHpo and Y are from labHpo; \n",
    "    Secondary dictionary, all terms in X, Y are from textHpo;\n",
    "    Third dictionary, all terms in X, Y are all from labHpo. Note that terms in X and Y are calculated separately for each diagnosis and may be different.\n",
    "    \"\"\"\n",
    "    logger.info('starting iterate_in_batch()')\n",
    "    batch_size = 100\n",
    "    \n",
    "    # define a set of diseases that we want to analyze\n",
    "    rankICD()\n",
    "    \n",
    "    if disease_of_interest == 'calculated': \n",
    "        diseaseOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_diagFrequencyRank WHERE N > {}\".format(diagnosis_threshold_min), mydb).ICD9_CODE.values\n",
    "    elif isinstance(disease_of_interest, list) and len(disease_of_interest) > 0:\n",
    "        #disable the following line to analyze all diseases of interest\n",
    "        #diseaseOfInterest = ['428', '584', '038', '493']\n",
    "        diseaseOfInterest = disease_of_interest\n",
    "    else:\n",
    "        raise RuntimeError\n",
    "    logger.info('diagnosis of interest: {}'.format(len(diseaseOfInterest)))\n",
    "    \n",
    "    summaries_diag_textHpo_labHpo = {}\n",
    "    summaries_diag_textHpo_textHpo = {}\n",
    "    summaries_diag_labHpo_labHpo = {}\n",
    "    \n",
    "    pbar = tqdm(total=len(diseaseOfInterest))\n",
    "    for diagnosis in diseaseOfInterest:\n",
    "        logger.info(\"start analyzing disease {}\".format(diagnosis))\n",
    "        \n",
    "        logger.info(\".......assigning values of diagnosis\")\n",
    "        # assign each encounter whether a diagnosis code is observed\n",
    "        # create a table j1 (joint 1)\n",
    "        createDiagnosisTable(diagnosis, primary_diagnosis_only)\n",
    "        indexDiagnosisTable()\n",
    "        # for every diagnosis, find phenotypes of interest to look at from radiology reports\n",
    "        # for every diagnosis, find phenotypes of interest to look at from laboratory tests\n",
    "        rankHpoFromText(diagnosis, textHpo_occurrance_min)\n",
    "        rankHpoFromLab(diagnosis, labHpo_occurrance_min)\n",
    "        logger.info(\"..............diagnosis values found\")\n",
    "        \n",
    "        textHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_textHpoFrequencyRank WHERE N BETWEEN {} AND {}\".format(textHpo_threshold_min, textHpo_threshold_max), mydb).MAP_TO.values\n",
    "        labHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_labHpoFrequencyRank WHERE N BETWEEN {} AND {}\".format(labHpo_threshold_min, labHpo_threshold_max), mydb).MAP_TO.values\n",
    "        logger.info(\"TextHpo of interest established, size: {}\".format(len(textHpoOfInterest)))\n",
    "        logger.info(\"LabHpo of interest established, size: {}\".format(len(labHpoOfInterest)))\n",
    "\n",
    "        ## find the start and end ROW_ID for patient*encounter\n",
    "        ADM_ID_START, ADM_ID_END = pd.read_sql_query('SELECT MIN(ROW_ID) AS min, MAX(ROW_ID) AS max FROM JAX_mf_diag', mydb).iloc[0]\n",
    "        batch_N = ADM_ID_END - ADM_ID_START + 1\n",
    "        TOTAL_BATCH = math.ceil(batch_N / batch_size) # total number of batches\n",
    "        \n",
    "        summaries_diag_textHpo_labHpo[diagnosis] = mf.SummaryXYz(textHpoOfInterest, labHpoOfInterest, diagnosis)\n",
    "        summaries_diag_textHpo_textHpo[diagnosis] = mf.SummaryXYz(textHpoOfInterest, textHpoOfInterest, diagnosis)\n",
    "        summaries_diag_labHpo_labHpo[diagnosis] = mf.SummaryXYz(labHpoOfInterest, labHpoOfInterest, diagnosis)\n",
    "        \n",
    "        logger.info('starting batch queries for {}'.format(diagnosis))\n",
    "        for i in np.arange(TOTAL_BATCH):\n",
    "            start_index = i * batch_size + ADM_ID_START\n",
    "            if i < TOTAL_BATCH - 1:\n",
    "                end_index = start_index + batch_size - 1\n",
    "            else:\n",
    "                end_index = batch_N\n",
    "\n",
    "            diagnosisFlat, textHpoFlat, labHpoFlat =  batch_query(start_index, end_index, textHpo_occurrance_min, labHpo_occurrance_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max)\n",
    "            \n",
    "            batch_size_actual = len(diagnosisFlat)\n",
    "            textHpoOfInterest_size = len(textHpoOfInterest)\n",
    "            labHpoOfInterest_size = len(labHpoOfInterest)\n",
    "            #print('len(textHpoFlat)= {}, batch_size_actual={}, textHpoOfInterest_size={}'.format(len(textHpoFlat), batch_size_actual, textHpoOfInterest_size))\n",
    "            assert(len(textHpoFlat) == batch_size_actual * textHpoOfInterest_size)\n",
    "            assert(len(labHpoFlat) == batch_size_actual * labHpoOfInterest_size)\n",
    "            \n",
    "            if batch_size_actual > 0:\n",
    "                diagnosisVector = diagnosisFlat.DIAGNOSIS.values.astype(int)\n",
    "                # reformat the flat vector into N x M matrix, N is batch size, i.e. number of encounters, M is the length of HPO terms  \n",
    "                textHpoMatrix = textHpoFlat.VALUE.values.astype(int).reshape([batch_size_actual, textHpoOfInterest_size], order='F')\n",
    "                labHpoMatrix = labHpoFlat.VALUE.values.astype(int).reshape([batch_size_actual, labHpoOfInterest_size], order='F')\n",
    "                # check the matrix formatting is correct\n",
    "                # disable the following 4 lines to speed things up\n",
    "                textHpoLabelsMatrix = textHpoFlat.MAP_TO.values.reshape([batch_size_actual, textHpoOfInterest_size], order='F')\n",
    "                labHpoLabelsMatrix = labHpoFlat.MAP_TO.values.reshape([batch_size_actual, labHpoOfInterest_size], order='F')\n",
    "                assert (textHpoLabelsMatrix[0, :] == textHpoOfInterest).all()\n",
    "                assert (labHpoLabelsMatrix[0, :] == labHpoOfInterest).all()\n",
    "                if i % 100 == 0:\n",
    "                    logger.info('new batch: start_index={}, end_index={}, batch_size= {}, textHpo_size = {}, labHpo_size = {}'.format(start_index, end_index, batch_size_actual, textHpoMatrix.shape[1], labHpoMatrix.shape[1]))\n",
    "                summaries_diag_textHpo_labHpo[diagnosis].add_batch(textHpoMatrix,labHpoMatrix, diagnosisVector)\n",
    "                summaries_diag_textHpo_textHpo[diagnosis].add_batch(textHpoMatrix,textHpoMatrix, diagnosisVector)\n",
    "                summaries_diag_labHpo_labHpo[diagnosis].add_batch(labHpoMatrix,labHpoMatrix, diagnosisVector)\n",
    "         \n",
    "        pbar.update(1)\n",
    "        \n",
    "    pbar.close()\n",
    "    \n",
    "    return summaries_diag_textHpo_labHpo, summaries_diag_textHpo_textHpo, summaries_diag_labHpo_labHpo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  --TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-20 15:09:58,034 - 11200 - root - INFO - starting iterate_in_batch()\n",
      "2019-12-20 15:09:58,038 - 11200 - root - INFO - diagnosis of interest: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-20 15:09:58,040 - 11200 - root - INFO - start analyzing disease 428\n",
      "2019-12-20 15:09:58,041 - 11200 - root - INFO - .......assigning values of diagnosis\n",
      "2019-12-20 15:09:58,056 - 11200 - root - INFO - ..............diagnosis values found\n",
      "2019-12-20 15:09:58,061 - 11200 - root - INFO - TextHpo of interest established, size: 28\n",
      "2019-12-20 15:09:58,062 - 11200 - root - INFO - LabHpo of interest established, size: 52\n",
      "2019-12-20 15:09:58,065 - 11200 - root - INFO - starting batch queries for 428\n",
      "2019-12-20 15:09:58,173 - 11200 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 28, labHpo_size = 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:00<00:00,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-20 15:09:58,187 - 11200 - root - INFO - start analyzing disease 584\n",
      "2019-12-20 15:09:58,188 - 11200 - root - INFO - .......assigning values of diagnosis\n",
      "2019-12-20 15:09:58,200 - 11200 - root - INFO - ..............diagnosis values found\n",
      "2019-12-20 15:09:58,204 - 11200 - root - INFO - TextHpo of interest established, size: 9\n",
      "2019-12-20 15:09:58,205 - 11200 - root - INFO - LabHpo of interest established, size: 29\n",
      "2019-12-20 15:09:58,208 - 11200 - root - INFO - starting batch queries for 584\n",
      "2019-12-20 15:09:58,269 - 11200 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 9, labHpo_size = 29\n",
      "2019-12-20 15:09:58,274 - 11200 - root - INFO - start analyzing disease 038\n",
      "2019-12-20 15:09:58,275 - 11200 - root - INFO - .......assigning values of diagnosis\n",
      "2019-12-20 15:09:58,287 - 11200 - root - INFO - ..............diagnosis values found\n",
      "2019-12-20 15:09:58,292 - 11200 - root - INFO - TextHpo of interest established, size: 14\n",
      "2019-12-20 15:09:58,293 - 11200 - root - INFO - LabHpo of interest established, size: 25\n",
      "2019-12-20 15:09:58,295 - 11200 - root - INFO - starting batch queries for 038\n",
      "2019-12-20 15:09:58,360 - 11200 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 14, labHpo_size = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:00<00:00,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-20 15:09:58,365 - 11200 - root - INFO - start analyzing disease 493\n",
      "2019-12-20 15:09:58,366 - 11200 - root - INFO - .......assigning values of diagnosis\n",
      "2019-12-20 15:09:58,373 - 11200 - root - INFO - ..............diagnosis values found\n",
      "2019-12-20 15:09:58,377 - 11200 - root - INFO - TextHpo of interest established, size: 0\n",
      "2019-12-20 15:09:58,378 - 11200 - root - INFO - LabHpo of interest established, size: 0\n",
      "2019-12-20 15:09:58,380 - 11200 - root - INFO - starting batch queries for 493\n",
      "2019-12-20 15:09:58,388 - 11200 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 0, labHpo_size = 0\n",
      "2019-12-20 15:09:58,390 - 11200 - root - INFO - start analyzing disease *\n",
      "2019-12-20 15:09:58,391 - 11200 - root - INFO - .......assigning values of diagnosis\n",
      "2019-12-20 15:09:58,397 - 11200 - root - INFO - ..............diagnosis values found\n",
      "2019-12-20 15:09:58,401 - 11200 - root - INFO - TextHpo of interest established, size: 0\n",
      "2019-12-20 15:09:58,401 - 11200 - root - INFO - LabHpo of interest established, size: 0\n",
      "2019-12-20 15:09:58,404 - 11200 - root - INFO - starting batch queries for *\n",
      "2019-12-20 15:09:58,412 - 11200 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 0, labHpo_size = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 13.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# how to run this\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# 1. build the temp tables for Lab converted HPO, Text convert HPO\n",
    "# Read the comments within the method!\n",
    "initTables(debug=True)\n",
    "\n",
    "# 2. iterate throw the dataset\n",
    "primary_diagnosis_only = True\n",
    "diagnosis_threshold_min = 5\n",
    "textHpo_occurrance_min, labHpo_occurrance_min = 1, 3\n",
    "textHpo_threshold_min, textHpo_threshold_max = 7, 100\n",
    "labHpo_threshold_min, labHpo_threshold_max = 7, 100\n",
    "disease_of_interest = ['428', '584', '038', '493', '*']\n",
    "\n",
    "summaries_diag_textHpo_labHpo, summaries_diag_textHpo_textHpo, summaries_diag_labHpo_labHpo = summarize_diagnosis_textHpo_labHpo(primary_diagnosis_only, textHpo_occurrance_min, labHpo_occurrance_min, diagnosis_threshold_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max, disease_of_interest, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 25, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_diag_textHpo_labHpo['038'].m2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --PRODUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 39.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# how to run this\n",
    "# Again, it take either too long or too much memory space to run\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.WARN)\n",
    "\n",
    "# 1. build the temp tables for Lab converted HPO, Text convert HPO\n",
    "# Read the comments within the method!\n",
    "initTables(debug=False)\n",
    "\n",
    "# 2. iterate throw the dataset\n",
    "primary_diagnosis_only = True\n",
    "diagnosis_threshold_min = 3000\n",
    "textHpo_threshold_min, textHpo_threshold_max = 500, 100000\n",
    "labHpo_threshold_min, labHpo_threshold_max = 1000, 100000\n",
    "textHpo_occurrance_min, labHpo_occurrance_min = 1, 3\n",
    "disease_of_interest = ['428', '584', '038', '493']\n",
    "\n",
    "summaries_diag_textHpo_labHpo, summaries_diag_textHpo_textHpo, summaries_diag_labHpo_labHpo = summarize_diagnosis_textHpo_labHpo(primary_diagnosis_only, textHpo_occurrance_min, labHpo_occurrance_min, diagnosis_threshold_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max, disease_of_interest, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if primary_diagnosis_only:\n",
    "    fName_diag_textHpo_labHpo = '../../../data/mf_regarding_diseases/primary_only/summaries_diagnosis_textHpo_labHpo.obj'\n",
    "    fName_diag_textHpo_textHpo = '../../../data/mf_regarding_diseases/primary_only/summaries_diagnosis_textHpo_textHpo.obj'\n",
    "    fName_diag_labHpo_labHpo = '../../../data/mf_regarding_diseases/primary_only/summaries_diagnosis_labHpo_labHpo.obj'\n",
    "else:\n",
    "    fName_diag_textHpo_labHpo = '../../../data/mf_regarding_diseases/primary_and_secondary/summaries_diagnosis_textHpo_labHpo.obj'\n",
    "    fName_diag_textHpo_textHpo = '../../../data/mf_regarding_diseases/primary_and_secondary/summaries_diagnosis_textHpo_textHpo.obj'\n",
    "    fName_diag_labHpo_labHpo = '../../../data/mf_regarding_diseases/primary_and_secondary/summaries_diagnosis_labHpo_labHpo.obj'\n",
    "\n",
    "with open(fName_diag_textHpo_labHpo, 'wb') as f:\n",
    "    pickle.dump(summaries_diag_textHpo_labHpo, f)\n",
    "with open(fName_diag_textHpo_textHpo, 'wb') as f:\n",
    "    pickle.dump(summaries_diag_textHpo_textHpo, f)\n",
    "with open(fName_diag_labHpo_labHpo, 'wb') as f:\n",
    "    pickle.dump(summaries_diag_labHpo_labHpo, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'428': <mf.SummaryXYz at 0xa17c01630>,\n",
       " '584': <mf.SummaryXYz at 0x1050d9cf8>,\n",
       " '038': <mf.SummaryXYz at 0xa1776c048>,\n",
       " '493': <mf.SummaryXYz at 0xa17b37b70>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_diag_textHpo_labHpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'428': <mf.SummaryXYz at 0xa17c01cc0>,\n",
       " '584': <mf.SummaryXYz at 0xa1776bf98>,\n",
       " '038': <mf.SummaryXYz at 0xa1776bef0>,\n",
       " '493': <mf.SummaryXYz at 0x81753fa90>}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_diag_textHpo_textHpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'428': <mf.SummaryXYz at 0xa17c01a90>,\n",
       " '584': <mf.SummaryXYz at 0xa1776bb38>,\n",
       " '038': <mf.SummaryXYz at 0xa17bba978>,\n",
       " '493': <mf.SummaryXYz at 0xa1776bdd8>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_diag_labHpo_labHpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo = Ontology('/Users/zhangx/git/human-phenotype-ontology/hp.obo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synergy network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_multi_variant_table(labHpos, radHpos, diag):\n",
    "    \"\"\"\n",
    "    Compute the mutual information between multiple phenotypes and the diagnosis.\n",
    "    Algorithm:\n",
    "    1. create a temp table Jax_multivariant_synergy_table (SUBJECT_ID, HADM_ID, diag_value)\n",
    "    2. for each phenotype, finding whether they are present, add a column \n",
    "    3. using the combined table, calculate the mutual information of \n",
    "    @param labHpos: a set of lab-derived HPO terms\n",
    "    @param radHpos: a set of text-derived HPO terms\n",
    "    @param diag: a diagnosis code\n",
    "    \"\"\"\n",
    "    # diagnosis column\n",
    "    # create diagnosis table\n",
    "    \n",
    "    # iterate labHpos\n",
    "    \n",
    "    # iterate textHpos\n",
    "    \n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "def add_diag_columns(diagnosis, primary_diagnosis_only):\n",
    "    createDiagnosisTable(diagnosis, primary_diagnosis_only)\n",
    "    # copy into a new table Jax_multivariant_synergy_table(SUBJECT_ID, HADM_ID, DIAGNOSIS)\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TEMPORARY TABLE IF NOT EXISTS Jax_multivariant_synergy_table AS (\n",
    "            SELECT * \n",
    "            FROM JAX_mf_diag\n",
    "        )\"\"\")\n",
    "    cursor.execute('CREATE INDEX Jax_multivariant_synergy_table_idx01 ON JAX_mf_diag (SUBJECT_ID, HADM_ID)')\n",
    " \n",
    "    \n",
    "def add_phenotype_columns(labHpos, textHpos, labHpo_threshold_min, textHpo_threshold_min):\n",
    "    # save the variable transformation for later use\n",
    "    var_dict = {}\n",
    "    i = 0\n",
    "    for labHpo in labHpos:\n",
    "        i = i + 1\n",
    "        colName = 'V' + str(i)\n",
    "        var_dict[colName] = ('LabHpo', labHpo)\n",
    "        cursor.execute(\"\"\"\n",
    "            ALTER TABLE Jax_multivariant_synergy_table ADD COLUMN {} INT DEFAULT 0\"\"\".format(colName))\n",
    "        cursor.execute(\"\"\"\n",
    "            UPDATE Jax_multivariant_synergy_table \n",
    "            LEFT JOIN JAX_labHpoProfile \n",
    "            ON Jax_multivariant_synergy_table.SUBJECT_ID = JAX_labHpoProfile.SUBJECT_ID AND \n",
    "            Jax_multivariant_synergy_table.HADM_ID = JAX_labHpoProfile.HADM_ID\n",
    "            SET {} = IF(JAX_labHpoProfile.OCCURRANCE > {}, 1, 0)\n",
    "            WHERE JAX_labHpoProfile.MAP_TO = '{}'\n",
    "        \"\"\".format(colName, labHpo_threshold_min, labHpo))\n",
    "        \n",
    "    for textHpo in textHpos:\n",
    "        i = i + 1\n",
    "        colName = 'V' + str(i)\n",
    "        var_dict[colName] = ('TextHpo', textHpo)\n",
    "        cursor.execute(\"\"\"\n",
    "            ALTER TABLE Jax_multivariant_synergy_table ADD COLUMN {} INT DEFAULT 0\"\"\".format(colName))\n",
    "        cursor.execute(\"\"\"\n",
    "            UPDATE Jax_multivariant_synergy_table \n",
    "            LEFT JOIN JAX_textHpoProfile \n",
    "            ON Jax_multivariant_synergy_table.SUBJECT_ID = JAX_textHpoProfile.SUBJECT_ID AND \n",
    "            Jax_multivariant_synergy_table.HADM_ID = JAX_textHpoProfile.HADM_ID\n",
    "            SET {} = IF(JAX_textHpoProfile.OCCURRANCE > {}, 1, 0)\n",
    "            WHERE JAX_textHpoProfile.MAP_TO = '{}'\n",
    "        \"\"\".format(colName, textHpo_threshold_min, textHpo))\n",
    "    return var_dict\n",
    "        \n",
    "\n",
    "def precompute_mf(variables):\n",
    "    \"\"\"\n",
    "    Compute the mutual information between the joint distribution of all the variables and the medical outcome\n",
    "    \"\"\" \n",
    "    summary_counts = pd.read_sql_query(\"\"\"\n",
    "        WITH summary AS (\n",
    "        SELECT {}, DIAGNOSIS, COUNT(*) AS N\n",
    "        FROM Jax_multivariant_synergy_table\n",
    "        GROUP BY {}, DIAGNOSIS)\n",
    "        SELECT *, SUM(N) OVER (PARTITION BY {}) AS V, SUM(N) OVER (PARTITION BY DIAGNOSIS) AS D\n",
    "        FROM summary\n",
    "    \"\"\".format(','.join(variables), ','.join(variables), ','.join(variables)), mydb)\n",
    "    total = np.sum(summary_counts.N)\n",
    "    p = summary_counts.N / total\n",
    "    p_V = summary_counts.V / total\n",
    "    p_D = summary_counts.D / total\n",
    "    mf = np.sum(p * np.log2(p / (p_V * p_D)))\n",
    "    return mf, summary_counts\n",
    "\n",
    "\n",
    "def precompute_mf_dict(var_ids):\n",
    "    var_subsets = synergy_tree.subsets(var_ids, include_self=True)\n",
    "    mf_dict = {}\n",
    "    summary_dict = {}\n",
    "    pbar = tqdm_notebook(total=len(var_subsets))\n",
    "    for var_subset in var_subsets: \n",
    "        mf, summary_count = precompute_mf(var_subset)\n",
    "        mf_dict[var_subset] = mf\n",
    "        summary_dict[var_subset] = summary_count\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    \n",
    "    return mf_dict, summary_dict       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis = '038'\n",
    "textHpo_occurrance_min=1\n",
    "labHpo_occurrance_min=3\n",
    "textHpo_threshold_min=7\n",
    "textHpo_threshold_max=7\n",
    "labHpo_threshold_min=8\n",
    "labHpo_threshold_max=8\n",
    "primary_diagnosis_only=True\n",
    "\n",
    "initTables(debug=True)\n",
    "\n",
    "rankHpoFromText(diagnosis, textHpo_occurrance_min)\n",
    "rankHpoFromLab(diagnosis, labHpo_occurrance_min)\n",
    "#logger.info(\"..............diagnosis values found\")\n",
    "\n",
    "textHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_textHpoFrequencyRank WHERE N BETWEEN {} AND {}\".format(textHpo_threshold_min, textHpo_threshold_max), mydb).MAP_TO.values\n",
    "labHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_labHpoFrequencyRank WHERE N BETWEEN {} AND {}\".format(labHpo_threshold_min, labHpo_threshold_max), mydb).MAP_TO.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HP:0001877' 'HP:0020058' 'HP:0010927' 'HP:0001871' 'HP:0010929'\n",
      " 'HP:0020061' 'HP:0003111' 'HP:0012337' 'HP:0032180' 'HP:0011015'\n",
      " 'HP:0001939' 'HP:0011014' 'HP:0000118' 'HP:0000001' 'HP:0031850']\n",
      "['HP:0002202' 'HP:0011032' 'HP:0100750' 'HP:0000969' 'HP:0002597'\n",
      " 'HP:0012337' 'HP:0030680']\n",
      "filtered phenotypes:\n",
      "['HP:0002202', 'HP:0011032', 'HP:0100750']\n",
      "['HP:0001877', 'HP:0020058', 'HP:0010927', 'HP:0001871', 'HP:0010929']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d64a2a753941509257a2e09cfc8199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=255), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-20 14:40:39,890 - 11200 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# manually trim phenotypes TODO: further filter them\n",
    "print(labHpoOfInterest)\n",
    "print(textHpoOfInterest)\n",
    "textHpoOfInterest = ['HP:0001877', 'HP:0020058', 'HP:0010927', 'HP:0001871', 'HP:0010929']\n",
    "labHpoOfInterest = ['HP:0002202', 'HP:0011032', 'HP:0100750']\n",
    "print(\"filtered phenotypes:\")\n",
    "print(labHpoOfInterest)\n",
    "print(textHpoOfInterest)\n",
    "\n",
    "\n",
    "cursor.execute(\"\"\"drop table if exists Jax_multivariant_synergy_table\"\"\", mydb)\n",
    "\n",
    "add_diag_columns(diagnosis, primary_diagnosis_only)\n",
    "var_dict = add_phenotype_columns(labHpos=labHpoOfInterest, \\\n",
    "                                 textHpos=textHpoOfInterest, \\\n",
    "                                 labHpo_threshold_min = labHpo_occurrance_min, \\\n",
    "                                 textHpo_threshold_min = textHpo_occurrance_min)\n",
    "mf_dict, summary_dict = precompute_mf_dict(var_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8')\n",
      "├── ('V1', 'V2', 'V4', 'V7')\n",
      "│   ├── ('V1',)\n",
      "│   ├── ('V2', 'V7')\n",
      "│   │   ├── ('V2',)\n",
      "│   │   └── ('V7',)\n",
      "│   └── ('V4',)\n",
      "├── ('V3', 'V5', 'V6')\n",
      "│   ├── ('V3', 'V6')\n",
      "│   │   ├── ('V3',)\n",
      "│   │   └── ('V6',)\n",
      "│   └── ('V5',)\n",
      "└── ('V8',)\n",
      "\n",
      "{'V1': ('LabHpo', 'HP:0002202'), 'V2': ('LabHpo', 'HP:0011032'), 'V3': ('LabHpo', 'HP:0100750'), 'V4': ('TextHpo', 'HP:0001877'), 'V5': ('TextHpo', 'HP:0020058'), 'V6': ('TextHpo', 'HP:0010927'), 'V7': ('TextHpo', 'HP:0001871'), 'V8': ('TextHpo', 'HP:0010929')}\n"
     ]
    }
   ],
   "source": [
    "syntree_038 = synergy_tree.SynergyTree(var_dict.keys(), var_dict, mf_dict)\n",
    "syntree_038.synergy_tree().show()\n",
    "print(var_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis = '038'\n",
    "textHpo_occurrance_min=1\n",
    "labHpo_occurrance_min=3\n",
    "textHpo_threshold_min=500\n",
    "textHpo_threshold_max=100000\n",
    "labHpo_threshold_min=1000\n",
    "labHpo_threshold_max=100000\n",
    "primary_diagnosis_only=True\n",
    "\n",
    "initTables(debug=False)\n",
    "\n",
    "rankHpoFromText(diagnosis, textHpo_occurrance_min)\n",
    "rankHpoFromLab(diagnosis, labHpo_occurrance_min)\n",
    "#logger.info(\"..............diagnosis values found\")\n",
    "\n",
    "textHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_textHpoFrequencyRank WHERE N BETWEEN {} AND {}\".format(textHpo_threshold_min, textHpo_threshold_max), mydb).MAP_TO.values\n",
    "labHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_labHpoFrequencyRank WHERE N BETWEEN {} AND {}\".format(labHpo_threshold_min, labHpo_threshold_max), mydb).MAP_TO.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered phenotypes:\n",
      "['HP:0020062', 'HP:0020063', 'HP:0012419', 'HP:0002151', 'HP:0012417', 'HP:0020060', 'HP:0020059', 'HP:0002148']\n",
      "['HP:0002107', 'HP:0000969', 'HP:0001945', 'HP:0001626']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f665c8580d704b608e411e9c2c45013c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4095), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# manually trim phenotypes TODO: further filter them\n",
    "textHpoOfInterest = ['HP:0002107', 'HP:0000969', 'HP:0001945', 'HP:0001626']\n",
    "labHpoOfInterest = ['HP:0020062', 'HP:0020063', 'HP:0012419', 'HP:0002151', 'HP:0012417', \n",
    "                    'HP:0020060', 'HP:0020059', 'HP:0002148']\n",
    "print(\"filtered phenotypes:\")\n",
    "print(labHpoOfInterest)\n",
    "print(textHpoOfInterest)\n",
    "\n",
    "\n",
    "cursor.execute(\"\"\"drop table if exists Jax_multivariant_synergy_table\"\"\", mydb)\n",
    "\n",
    "add_diag_columns(diagnosis, primary_diagnosis_only)\n",
    "var_dict = add_phenotype_columns(labHpos=labHpoOfInterest, \\\n",
    "                                 textHpos=textHpoOfInterest, \\\n",
    "                                 labHpo_threshold_min = labHpo_occurrance_min, \\\n",
    "                                 textHpo_threshold_min = textHpo_occurrance_min)\n",
    "mf_dict, summary_dict = precompute_mf_dict(var_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntree_038 = synergy_tree.SynergyTree(var_dict.keys(), var_dict, mf_dict)\n",
    "syntree_038.synergy_tree().show()\n",
    "term_map = hpo.term_id_2_label_map\n",
    "for k, v in var_dict.items():\n",
    "    print('{}: {} {}'.format(k, v[1], term_map[v[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual information between phenotypes of radiology and lab tests regardless of diseases\n",
    "Without considering diseases, we want to determine the mutual information between pairs of phenotypes from radiology reports and lab tests. The algorithm:\n",
    "\n",
    "    * find phenotypes of interest from radiology reports\n",
    "    * find phenotypes of interest from lab tests\n",
    "    * in batches, create a matrix of text phenotype profiles and a matrix of lab phenotype profiles, update summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_query_lab_text(start_index, end_index, textHpo_occurrance_min, labHpo_occurrance_min, textHpo_min, textHpo_max, labHpo_min, labHpo_max):\n",
    "    \n",
    "    textHpo_flat = pd.read_sql_query('''\n",
    "        WITH encounters AS (\n",
    "                SELECT *\n",
    "                FROM JAX_encounterOfInterest\n",
    "                WHERE ROW_ID BETWEEN {} AND {}),\n",
    "            phenotypes AS (\n",
    "                SELECT MAP_TO\n",
    "                FROM JAX_textHpoFrequencyRank\n",
    "                WHERE N BETWEEN {} AND {}\n",
    "            ), \n",
    "            temp AS (\n",
    "                SELECT * \n",
    "                FROM encounters \n",
    "                JOIN phenotypes)\n",
    "\n",
    "            SELECT L.SUBJECT_ID, L.HADM_ID, L.MAP_TO AS PHEN_TEXT, IF(R.dummy IS NULL, 0, 1) AS PHEN_TEXT_VALUE\n",
    "            FROM temp AS L\n",
    "            LEFT JOIN \n",
    "                (SELECT * FROM JAX_textHpoProfile WHERE OCCURRANCE >= {}) AS R\n",
    "            ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.MAP_TO = R.MAP_TO\n",
    "        '''.format(start_index, end_index, textHpo_min, textHpo_max, textHpo_occurrance_min), mydb)\n",
    "    \n",
    "    labHpo_flat = pd.read_sql_query('''\n",
    "        WITH encounters AS (\n",
    "                SELECT *\n",
    "                FROM JAX_encounterOfInterest\n",
    "                WHERE ROW_ID BETWEEN {} AND {}),\n",
    "            phenotypes AS (\n",
    "                SELECT MAP_TO\n",
    "                FROM JAX_labHpoFrequencyRank\n",
    "                WHERE N BETWEEN {} AND {}\n",
    "            ), \n",
    "            temp AS (\n",
    "                SELECT * \n",
    "                FROM encounters \n",
    "                JOIN phenotypes)\n",
    "\n",
    "            SELECT L.SUBJECT_ID, L.HADM_ID, L.MAP_TO AS PHEN_LAB, IF(R.dummy IS NULL, 0, 1) AS PHEN_LAB_VALUE\n",
    "            FROM temp AS L\n",
    "            LEFT JOIN \n",
    "                (SELECT * FROM JAX_labHpoProfile WHERE OCCURRANCE >= {}) AS R\n",
    "            ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.MAP_TO = R.MAP_TO\n",
    "        '''.format(start_index, end_index, labHpo_min, labHpo_max, labHpo_occurrance_min), mydb)\n",
    "    \n",
    "    return textHpo_flat, labHpo_flat \n",
    "    \n",
    "\n",
    "def summary_textHpo_labHpo(batch_size, textHpo_occurrance_min, labHpo_occurrance_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max):\n",
    "    \n",
    "    textHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_textHpoFrequencyRank WHERE N BETWEEN {} AND {}\".format(textHpo_threshold_min, textHpo_threshold_max), mydb).MAP_TO.values\n",
    "    labHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_labHpoFrequencyRank WHERE N BETWEEN {} AND {}\".format(labHpo_threshold_min, labHpo_threshold_max), mydb).MAP_TO.values\n",
    "    M1 = len(textHpoOfInterest)\n",
    "    M2 = len(labHpoOfInterest)\n",
    "    \n",
    "    summary_rad_lab = mf.SummaryXY(textHpoOfInterest, labHpoOfInterest)\n",
    "    summary_rad_rad = mf.SummaryXY(textHpoOfInterest, textHpoOfInterest)\n",
    "    summary_lab_lab = mf.SummaryXY(labHpoOfInterest, labHpoOfInterest)\n",
    "    \n",
    "    ## find the start and end ROW_ID for patient*encounter\n",
    "    \n",
    "    ADM_ID_START, ADM_ID_END = pd.read_sql_query('SELECT MIN(ROW_ID) AS min, MAX(ROW_ID) AS max FROM JAX_encounterOfInterest', mydb).iloc[0]\n",
    "    batch_N = ADM_ID_END - ADM_ID_START + 1\n",
    "    TOTAL_BATCH = math.ceil(batch_N / batch_size) # total number of batches\n",
    "\n",
    "    print('total batches: ' + str(batch_N))\n",
    "    pbar = tqdm(total=TOTAL_BATCH)\n",
    "    for i in np.arange(TOTAL_BATCH):\n",
    "        start_index = i * batch_size + ADM_ID_START\n",
    "        if i < TOTAL_BATCH - 1:\n",
    "            end_index = start_index + batch_size - 1\n",
    "        else:\n",
    "            end_index = batch_N\n",
    "        actual_batch_size = end_index - start_index + 1\n",
    "        textHpo, labHpo = batch_query_lab_text(start_index, end_index, textHpo_occurrance_min, labHpo_occurrance_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max)\n",
    "        textHpo_matrix = textHpo.PHEN_TEXT_VALUE.values.astype(int).reshape([actual_batch_size, M1], order='F')\n",
    "        labHpo_matrix = labHpo.PHEN_LAB_VALUE.values.astype(int).reshape([actual_batch_size, M2], order='F')\n",
    "        summary_rad_lab.add_batch(textHpo_matrix, labHpo_matrix)\n",
    "        summary_rad_rad.add_batch(textHpo_matrix, textHpo_matrix)\n",
    "        summary_lab_lab.add_batch(labHpo_matrix, labHpo_matrix)\n",
    "        pbar.update(1)\n",
    "        \n",
    "    pbar.close()\n",
    "    \n",
    "    return summary_rad_lab, summary_rad_rad, summary_lab_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_all_df.head()\n",
    "mf_all_df.sort_values(by='mf_P1_P2', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encounterOfInterest(debug=True)\n",
    "indexEncounterOfInterest()\n",
    "diagnosisProfile()\n",
    "rankHpoFromText('', hpo_min_occurrence_per_encounter=1)\n",
    "rankHpoFromLab('', hpo_min_occurrence_per_encounter=3)\n",
    "\n",
    "batch_size = 11\n",
    "textHpo_threshold_min = 45\n",
    "textHpo_threshold_max = 65\n",
    "labHpo_threshold_min = 75\n",
    "labHpo_threshold_max = 85\n",
    "textHpo_occurrance_min = 1\n",
    "labHpo_occurrance_min = 3\n",
    "\n",
    "summary_rad_lab, summary_rad_rad, summary_lab_lab = summary_textHpo_labHpo(batch_size, textHpo_occurrance_min, labHpo_occurrance_min, textHpo_threshold_min,textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max)\n",
    "\n",
    "print(summary_rad_lab.m.shape)\n",
    "print(summary_rad_rad.m.shape)\n",
    "print(summary_lab_lab.m.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/590 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total batches: 58976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 590/590 [32:42<00:00,  3.08s/it]\n"
     ]
    }
   ],
   "source": [
    "encounterOfInterest(debug=False)\n",
    "indexEncounterOfInterest()\n",
    "diagnosisProfile()\n",
    "rankHpoFromText('', hpo_min_occurrence_per_encounter=1)\n",
    "rankHpoFromLab('', hpo_min_occurrence_per_encounter=3)\n",
    "\n",
    "batch_size = 100\n",
    "textHpo_threshold_min = 500\n",
    "textHpo_threshold_max = 100000\n",
    "labHpo_threshold_min = 1000\n",
    "labHpo_threshold_max = 100000\n",
    "textHpo_occurrance_min = 1\n",
    "labHpo_occurrance_min = 3\n",
    "\n",
    "summary_rad_lab, summary_rad_rad, summary_lab_lab = summary_textHpo_labHpo(batch_size, textHpo_occurrance_min, labHpo_occurrance_min, textHpo_threshold_min,textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../data/mf_regardless_of_diseases/summary_textHpo_labHpo.obj', 'wb') as file:\n",
    "    pickle.dump(summary_rad_lab, file)\n",
    "    \n",
    "with open('../../../data/mf_regardless_of_diseases/summary_textHpo_textHpo.obj', 'wb') as file:\n",
    "    pickle.dump(summary_rad_rad, file)\n",
    "    \n",
    "with open('../../../data/mf_regardless_of_diseases/summary_labHpo_labHpo.obj', 'wb') as file:\n",
    "    pickle.dump(summary_lab_lab, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_all=mf.MutualInfoXY(summary_all)\n",
    "textHpo_labels = mf_all.X_names\n",
    "labHpo_labels = mf_all.Y_names\n",
    "M1 = len(mf_all.X_names)\n",
    "M2 = len(mf_all.Y_names)\n",
    "entropy_x, entropy_y = mf_all.entropies().values()\n",
    "mf_all_df = pd.DataFrame(data={'P1': np.repeat(textHpo_labels, M2), 'P2': np.tile(labHpo_labels, [M1]),'entropy_P1': np.repeat(entropy_x, M2), 'entropy_P2': np.tile(entropy_y, [M1]), 'mf_P1_P2': mf_all.mf().flat})\n",
    "mf_all_df.head()\n",
    "mf_all_df.to_csv('mutual_info_textHpo_labHpo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 178.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total batches: 100\n",
      "(8, 2, 4)\n",
      "(8, 8, 4)\n",
      "(2, 2, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: move the following section to the machine learning notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature generation for phenotype-based disease prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare phenotypes for machine learning tasks. For specified disease of interest, find the patient info (gender, DOB), find the diagnosis info (case or control, date), and phenotype terms.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encounterOfInterest(debug=False, N=100)\n",
    "indexEncounterOfInterest()\n",
    "diagnosisProfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = pd.read_sql_query('''\n",
    "        SELECT \n",
    "            PATIENTS.SUBJECT_ID, PATIENTS.GENDER, PATIENTS.DOB\n",
    "        FROM \n",
    "            PATIENTS\n",
    "        WHERE \n",
    "            SUBJECT_ID IN (SELECT SUBJECT_ID FROM JAX_encounterOfInterest) \n",
    "    ''', mydb)\n",
    "\n",
    "len(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createDiagnosisTable(diagnosis='038', primary_diagnosis_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_diag_time(diagnosis):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_first_diag_time')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_first_diag_time\n",
    "        WITH diag_time AS (\n",
    "            SELECT L.*, R.ADMITTIME \n",
    "            FROM JAX_mf_diag AS L\n",
    "            JOIN ADMISSIONS AS R\n",
    "            ON \n",
    "                L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID\n",
    "        ), \n",
    "        overallDiagnosis AS (\n",
    "            SELECT *, IF(SUM(DIAGNOSIS) OVER (PARTITION BY SUBJECT_ID) > 0, 1, 0) AS everDiagnosed\n",
    "            FROM diag_time\n",
    "        )\n",
    "        \n",
    "        SELECT \n",
    "            *, MIN(IF(everDiagnosed = 1, ADMITTIME, NULL) ) OVER (PARTITION BY SUBJECT_ID) AS first_diag, \n",
    "            MAX(IF(everDiagnosed = 0, ADMITTIME, NULL)) OVER (PARTITION BY SUBJECT_ID) AS last_visit_if_not_diagnosed\n",
    "        FROM \n",
    "            overallDiagnosis  \n",
    "    '''.format(diagnosis))\n",
    "\n",
    "first_diag_time('038')\n",
    "pd.read_sql_query('SELECT * FROM JAX_first_diag_time LIMIT 5', mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encountersAfterDiagnosis():\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_encounters_after_diagnosis')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_encounters_after_diagnosis\n",
    "            SELECT *, 1 AS toIgnore\n",
    "            FROM JAX_first_diag_time\n",
    "            WHERE DIAGNOSIS = 1 AND ADMITTIME > first_diag\n",
    "    ''')\n",
    "    cursor.execute('CREATE INDEX JAX_encounters_after_diagnosis_idx01 ON JAX_encounters_after_diagnosis (SUBJECT_ID, HADM_ID)')\n",
    "    \n",
    "encountersAfterDiagnosis() \n",
    "pd.read_sql_query(\"SELECT * FROM JAX_encounters_after_diagnosis LIMIT 5\", mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_vector = pd.read_sql_query('''\n",
    "        SELECT\n",
    "            SUBJECT_ID, IF(SUM(DIAGNOSIS)>0, 1, 0) AS DIAGNOSED, MAX(IF(everDiagnosed = 1, first_diag, last_visit_if_not_diagnosed)) AS LAST_VISIT\n",
    "        FROM\n",
    "            JAX_first_diag_time\n",
    "        GROUP BY SUBJECT_ID\n",
    "    ''', mydb)\n",
    "diagnosis_vector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab_phenotype_before_diagnosis():\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_phen_lab_before_diag')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_phen_lab_before_diag\n",
    "        WITH temp as (\n",
    "            SELECT L.*, W.toIgnore\n",
    "            FROM JAX_LABHPOPROFILE AS L\n",
    "            JOIN JAX_mf_diag AS R ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID\n",
    "            LEFT JOIN JAX_encounters_after_diagnosis W on  L.SUBJECT_ID = W.SUBJECT_ID AND L.HADM_ID = W.HADM_ID\n",
    "            WHERE L.OCCURRANCE >= 1\n",
    "        )\n",
    "        SELECT SUBJECT_ID, MAP_TO, COUNT(*) as N\n",
    "        FROM temp\n",
    "        WHERE toIgnore IS NULL\n",
    "        GROUP BY SUBJECT_ID, MAP_TO\n",
    "    ''')\n",
    "    cursor.execute('CREATE INDEX JAX_phen_lab_before_diag_idx01 ON JAX_phen_lab_before_diag (N)')\n",
    "    \n",
    "\n",
    "def text_phenotype_before_diagnosis():\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_phen_text_before_diag')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_phen_text_before_diag\n",
    "        WITH temp as (\n",
    "            SELECT L.*, W.toIgnore\n",
    "            FROM JAX_TEXTHPOPROFILE AS L\n",
    "            JOIN JAX_mf_diag AS R ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID\n",
    "            LEFT JOIN JAX_encounters_after_diagnosis W on  L.SUBJECT_ID = W.SUBJECT_ID AND L.HADM_ID = W.HADM_ID\n",
    "        )\n",
    "        SELECT SUBJECT_ID, MAP_TO, COUNT(*) as N\n",
    "        FROM temp\n",
    "        WHERE toIgnore IS NULL\n",
    "        GROUP BY SUBJECT_ID, MAP_TO\n",
    "    ''')\n",
    "    cursor.execute('CREATE INDEX JAX_phen_text_before_diag_idx01 ON JAX_phen_text_before_diag (N)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lab_phenotype_before_diagnosis()\n",
    "lab_phenotype_vector = pd.read_sql_query('''\n",
    "    SELECT * FROM JAX_phen_lab_before_diag\n",
    "'''.format(1), mydb)\n",
    "lab_phenotype_vector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_phenotype_before_diagnosis()\n",
    "text_phenotype_vector = pd.read_sql_query('''\n",
    "    SELECT * FROM JAX_phen_text_before_diag WHERE N >= {}\n",
    "'''.format(1), mydb)\n",
    "text_phenotype_vector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes = lab_phenotype_vector.merge(text_phenotype_vector, on = ['SUBJECT_ID', 'MAP_TO'], how = 'outer').fillna(value = 0)\n",
    "phenotypes['N'] = phenotypes['N_x'] + phenotypes['N_y']\n",
    "phenotypes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes_matrix = merged.loc[:, ['SUBJECT_ID', 'MAP_TO', 'N']].pivot_table(values='N', index='SUBJECT_ID', columns='MAP_TO', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = patients.merge(diagnosis_vector, on = 'SUBJECT_ID')\n",
    "df['AGE'] = (pd.to_datetime(df.LAST_VISIT, format='%Y-%m-%d %H:%M:%S').dt.year - pd.to_datetime(df.DOB, format='%Y-%m-%d %H:%M:%S').dt.year)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, ['SUBJECT_ID', 'GENDER', 'AGE', 'DIAGNOSED']].merge(phenotypes_matrix, on = 'SUBJECT_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ml_df_038_primary_only.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = patients.merge(m, on = 'SUBJECT_ID', how = 'left').sort_values(by = 'SUBJECT_ID').set_index('SUBJECT_ID')\n",
    "X = X.drop('DOB', axis=1).fillna(value=0)\n",
    "X.head(n = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diagnosis_vector.sort_values(by = 'SUBJECT_ID').set_index('SUBJECT_ID')\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = X.dtypes == object\n",
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = pd.get_dummies(X.GENDER)\n",
    "X = X.drop('GENDER', axis=1).merge(sex, left_index=True, right_index=True).drop('F', axis=1)\n",
    "X.M = X.M.astype(float)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_test.IsDiagnosed)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "mydb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
