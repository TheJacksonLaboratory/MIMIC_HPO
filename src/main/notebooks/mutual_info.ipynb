{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "mf_module_path = os.path.abspath(os.path.join('../python'))\n",
    "if mf_module_path not in sys.path:\n",
    "    sys.path.append(mf_module_path)\n",
    "import mf\n",
    "import mf_random\n",
    "import hpoutil\n",
    "import networkx\n",
    "import obonet\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connect to MySQL database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(host='localhost',\n",
    "                               user='mimicuser',\n",
    "                               passwd='mimic',\n",
    "                               database='mimiciiiv13',\n",
    "                              auth_plugin='mysql_native_password')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First approach to query mysql from python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that MySQL connection works properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ITEMID</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>VALUENUM</th>\n",
       "      <th>VALUEUOM</th>\n",
       "      <th>FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>51143</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>51144</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>51146</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>51200</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>51221</td>\n",
       "      <td>2138-07-17 20:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>%</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID  SUBJECT_ID  HADM_ID  ITEMID           CHARTTIME  VALUE  VALUENUM  \\\n",
       "0       1           2   163353   51143 2138-07-17 20:48:00      0       0.0   \n",
       "1       2           2   163353   51144 2138-07-17 20:48:00      0       0.0   \n",
       "2       3           2   163353   51146 2138-07-17 20:48:00      0       0.0   \n",
       "3       4           2   163353   51200 2138-07-17 20:48:00      0       0.0   \n",
       "4       5           2   163353   51221 2138-07-17 20:48:00      0       0.0   \n",
       "\n",
       "  VALUEUOM      FLAG  \n",
       "0        %      None  \n",
       "1        %      None  \n",
       "2        %      None  \n",
       "3        %      None  \n",
       "4        %  abnormal  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM LABEVENTS LIMIT 5;\", mydb)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a cursor so that it can be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = mydb.cursor(buffered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explored several method to compute the synergy score for different diseases. Method 1-3 all worked but the time and space requirements are too high. See the archived file. Here, we use method 4 to compute phenotype pairwise synergies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synergy between Lab-derived Abnormalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This method relies on the power of MySQL for doing queies and joins, return a batch of phenotype profiles a time, and then use the power of Numpy to do numeric computation.\n",
    "\n",
    "Specificially, the method runs the following algorithm:\n",
    "\n",
    "    1. For one diagnosis code, specify the phenotypes to analyze--a list of HPO terms.\n",
    "    2. For a batch of patient encounters, return a list of diagnosis codes (1 or 0)\n",
    "    3. For the same batch of patient*encounters, return a list of phenotypes.\n",
    "    4. Create a numpy array with dimension (N x P)\n",
    "    5. Perform numeric computation with Numpy:\n",
    "        outer product for ++ of PxP.T\n",
    "        outer product for +- of Px(1-P).T\n",
    "        outer product for -+ of (1-P)xP\n",
    "        outer product for -- of (1-P)x(1-P).T\n",
    "        combine the above with - and + of diagnosis value\n",
    "        stack them together as a (N x P x P x 8) matrix.\n",
    "        Step 1 - 5 are performed at each site. The resulting matrix is returned to JAX for final analyze.\n",
    "    6. Compute pairwise synergy:\n",
    "        use the multi-dimension array to calculate p(D = 1), p(D = 0), p(P1 * P2)\n",
    "        compute mutual information of each phenotype in regarding to one diagnosis I(P:D)\n",
    "        compute mutual information of two phenotypes in regarding to one diagnosis I(P:D)\n",
    "        compute pairwise synergy\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Synergy between lab-derived and radiology report-derived Abnormalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm is about the same. Briefly, \n",
    "\n",
    "    * Select encounterOfInterest, temp table: JAX_encounterOfInterest(SUBJECT_ID, HADM_ID)\n",
    "    * Init diagnosisProfile: temp table: JAX_diagnosisProfile(SUBJECT_ID, HADM_ID, ICD, N)\n",
    "    * Init textHpoProfile: temp table: JAX_textHpoProfile(SUBJECT_ID, HADM_ID, MAP_TO, N)\n",
    "    * Init labHpoProfile: temp table: JAX_labHpoProfile(SUBJECT_ID, HADM_ID, MAP_TO, N)\n",
    "    \n",
    "    * Rank ICD frequency, temp table: JAX_diagFrequencyRank(ICD, N)\n",
    "      select diagOfInterest\n",
    "    * Rank textHPO frequency, temp table: JAX_textHpoFrequencyRank(MAP_TO, N)\n",
    "      select textHpoOfInterest\n",
    "    * Rank labHPO frequency, temp table: JAX_labHpoFrequencyRank(MAP_TO, N)\n",
    "      select labHpoOfInterest\n",
    "    \n",
    "    * Iteratation\n",
    "      for diagnosis in diagOfInterest\n",
    "          for textHpo in textHpoOfInterest\n",
    "              for labHpo in labHpoOfInterest\n",
    "                 Assign diagnosis value: assignDiagnosis(), table: (SUBJECT_ID, HADM_ID, DIAGNOSIS)\n",
    "                 Assign text2hpo phenotype value: table: SUBJECT_ID, HADM_ID, PHEN_TEXT\n",
    "                 Assign lab2hpo phenotype value: table: SUBJECT_ID, HADM_ID, PHEN_LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm implemention\n",
    "The mutual information theory and algorithm is described in the following paper:\n",
    "\n",
    "\n",
    "    Anastassiou D, Computational analysis of the synergy among multiple\n",
    "    interacting genes. Molecular System Biology 3:83\n",
    "\n",
    "The algorithm is implemented in Python [link](https://github.com/TheJacksonLaboratory/MIMIC_HPO/blob/export_intermediate_data/src/main/python/mf.py). Python is chosen over Java because the numeric computation library (Numpy) in python is better (?) and easier to use (sure) than Java counterparts.\n",
    "\n",
    "Methods defined below are to prepare MySql database, query data, format them and call the mutual information algorithm implementation. \n",
    "\n",
    "The results are summary statistics that do not contain any PHI. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encounterOfInterest(debug=False, N=100):\n",
    "    \"\"\"\n",
    "    Define encounters of interest. The method is not finalized yet. Currently, it will use all encounters in our database. \n",
    "    @param debug: set to True to select a small subset for testing\n",
    "    @param N: limit the number of encounters when debug is set to True. If debug is set to False, N is ignored.  \n",
    "    \"\"\"\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_encounterOfInterest')\n",
    "    if debug:\n",
    "        limit = 'LIMIT {}'.format(N)\n",
    "    else:\n",
    "        limit = ''\n",
    "    # This is admissions that we want to analyze, 'LIMIT 100' in debug mode\n",
    "    cursor.execute('''\n",
    "                CREATE TEMPORARY TABLE IF NOT EXISTS JAX_encounterOfInterest(\n",
    "                    ROW_ID MEDIUMINT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY)\n",
    "                \n",
    "                SELECT \n",
    "                    DISTINCT SUBJECT_ID, HADM_ID \n",
    "                FROM admissions\n",
    "                {}\n",
    "                '''.format(limit))\n",
    "    \n",
    "def indexEncounterOfInterest():\n",
    "    \"\"\"\n",
    "    Create index on encounters table.\n",
    "    \"\"\"\n",
    "    cursor.execute('CREATE INDEX JAX_encounterOfInterest_idx01 ON JAX_encounterOfInterest (SUBJECT_ID, HADM_ID)')\n",
    "    \n",
    "def diagnosisProfile():\n",
    "    \"\"\"\n",
    "    For encounters of interest, find all of their diagnosis codes\n",
    "    \"\"\"\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_diagnosisProfile')\n",
    "    cursor.execute('''\n",
    "                CREATE TEMPORARY TABLE IF NOT EXISTS JAX_diagnosisProfile\n",
    "                SELECT \n",
    "                    DIAGNOSES_ICD.SUBJECT_ID, DIAGNOSES_ICD.HADM_ID, DIAGNOSES_ICD.ICD9_CODE, DIAGNOSES_ICD.SEQ_NUM\n",
    "                FROM\n",
    "                    DIAGNOSES_ICD\n",
    "                RIGHT JOIN\n",
    "                    JAX_encounterOfInterest\n",
    "                ON \n",
    "                    DIAGNOSES_ICD.SUBJECT_ID = JAX_encounterOfInterest.SUBJECT_ID \n",
    "                    AND \n",
    "                    DIAGNOSES_ICD.HADM_ID = JAX_encounterOfInterest.HADM_ID\n",
    "                ''')\n",
    "    \n",
    "def textHpoProfile(include_inferred=True):\n",
    "    \"\"\"\n",
    "    Set up a table for patient phenotypes from text mining. By default, merge directly mapped HPO terms and inferred terms.\n",
    "    It is currently defined as a temporary table. But in reality, it is created as a perminent table as it takes a long time to init, and it is going to be used multiple times. \n",
    "    \"\"\"\n",
    "    if include_inferred:\n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS JAX_textHpoProfile\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            NOTEEVENTS.SUBJECT_ID, NOTEEVENTS.HADM_ID, NoteHpoClinPhen.MAP_TO\n",
    "                        FROM \n",
    "                            NOTEEVENTS \n",
    "                        JOIN NoteHpoClinPhen on NOTEEVENTS.ROW_ID = NoteHpoClinPhen.NOTES_ROW_ID\n",
    "                        \n",
    "                        UNION ALL\n",
    "                        \n",
    "                        SELECT\n",
    "                            NOTEEVENTS.SUBJECT_ID, NOTEEVENTS.HADM_ID, Inferred_NoteHpo.INFERRED_TO AS MAP_TO\n",
    "                        FROM \n",
    "                            NOTEEVENTS \n",
    "                        JOIN Inferred_NoteHpo on NOTEEVENTS.ROW_ID = Inferred_NoteHpo.NOTEEVENT_ROW_ID\n",
    "                        )\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO, COUNT(*) AS OCCURRANCE, 1 AS dummy\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                ''')\n",
    "        \n",
    "    else:\n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS JAX_p_text\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            NOTEEVENTS.SUBJECT_ID, NOTEEVENTS.HADM_ID, NoteHpoClinPhen.MAP_TO\n",
    "                        FROM \n",
    "                            NOTEEVENTS \n",
    "                        JOIN NoteHpoClinPhen on NOTEEVENTS.ROW_ID = NoteHpoClinPhen.NOTES_ROW_ID)\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO, COUNT(*) AS OCCURRANCE, 1 AS dummy\n",
    "                ''')\n",
    "        \n",
    "def indexTextHpoProfile():\n",
    "    \"\"\"\n",
    "    Create indeces to speed up query\n",
    "    \"\"\"\n",
    "    #_idx01 is unnecessary if _idx3 exists\n",
    "    #cursor.execute('CREATE INDEX JAX_textHpoProfile_idx01 ON JAX_textHpoProfile (SUBJECT_ID, HADM_ID)')\n",
    "    cursor.execute('CREATE INDEX JAX_textHpoProfile_idx02 ON JAX_textHpoProfile (MAP_TO);')\n",
    "    cursor.execute('CREATE INDEX JAX_textHpoProfile_idx03 ON JAX_textHpoProfile (SUBJECT_ID, HADM_ID, MAP_TO)')\n",
    "    cursor.execute('CREATE INDEX JAX_textHpoProfile_idx04 ON JAX_textHpoProfile (OCCURRANCE)')\n",
    "    \n",
    "def labHpoProfile(include_inferred=True):\n",
    "    \"\"\"\n",
    "    Set up a table for lab tests-derived phenotypes. By default, also include phenotypes that are inferred from direct mapping.\n",
    "    Similar to textHpoProfile, this could be created as a perminent table. \n",
    "    \"\"\"\n",
    "    cursor.execute('''DROP TEMPORARY TABLE IF EXISTS JAX_labHpoProfile''')\n",
    "    if include_inferred:\n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS JAX_labHpoProfile\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, LabHpo.MAP_TO\n",
    "                        FROM \n",
    "                            LABEVENTS \n",
    "                        JOIN LabHpo on LABEVENTS.ROW_ID = LabHpo.ROW_ID\n",
    "                        WHERE LabHpo.NEGATED = 'F'\n",
    "                        \n",
    "                        UNION ALL\n",
    "                        \n",
    "                        SELECT \n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, INFERRED_LABHPO.INFERRED_TO AS MAP_TO \n",
    "                        FROM \n",
    "                            INFERRED_LABHPO \n",
    "                        JOIN \n",
    "                            LABEVENTS ON INFERRED_LABHPO.LABEVENT_ROW_ID = LABEVENTS.ROW_ID\n",
    "                        )\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO, COUNT(*) AS OCCURRANCE, 1 AS dummy\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                ''')\n",
    "    else:       \n",
    "        cursor.execute('''\n",
    "                    CREATE TEMPORARY TABLE IF NOT EXISTS JAX_labHpoProfile\n",
    "                    WITH abnorm AS (\n",
    "                        SELECT\n",
    "                            LABEVENTS.SUBJECT_ID, LABEVENTS.HADM_ID, LabHpo.MAP_TO\n",
    "                        FROM \n",
    "                            LABEVENTS \n",
    "                        JOIN LabHpo on LABEVENTS.ROW_ID = LabHpo.ROW_ID\n",
    "                        WHERE LabHpo.NEGATED = 'F')\n",
    "                    SELECT SUBJECT_ID, HADM_ID, MAP_TO, COUNT(*) AS OCCURRANCE, 1 AS dummy\n",
    "                    FROM abnorm \n",
    "                    GROUP BY SUBJECT_ID, HADM_ID, MAP_TO\n",
    "                ''')\n",
    "\n",
    "def indexLabHpoProfile():\n",
    "    #_idx01 is not necessary if _idx3 exists\n",
    "    #cursor.execute('CREATE INDEX JAX_labHpoProfile_idx01 ON JAX_labHpoProfile (SUBJECT_ID, HADM_ID)')\n",
    "    cursor.execute('CREATE INDEX JAX_labHpoProfile_idx02 ON JAX_labHpoProfile (MAP_TO);')\n",
    "    cursor.execute('CREATE INDEX JAX_labHpoProfile_idx03 ON JAX_labHpoProfile (SUBJECT_ID, HADM_ID, MAP_TO)')\n",
    "    cursor.execute('CREATE INDEX JAX_labHpoProfile_idx04 ON JAX_labHpoProfile (OCCURRANCE)')\n",
    "    \n",
    "def rankICD():\n",
    "    \"\"\"\n",
    "    Rank frequently seen ICD-9 codes (first three or four digits) among encounters of interest.\n",
    "    \"\"\"\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_diagFrequencyRank')\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TEMPORARY TABLE IF NOT EXISTS JAX_diagFrequencyRank\n",
    "        WITH JAX_temp_diag AS (\n",
    "            SELECT DISTINCT SUBJECT_ID, HADM_ID, \n",
    "                CASE \n",
    "                    WHEN(ICD9_CODE LIKE 'V%') THEN SUBSTRING(ICD9_CODE, 1, 3) \n",
    "                    WHEN(ICD9_CODE LIKE 'E%') THEN SUBSTRING(ICD9_CODE, 1, 4) \n",
    "                ELSE \n",
    "                    SUBSTRING(ICD9_CODE, 1, 3) END AS ICD9_CODE \n",
    "            FROM JAX_diagnosisProfile)\n",
    "        SELECT \n",
    "            ICD9_CODE, COUNT(*) AS N\n",
    "        FROM\n",
    "            JAX_temp_diag\n",
    "        GROUP BY \n",
    "            ICD9_CODE\n",
    "        ORDER BY N\n",
    "        DESC\n",
    "        \"\"\")\n",
    "\n",
    "def rankHpoFromText(diagnosis, hpo_min_occurrence_per_encounter):\n",
    "    \"\"\"\n",
    "    Rank frequently seen phenotypes (HPO term) from text mining among encounters of interest. \n",
    "    An encounter may have multiple occurrances of a phenotype term. A phenotype is called if its occurrance\n",
    "    meets a minimum threshold. \n",
    "    @param hpo_min_occurrence_per_encounter: threshold for a phenotype abnormality to be called. Usually use 1. \n",
    "    \"\"\"\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_textHpoFrequencyRank')\n",
    "    cursor.execute('''\n",
    "            CREATE TEMPORARY TABLE JAX_textHpoFrequencyRank            \n",
    "            WITH pd AS(\n",
    "                SELECT \n",
    "                    JAX_textHpoProfile.*\n",
    "                FROM \n",
    "                    JAX_textHpoProfile \n",
    "                JOIN (\n",
    "                    SELECT \n",
    "                        DISTINCT SUBJECT_ID, HADM_ID\n",
    "                    FROM \n",
    "                        JAX_diagnosisProfile \n",
    "                    WHERE \n",
    "                        ICD9_CODE LIKE '{}%') AS d\n",
    "                ON \n",
    "                    JAX_textHpoProfile.SUBJECT_ID = d.SUBJECT_ID AND JAX_textHpoProfile.HADM_ID = d.HADM_ID\n",
    "                WHERE \n",
    "                    OCCURRANCE >= {})\n",
    "            SELECT \n",
    "                MAP_TO, COUNT(*) AS N, 1 AS PHENOTYPE\n",
    "            FROM pd\n",
    "            GROUP BY MAP_TO\n",
    "            ORDER BY N DESC'''.format(diagnosis, hpo_min_occurrence_per_encounter))\n",
    "    \n",
    "def rankHpoFromLab(diagnosis, hpo_min_occurrence_per_encounter):\n",
    "    \"\"\"\n",
    "    Rank frequently seen phenotypes (HPO term) from lab texts among encounters of interest. \n",
    "    An encounter may have multiple occurrances of a phenotype term, such as from lab tests that are frequently ordered.\n",
    "    A phenotype is called if its occurrance meets a minimum threshold.\n",
    "    @param hpo_min_occurrence_per_encounter: threshold for a phenotype abnormality to be called. \n",
    "    For example, if the parameter is set to 3, HP:0002153 Hyperkalemia is assigned iff three or more lab tests return higher than normal values for blood potassium concentrations\n",
    "    \"\"\"\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_labHpoFrequencyRank')\n",
    "    cursor.execute('''\n",
    "            CREATE TEMPORARY TABLE JAX_labHpoFrequencyRank            \n",
    "            WITH pd AS(\n",
    "                SELECT \n",
    "                    JAX_labHpoProfile.*\n",
    "                FROM \n",
    "                    JAX_labHpoProfile \n",
    "                JOIN (\n",
    "                    SELECT \n",
    "                        DISTINCT SUBJECT_ID, HADM_ID\n",
    "                    FROM \n",
    "                        JAX_diagnosisProfile \n",
    "                    WHERE \n",
    "                        ICD9_CODE LIKE '{}%') AS d\n",
    "                ON \n",
    "                    JAX_labHpoProfile.SUBJECT_ID = d.SUBJECT_ID AND JAX_labHpoProfile.HADM_ID = d.HADM_ID\n",
    "                WHERE\n",
    "                    OCCURRANCE >= {})\n",
    "            SELECT \n",
    "                MAP_TO, COUNT(*) AS N, 1 AS PHENOTYPE\n",
    "            FROM pd\n",
    "            GROUP BY MAP_TO\n",
    "            ORDER BY N DESC'''.format(diagnosis, hpo_min_occurrence_per_encounter))           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mutual information between radiology and lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDiagnosisTable(diagnosis, primary_diagnosis_only):\n",
    "    \"\"\"\n",
    "    Create a temporary table JAX_mf_diag. For encounters of interest, assign 0 or 1 to each encouter whether a diagnosis is observed.\n",
    "    @param diagnosis: diagnosis code. An encounter is considered to be 1 if same or more detailed code is called. \n",
    "    @prarm primary_diagnosis_only: an encounter may be associated with one primary diagnosis and many secondary ones. \n",
    "    if value is set true, only primary diagnosis counts.  \n",
    "    \"\"\"\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag')\n",
    "    if primary_diagnosis_only:\n",
    "        limit = 'AND SEQ_NUM=1'\n",
    "    else:\n",
    "        limit = ''\n",
    "    cursor.execute('''\n",
    "                CREATE TEMPORARY TABLE IF NOT EXISTS JAX_mf_diag \n",
    "                WITH \n",
    "                    d AS (\n",
    "                        SELECT \n",
    "                            DISTINCT SUBJECT_ID, HADM_ID, '1' AS DIAGNOSIS\n",
    "                        FROM \n",
    "                            JAX_diagnosisProfile \n",
    "                        WHERE ICD9_CODE LIKE '{}%' {})\n",
    "                    -- This is encounters with positive diagnosis\n",
    "\n",
    "                SELECT \n",
    "                    DISTINCT a.SUBJECT_ID, a.HADM_ID, IF(d.DIAGNOSIS IS NULL, '0', '1') AS DIAGNOSIS\n",
    "                FROM \n",
    "                    JAX_encounterOfInterest AS a\n",
    "                LEFT JOIN\n",
    "                    d ON a.SUBJECT_ID = d.SUBJECT_ID AND a.HADM_ID = d.HADM_ID       \n",
    "                /* -- This is the first join for diagnosis (0, or 1) */    \n",
    "                '''.format(diagnosis, limit))\n",
    "    cursor.execute('CREATE INDEX JAX_mf_diag_idx01 ON JAX_mf_diag (SUBJECT_ID, HADM_ID)')\n",
    "\n",
    "\n",
    "def diagnosisTextHpo(phenotype):\n",
    "    \"\"\"\n",
    "    Assign 0 or 1 to each encounter whether a phenotype is observed from radiology reports\n",
    "    @phenotype: an HPO term id\n",
    "    \"\"\"\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_textHpo')\n",
    "    \"\"\"\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_textHpo\n",
    "        SELECT \n",
    "            L.*, IF(R.MAP_TO IS NULL, '0', '1') AS PHEN_TXT\n",
    "        FROM JAX_mf_diag AS L \n",
    "        LEFT JOIN \n",
    "            (SELECT * \n",
    "            FROM JAX_textHpoProfile \n",
    "            WHERE JAX_textHpoProfile.MAP_TO = '{}') AS R \n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID \n",
    "    '''.format(phenotype))\n",
    "    \"\"\"\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_textHpo\n",
    "        WITH L AS (SELECT JAX_mf_diag.*, '{}' AS PHEN_TXT FROM JAX_mf_diag)\n",
    "        SELECT \n",
    "            L.*, IF(R.dummy IS NULL, '0', '1') AS PHEN_TXT_VALUE\n",
    "        FROM L \n",
    "        LEFT JOIN \n",
    "            JAX_textHpoProfile AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.PHEN_TXT = R.MAP_TO\n",
    "    '''.format(phenotype))\n",
    "    cursor.execute('CREATE INDEX JAX_mf_diag_textHpo_idx01 ON JAX_mf_diag_textHpo (SUBJECT_ID, HADM_ID)')\n",
    "\n",
    "def diagnosisAllTextHpo(threshold_min, threshold_max):\n",
    "    \"\"\"\n",
    "    For phenotypes of interest, defined with two parameters, assign 0 or 1 to each encounter whether a phenotype is observated from text data\n",
    "    @param threshold_min: minimum threshold of encounter count for a phenotype to be interesting. \n",
    "    @param threshold_max: maximum threshold of encounter count for a phenotype to be interesting. \n",
    "    \"\"\"\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_allTextHpo')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_allTextHpo\n",
    "        WITH \n",
    "            P AS (SELECT MAP_TO AS PHEN_TXT FROM JAX_textHpoFrequencyRank WHERE N BETWEEN {} AND {}),\n",
    "            L AS (SELECT * FROM JAX_mf_diag JOIN P)\n",
    "        SELECT \n",
    "            L.*, IF(R.dummy IS NULL, '0', '1') AS PHEN_TXT_VALUE\n",
    "        FROM L \n",
    "        LEFT JOIN \n",
    "            JAX_textHpoProfile AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.PHEN_TXT = R.MAP_TO\n",
    "    '''.format(threshold_min, threshold_max))\n",
    "    cursor.execute('CREATE INDEX JAX_mf_diag_allTextHpo_idx01 ON JAX_mf_diag_allTextHpo (SUBJECT_ID, HADM_ID, PHEN_TXT)')\n",
    "    \n",
    "def diagnosisLabHpo(phenotype):\n",
    "    \"\"\"\n",
    "    Assign 0 or 1 to each encounter whether a phenotype is observed from lab tests\n",
    "    @phenotype: an HPO term id\n",
    "    \"\"\"\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_labHpo')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_labHpo\n",
    "        WITH L AS (SELECT JAX_mf_diag.*, '{}' AS PHEN_LAB FROM JAX_mf_diag)\n",
    "        SELECT \n",
    "            L.*, IF(R.dummy IS NULL, '0', '1') AS PHEN_LAB_VALUE\n",
    "        FROM L \n",
    "        LEFT JOIN \n",
    "             JAX_labHpoProfile AS R \n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.PHEN_LAB = R.MAP_TO\n",
    "    '''.format(phenotype))\n",
    "    cursor.execute('CREATE INDEX JAX_mf_diag_labHpo_idx01 ON JAX_mf_diag_labHpo (SUBJECT_ID, HADM_ID)')\n",
    "    \n",
    "def diagnosisAllLabHpo(threshold_min, threshold_max):\n",
    "    \"\"\"\n",
    "    For phenotypes of interest, defined with two parameters, assign 0 or 1 to each encounter whether a phenotype is observated from lab tests\n",
    "    @param threshold_min: minimum threshold of encounter count for a phenotype to be interesting. \n",
    "    @param threshold_max: maximum threshold of encounter count for a phenotype to be interesting. \n",
    "    \"\"\"\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_allLabHpo')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_allLabHpo\n",
    "        WITH \n",
    "            P AS (SELECT MAP_TO AS PHEN_LAB FROM JAX_labHpoFrequencyRank WHERE N BETWEEN {} AND {}),\n",
    "            L AS (SELECT * FROM JAX_mf_diag JOIN P)\n",
    "        SELECT \n",
    "            L.*, IF(R.dummy IS NULL, '0', '1') AS PHEN_LAB_VALUE\n",
    "        FROM L \n",
    "        LEFT JOIN \n",
    "             JAX_labHpoProfile AS R \n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.PHEN_LAB = R.MAP_TO\n",
    "    '''.format(threshold_min, threshold_max))\n",
    "    cursor.execute('CREATE INDEX JAX_mf_diag_allLabHpo_idx01 ON JAX_mf_diag_allLabHpo (SUBJECT_ID, HADM_ID)')\n",
    "\n",
    "def diagnosisTextLab(phenotype):\n",
    "    \"\"\"\n",
    "    Merge temporary tables to create one in which each encounter is assigned with 0 or 1 for diagnosis code, phenotype from text data and phenotype from lab tests. \n",
    "    \"\"\"\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_txtHpo_labHpo')\n",
    "    result = cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_txtHpo_labHpo \n",
    "        WITH L AS (SELECT JAX_mf_diag_textHpo.*, '{}' AS PHEN_LAB FROM JAX_mf_diag_textHpo)\n",
    "        SELECT L.*, IF(R.dummy IS NULL, '0', '1') AS PHEN_LAB_VALUE\n",
    "        FROM L \n",
    "        LEFT JOIN \n",
    "            JAX_labHpoProfile AS R \n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.PHEN_LAB = R.MAP_TO\n",
    "    '''.format(phenotype))\n",
    "    \n",
    "    \n",
    "def diagnosisAllTextAllLab():\n",
    "    \"\"\"\n",
    "    Merge temporary tables to create one in which each encounter is assigned with 0 or 1 for diagnosis code, all phenotypes of interest from text data, and all phenotypes from lab tests\n",
    "    \"\"\"\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_mf_diag_allTxtHpo_allLabHpo')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_mf_diag_allTxtHpo_allLabHpo \n",
    "        SELECT L.SUBJECT_ID, L.HADM_ID, L.DIAGNOSIS, L.PHEN_TXT, L.PHEN_TXT_VALUE, R.PHEN_LAB, R.PHEN_LAB_VALUE \n",
    "        FROM JAX_mf_diag_allTextHpo AS L \n",
    "        JOIN JAX_mf_diag_allLabHpo AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID\n",
    "    ''')\n",
    "    \n",
    "\n",
    "def initSummaryStatisticTables():\n",
    "    \"\"\"\n",
    "    Init summary statistics tables.\n",
    "    \"\"\"\n",
    "    # define empty columns to store summary statistics\n",
    "    summary_statistics1_radiology = pd.DataFrame(data={'DIAGNOSIS_CODE':[], \n",
    "                       'PHENOTYPE':[], \n",
    "                       'DIAGNOSIS_VALUE':[], \n",
    "                       'PHENOTYPE_VALUE':[], \n",
    "                       'N':[]},\n",
    "                columns = ['DIAGNOSIS_CODE', 'PHENOTYPE', 'DIAGNOSIS_VALUE', 'PHENOTYPE_VALUE', 'N'])\n",
    "    \n",
    "    summary_statistics1_lab = pd.DataFrame(data={'DIAGNOSIS_CODE':[], \n",
    "                       'PHENOTYPE':[], \n",
    "                       'DIAGNOSIS_VALUE':[], \n",
    "                       'PHENOTYPE_VALUE':[], \n",
    "                       'N':[]},\n",
    "                columns = ['DIAGNOSIS_CODE', 'PHENOTYPE', 'DIAGNOSIS_VALUE', 'PHENOTYPE_VALUE', 'N'])\n",
    "\n",
    "    summary_statistics2 = pd.DataFrame(data={'DIAGNOSIS_CODE':[], \n",
    "                       'PHEN_TXT':[], \n",
    "                       'PHEN_LAB':[], \n",
    "                       'DIAGNOSIS_VALUE':[], \n",
    "                       'PHEN_TXT_VALUE':[], \n",
    "                       'PHEN_LAB_VALUE':[], \n",
    "                       'N':[]},\n",
    "                columns = ['DIAGNOSIS_CODE', 'PHEN_TXT', 'PHEN_LAB', 'DIAGNOSIS_VALUE', 'PHEN_TXT_VALUE', 'PHEN_LAB_VALUE', 'N']) \n",
    "\n",
    "    return summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2\n",
    "\n",
    "def initTables(debug=False):\n",
    "    \"\"\"\n",
    "    This combines LabHpo and Inferred_LabHpo, and combines TextHpo and Inferred_TextHpo. \n",
    "    Only need to run once. For efficiency consideration, the tables can also be created as perminent. \n",
    "    It is time-consuming, so call it with caution. \n",
    "    \"\"\"\n",
    "    #init textHpoProfile and index it\n",
    "    #I create perminant tables to save time; other users should enable them\n",
    "    #textHpoProfile(include_inferred=True, threshold=1)\n",
    "    #indexTextHpoProfile()\n",
    "    #init labHpoProfile and index it\n",
    "    #labHpoProfile(threshold=1, include_inferred=True, force_update=True)\n",
    "    #indexLabHpoProfile()\n",
    "    \n",
    "    #define encounters to analyze\n",
    "    encounterOfInterest(debug)\n",
    "    indexEncounterOfInterest()\n",
    "    #init diagnosisProfile\n",
    "    diagnosisProfile()\n",
    "    \n",
    "\n",
    "def iterate(primary_diagnosis_only, diagnosis_threshold_min, textHpo_threshold_min, labHpo_threshold_min, logger): \n",
    "    logger.info('starting iterating...................................')\n",
    "    N = pd.read_sql_query(\"SELECT count(*) FROM JAX_encounterOfInterest\", mydb)\n",
    "    # init empty tables to hold summary statistics\n",
    "    summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 = initSummaryStatisticTables()\n",
    "    \n",
    "    # define a set of diseases that we want to analyze\n",
    "    rankICD()\n",
    "    \n",
    "    diseaseOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_diagFrequencyRank WHERE N > {}\".format(diagnosis_threshold_min), mydb).ICD9_CODE.values\n",
    "    diseaseOfInterest = ['428']\n",
    "    # define encounters to analyze\n",
    "    logger.info('diseases of interest established: {}'.format(len(diseaseOfInterest)))\n",
    "    for diagnosis in diseaseOfInterest:\n",
    "        logger.info(\"start analyzing disease {}\".format(diagnosis))\n",
    "        \n",
    "        # assign each encounter whether a diagnosis code is observed\n",
    "        # create a table j1 (joint 1)\n",
    "        createDiagnosisTable(diagnosis, primary_diagnosis_only)\n",
    "        # for every diagnosis, find phenotypes of interest to look at from radiology reports\n",
    "        # for every diagnosis, find phenotypes of interest to look at from laboratory tests\n",
    "        rankHpoFromText(diagnosis)\n",
    "        rankHpoFromLab(diagnosis)\n",
    "        \n",
    "        textHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_textHpoFrequencyRank WHERE N > {}\".format(textHpo_threshold_min), mydb).MAP_TO.values\n",
    "        labHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_labHpoFrequencyRank WHERE N > {}\".format(labHpo_threshold_min), mydb).MAP_TO.values\n",
    "        logger.info(\"TextHpo of interest established, size: {}\".format(len(textHpoOfInterest)))\n",
    "        logger.info(\"LabHpo of interest established, size: {}\".format(len(labHpoOfInterest)))\n",
    "        for textHpo in textHpoOfInterest:\n",
    "            logger.info(\"iteration: TextHpo--{}\".format(textHpo))\n",
    "            # assign each encounter whether a phenotype is observed from radiology reports\n",
    "            diagnosisTextHpo(textHpo)            \n",
    "            result1_text = pd.read_sql_query('''\n",
    "                SELECT \n",
    "                    '{}' AS DIAGNOSIS_CODE, '{}' AS PHENOTYPE, DIAGNOSIS AS DIAGNOSIS_VALUE, PHEN_TXT_VALUE AS PHENOTYPE_VALUE, COUNT(*) AS N \n",
    "                FROM JAX_mf_diag_textHpo \n",
    "                GROUP BY \n",
    "                    DIAGNOSIS, PHEN_TXT_VALUE\n",
    "            '''.format(diagnosis, textHpo), mydb)\n",
    "            summary_statistics1_radiology = summary_statistics1_radiology.append(result1_text)\n",
    "            # summary statistics for p1\n",
    "            # calculate I(p1;D)\n",
    "            for labHpo in labHpoOfInterest:\n",
    "                logger.info(\".........LabHpo--{}\".format(labHpo))\n",
    "                diagnosisLabHpo(labHpo)\n",
    "                result1_lab = pd.read_sql_query('''\n",
    "                    SELECT \n",
    "                        '{}' AS DIAGNOSIS_CODE, '{}' AS PHENOTYPE, DIAGNOSIS AS DIAGNOSIS_VALUE, PHEN_LAB_VALUE AS PHENOTYPE_VALUE, COUNT(*) AS N \n",
    "                    FROM \n",
    "                        JAX_mf_diag_labHpo \n",
    "                    GROUP BY DIAGNOSIS, PHEN_LAB_VALUE\n",
    "                '''.format(diagnosis, labHpo), mydb)\n",
    "                summary_statistics1_lab = summary_statistics1_lab.append(result1_lab)\n",
    "            \n",
    "                # assign each encounter whether a phenotype is observed from lab tests\n",
    "                diagnosisTextLab(labHpo)\n",
    "                result2 = pd.read_sql_query('''\n",
    "                    SELECT \n",
    "                        '{}' AS DIAGNOSIS_CODE, \n",
    "                        '{}' AS PHEN_TXT, \n",
    "                        '{}' AS PHEN_LAB,  \n",
    "                        DIAGNOSIS AS DIAGNOSIS_VALUE, \n",
    "                        PHEN_TXT_VALUE, \n",
    "                        PHEN_LAB_VALUE, \n",
    "                        COUNT(*) AS N\n",
    "                    FROM JAX_mf_diag_txtHpo_labHpo \n",
    "                    GROUP BY DIAGNOSIS, PHEN_TXT_VALUE, PHEN_LAB_VALUE\n",
    "                '''.format(diagnosis, textHpo, labHpo), mydb)\n",
    "                summary_statistics2 = summary_statistics2.append(result2)\n",
    "    logger.info('end iterating.....................................')            \n",
    "    return N, summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 \n",
    "\n",
    "\n",
    "def iterate_batch(primary_diagnosis_only, diagnosis_threshold_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max, logger): \n",
    "    logger.info('starting iterating...................................')\n",
    "    N = pd.read_sql_query(\"SELECT count(*) FROM JAX_encounterOfInterest\", mydb)\n",
    "    # init empty tables to hold summary statistics\n",
    "    summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 = initSummaryStatisticTables()\n",
    "    \n",
    "    # define a set of diseases that we want to analyze\n",
    "    rankICD()\n",
    "    \n",
    "    diseaseOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_diagFrequencyRank WHERE N > {}\".format(diagnosis_threshold_min), mydb).ICD9_CODE.values\n",
    "    diseaseOfInterest = ['428']\n",
    "    logger.info('diseases of interest established: {}'.format(len(diseaseOfInterest)))\n",
    "    \n",
    "    for diagnosis in diseaseOfInterest:\n",
    "        logger.info(\"start analyzing disease {}\".format(diagnosis))\n",
    "        \n",
    "        logger.info(\".......assigning values of diagnosis\")\n",
    "        # assign each encounter whether a diagnosis code is observed\n",
    "        # create a table j1 (joint 1)\n",
    "        createDiagnosisTable(diagnosis, primary_diagnosis_only)\n",
    "        # for every diagnosis, find phenotypes of interest to look at from radiology reports\n",
    "        # for every diagnosis, find phenotypes of interest to look at from laboratory tests\n",
    "        rankHpoFromText(diagnosis)\n",
    "        rankHpoFromLab(diagnosis)\n",
    "        logger.info(\"..............diagnosis values found\")\n",
    "        \n",
    "        logger.info(\".......assigning values of TextHpo\")\n",
    "        diagnosisAllTextHpo(textHpo_threshold_min, textHpo_threshold_max)\n",
    "        result1_text = pd.read_sql_query(\"\"\"\n",
    "            SELECT '{}' AS DIAGNOSIS_CODE, \n",
    "                PHEN_TXT AS PHENOTYPE, \n",
    "                DIAGNOSIS AS DIAGNOSIS_VALUE, \n",
    "                PHEN_TXT_VALUE AS PHENOTYPE_VALUE, \n",
    "                COUNT(*) AS N \n",
    "            FROM JAX_mf_diag_allTextHpo \n",
    "            GROUP BY DIAGNOSIS, PHEN_TXT, PHEN_TXT_VALUE\n",
    "        \"\"\".format(diagnosis), mydb)\n",
    "        logger.info(\"..............TextHpo values found\")\n",
    "        summary_statistics1_radiology = summary_statistics1_radiology.append(result1_text)\n",
    "\n",
    "        \n",
    "        logger.info(\".......assigning values of LabHpo\")\n",
    "        diagnosisAllLabHpo(labHpo_threshold_min, labHpo_threshold_max)\n",
    "        result1_lab = pd.read_sql_query(\"\"\"\n",
    "            SELECT \n",
    "                '{}' AS DIAGNOSIS_CODE, \n",
    "                PHEN_LAB AS PHENOTYPE, \n",
    "                DIAGNOSIS AS DIAGNOSIS_VALUE, \n",
    "                PHEN_LAB_VALUE AS PHENOTYPE_VALUE, \n",
    "                COUNT(*) AS N \n",
    "            FROM JAX_mf_diag_allLabHpo \n",
    "            GROUP BY DIAGNOSIS, PHEN_LAB, PHEN_LAB_VALUE\n",
    "        \"\"\".format(diagnosis), mydb)\n",
    "        logger.info(\"..............LabHpo values found\")\n",
    "        summary_statistics1_lab = summary_statistics1_lab.append(result1_lab)\n",
    "\n",
    "        logger.info(\".......building diagnosis-TextHpo-LabHpo joint distribution\")\n",
    "        diagnosisAllTextAllLab()\n",
    "        result2 = pd.read_sql_query(\"\"\"\n",
    "            SELECT \n",
    "                '{}' AS DIAGNOSIS_CODE, \n",
    "                PHEN_TXT, \n",
    "                PHEN_LAB, \n",
    "                DIAGNOSIS AS DIAGNOSIS_VALUE,\n",
    "                PHEN_TXT_VALUE, \n",
    "                PHEN_LAB_VALUE, \n",
    "                COUNT(*) AS N \n",
    "            FROM JAX_mf_diag_allTxtHpo_allLabHpo \n",
    "            GROUP BY DIAGNOSIS, PHEN_LAB, PHEN_LAB_VALUE, PHEN_TXT, PHEN_TXT_VALUE\n",
    "        \"\"\".format(diagnosis) , mydb)\n",
    "        logger.info(\"..............diagnosis-TextHpo-LabHpo joint distribution built\")\n",
    "        summary_statistics2 = summary_statistics2.append(result2)\n",
    "\n",
    "    logger.info('end iterating.....................................')            \n",
    "    return N, summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to run this\n",
    "# it takes either too long or too much memory space to run\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# 1. build the temp tables for Lab converted HPO, Text convert HPO\n",
    "# Read the comments within the method!\n",
    "#initTables(debug=False)\n",
    "# 2. iterate the database t (for debug, use parameter values: 0, 10, 15, for production, use parameter values: 0, 10000, 10000\n",
    "#N, summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 = iterate(diagnosis_threshold_min=0, textHpo_threshold_min=10, labHpo_threshold_min=15, logger=logger)\n",
    "#N, summary_statistics1_radiology, summary_statistics1_lab, summary_statistics2 = iterate(diagnosis_threshold_min=0, textHpo_threshold_min=1000, labHpo_threshold_min=1000, logger=logger)\n",
    "\n",
    "# 2b. use the batch method\n",
    "#N2, summary_statistics1_radiology2, summary_statistics1_lab2, summary_statistics22 = iterate_batch(diagnosis_threshold_min=0, textHpo_threshold_min=0, textHpo_threshold_max=100, labHpo_threshold_min=0, labHpo_threshold_max=100, logger=logger)\n",
    "#N2, summary_statistics1_radiology2, summary_statistics1_lab2, summary_statistics22 = iterate_batch(diagnosis_threshold_min=0, textHpo_threshold_min=1000, textHpo_threshold_max=100000, labHpo_threshold_min=1000, labHpo_threshold_max=100000, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexDiagnosisTable():\n",
    "    cursor.execute(\"ALTER TABLE JAX_mf_diag ADD COLUMN ROW_ID INT AUTO_INCREMENT PRIMARY KEY;\")\n",
    "    \n",
    "def batch_query(start_index, end_index, textHpo_occurrance_min, labHpo_occurrance_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max):\n",
    "    \"\"\"\n",
    "    Queries databases in small batches, return diagnosis values, phenotypes from text data and phenotypes from lab data.\n",
    "    @param start_index: minimum row_id\n",
    "    @param end_index: maximum row_id\n",
    "    @param textHpo_occurrance_min: minimum occurrances of a phenotype from text data for it to be called in one encounter\n",
    "    @param labHpo_occurrance_max: maximum occurrances of a phenotype from lab tests for it to be called in one encounter\n",
    "    @param textHpo_threshold_min: minimum number of encounters of a phenotypes from text data for it to be analyzed\n",
    "    @param textHpo_threshold_max: maximum number of encounters of a phenotypes from text data for it to be analyzed\n",
    "    @param labHpo_threshold_min: minimum number of encounters of a phenotype from lab tests for it to be analyzed\n",
    "    @param labHpo_threshold_max: maximum number of encounters of a phenotype from lab tests for it to be analyzed\n",
    "    \"\"\"\n",
    "    diagnosisVector = pd.read_sql_query('''\n",
    "        SELECT * FROM JAX_mf_diag WHERE ROW_ID BETWEEN {} AND {}\n",
    "    '''.format(start_index, end_index), mydb)\n",
    "    \n",
    "    textHpoFlat = pd.read_sql_query('''\n",
    "        WITH encounters AS (\n",
    "            SELECT SUBJECT_ID, HADM_ID\n",
    "            FROM JAX_mf_diag \n",
    "            WHERE ROW_ID BETWEEN {} AND {}\n",
    "        ), \n",
    "        textHpoOfInterest AS (\n",
    "            SELECT MAP_TO \n",
    "            FROM JAX_textHpoFrequencyRank \n",
    "            WHERE N BETWEEN {} AND {}\n",
    "        ), \n",
    "        joint as (\n",
    "            SELECT *\n",
    "            FROM encounters \n",
    "            JOIN textHpoOfInterest),\n",
    "        JAX_textHpoProfile_filtered AS (\n",
    "            SELECT * \n",
    "            FROM JAX_textHpoProfile \n",
    "            WHERE OCCURRANCE >= {}\n",
    "        )\n",
    "        \n",
    "        SELECT L.SUBJECT_ID, L.HADM_ID, L.MAP_TO, IF(R.dummy IS NULL, 0, 1) AS VALUE\n",
    "        FROM joint as L\n",
    "        LEFT JOIN \n",
    "        JAX_textHpoProfile_filtered AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.MAP_TO = R.MAP_TO  \n",
    "    '''.format(start_index, end_index, textHpo_threshold_min, textHpo_threshold_max, textHpo_occurrance_min), mydb)\n",
    "    \n",
    "    labHpoFlat = pd.read_sql_query('''\n",
    "        WITH encounters AS (\n",
    "            SELECT SUBJECT_ID, HADM_ID\n",
    "            FROM JAX_mf_diag \n",
    "            WHERE ROW_ID BETWEEN {} AND {}\n",
    "        ), \n",
    "        labHpoOfInterest AS (\n",
    "            SELECT MAP_TO \n",
    "            FROM JAX_labHpoFrequencyRank \n",
    "            WHERE N BETWEEN {} AND {}\n",
    "        ), \n",
    "        joint as (\n",
    "            SELECT *\n",
    "            FROM encounters \n",
    "            JOIN labHpoOfInterest),\n",
    "        JAX_labHpoProfile_filtered AS (\n",
    "            SELECT * \n",
    "            FROM JAX_labHpoProfile \n",
    "            WHERE OCCURRANCE >= {}\n",
    "        )\n",
    "        \n",
    "        SELECT L.SUBJECT_ID, L.HADM_ID, L.MAP_TO, IF(R.dummy IS NULL, 0, 1) AS VALUE\n",
    "        FROM joint as L\n",
    "        LEFT JOIN \n",
    "        JAX_labHpoProfile_filtered AS R\n",
    "        ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.MAP_TO = R.MAP_TO\n",
    "    '''.format(start_index, end_index, labHpo_threshold_min, labHpo_threshold_max, labHpo_occurrance_min), mydb)\n",
    "    \n",
    "    return diagnosisVector, textHpoFlat, labHpoFlat\n",
    "\n",
    "def summarize_diagnosis_textHpo_labHpo(primary_diagnosis_only, textHpo_occurrance_min, labHpo_occurrance_min, diagnosis_threshold_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max, logger):\n",
    "    \"\"\"\n",
    "    Iterate database to get summary statistics. \n",
    "    \n",
    "    @param primary_diagnosis_only: only primary diagnosis is analyzed\n",
    "    @param textHpo_occurrance_min: minimum occurrances of a phenotype from text data for it to be called in one encounter\n",
    "    @param labHpo_occurrance_max: maximum occurrances of a phenotype from lab tests for it to be called in one encounter\n",
    "    @param textHpo_threshold_min: minimum number of encounters of a phenotypes from text data for it to be analyzed\n",
    "    @param textHpo_threshold_max: maximum number of encounters of a phenotypes from text data for it to be analyzed\n",
    "    @param labHpo_threshold_min: minimum number of encounters of a phenotype from lab tests for it to be analyzed\n",
    "    @param labHpo_threshold_max: maximum number of encounters of a phenotype from lab tests for it to be analyzed\n",
    "    @param logger: logger for logging\n",
    "    \n",
    "    \"\"\"\n",
    "    logger.info('starting iterate_in_batch()')\n",
    "    batch_size = 100\n",
    "    \n",
    "    # define a set of diseases that we want to analyze\n",
    "    rankICD()\n",
    "    \n",
    "    diseaseOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_diagFrequencyRank WHERE N > {}\".format(diagnosis_threshold_min), mydb).ICD9_CODE.values\n",
    "    #disable the following line to analyze all diseases of interest\n",
    "    diseaseOfInterest = ['428', '584', '038']\n",
    "    logger.info('diagnosis of interest: {}'.format(len(diseaseOfInterest)))\n",
    "    \n",
    "    summaries_diag_textHpo_labHpo = {}\n",
    "    summaries_diag_textHpo_textHpo = {}\n",
    "    summaries_diag_labHpo_labHpo = {}\n",
    "    \n",
    "    pbar = tqdm(total=len(diseaseOfInterest))\n",
    "    for diagnosis in diseaseOfInterest:\n",
    "        logger.info(\"start analyzing disease {}\".format(diagnosis))\n",
    "        \n",
    "        logger.info(\".......assigning values of diagnosis\")\n",
    "        # assign each encounter whether a diagnosis code is observed\n",
    "        # create a table j1 (joint 1)\n",
    "        createDiagnosisTable(diagnosis, primary_diagnosis_only)\n",
    "        indexDiagnosisTable()\n",
    "        # for every diagnosis, find phenotypes of interest to look at from radiology reports\n",
    "        # for every diagnosis, find phenotypes of interest to look at from laboratory tests\n",
    "        rankHpoFromText(diagnosis, textHpo_occurrance_min)\n",
    "        rankHpoFromLab(diagnosis, labHpo_occurrance_min)\n",
    "        logger.info(\"..............diagnosis values found\")\n",
    "        \n",
    "        textHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_textHpoFrequencyRank WHERE N BETWEEN {} AND {}\".format(textHpo_threshold_min, textHpo_threshold_max), mydb).MAP_TO.values\n",
    "        labHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_labHpoFrequencyRank WHERE N BETWEEN {} AND {}\".format(labHpo_threshold_min, labHpo_threshold_max), mydb).MAP_TO.values\n",
    "        logger.info(\"TextHpo of interest established, size: {}\".format(len(textHpoOfInterest)))\n",
    "        logger.info(\"LabHpo of interest established, size: {}\".format(len(labHpoOfInterest)))\n",
    "\n",
    "        ## find the start and end ROW_ID for patient*encounter\n",
    "        ADM_ID_START, ADM_ID_END = pd.read_sql_query('SELECT MIN(ROW_ID) AS min, MAX(ROW_ID) AS max FROM JAX_mf_diag', mydb).iloc[0]\n",
    "        batch_N = ADM_ID_END - ADM_ID_START + 1\n",
    "        TOTAL_BATCH = math.ceil(batch_N / batch_size) # total number of batches\n",
    "        \n",
    "        summaries_diag_textHpo_labHpo[diagnosis] = mf.SummaryXYz(textHpoOfInterest, labHpoOfInterest, diagnosis)\n",
    "        summaries_diag_textHpo_textHpo[diagnosis] = mf.SummaryXYz(textHpoOfInterest, textHpoOfInterest, diagnosis)\n",
    "        summaries_diag_labHpo_labHpo[diagnosis] = mf.SummaryXYz(labHpoOfInterest, labHpoOfInterest, diagnosis)\n",
    "        \n",
    "        logger.info('starting batch queries for {}'.format(diagnosis))\n",
    "        for i in np.arange(TOTAL_BATCH):\n",
    "            start_index = i * batch_size + ADM_ID_START\n",
    "            if i < TOTAL_BATCH - 1:\n",
    "                end_index = start_index + batch_size - 1\n",
    "            else:\n",
    "                end_index = batch_N\n",
    "\n",
    "            diagnosisFlat, textHpoFlat, labHpoFlat =  batch_query(start_index, end_index, textHpo_occurrance_min, labHpo_occurrance_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max)\n",
    "            \n",
    "            batch_size_actual = len(diagnosisFlat)\n",
    "            textHpoOfInterest_size = len(textHpoOfInterest)\n",
    "            labHpoOfInterest_size = len(labHpoOfInterest)\n",
    "            #print('len(textHpoFlat)= {}, batch_size_actual={}, textHpoOfInterest_size={}'.format(len(textHpoFlat), batch_size_actual, textHpoOfInterest_size))\n",
    "            assert(len(textHpoFlat) == batch_size_actual * textHpoOfInterest_size)\n",
    "            assert(len(labHpoFlat) == batch_size_actual * labHpoOfInterest_size)\n",
    "            \n",
    "            if batch_size_actual > 0:\n",
    "                diagnosisVector = diagnosisFlat.DIAGNOSIS.values.astype(int)\n",
    "                # reformat the flat vector into N x M matrix, N is batch size, i.e. number of encounters, M is the length of HPO terms  \n",
    "                textHpoMatrix = textHpoFlat.VALUE.values.astype(int).reshape([batch_size_actual, textHpoOfInterest_size], order='F')\n",
    "                labHpoMatrix = labHpoFlat.VALUE.values.astype(int).reshape([batch_size_actual, labHpoOfInterest_size], order='F')\n",
    "                # check the matrix formatting is correct\n",
    "                # disable the following 4 lines to speed things up\n",
    "                textHpoLabelsMatrix = textHpoFlat.MAP_TO.values.reshape([batch_size_actual, textHpoOfInterest_size], order='F')\n",
    "                labHpoLabelsMatrix = labHpoFlat.MAP_TO.values.reshape([batch_size_actual, labHpoOfInterest_size], order='F')\n",
    "                assert (textHpoLabelsMatrix[0, :] == textHpoOfInterest).all()\n",
    "                assert (labHpoLabelsMatrix[0, :] == labHpoOfInterest).all()\n",
    "                if i % 100 == 0:\n",
    "                    logger.info('new batch: start_index={}, end_index={}, batch_size= {}, textHpo_size = {}, labHpo_size = {}'.format(start_index, end_index, batch_size_actual, textHpoMatrix.shape[1], labHpoMatrix.shape[1]))\n",
    "                summaries_diag_textHpo_labHpo[diagnosis].add_batch(textHpoMatrix,labHpoMatrix, diagnosisVector)\n",
    "                summaries_diag_textHpo_textHpo[diagnosis].add_batch(textHpoMatrix,textHpoMatrix, diagnosisVector)\n",
    "                summaries_diag_labHpo_labHpo[diagnosis].add_batch(labHpoMatrix,labHpoMatrix, diagnosisVector)\n",
    "         \n",
    "        pbar.update(1)\n",
    "        \n",
    "    pbar.close()\n",
    "    \n",
    "    return summaries_diag_textHpo_labHpo, summaries_diag_textHpo_textHpo, summaries_diag_labHpo_labHpo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  --TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-21 14:38:58,960 - 6689 - root - INFO - starting iterate_in_batch()\n",
      "2019-10-21 14:38:58,966 - 6689 - root - INFO - diagnosis of interest: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-21 14:38:58,967 - 6689 - root - INFO - start analyzing disease 428\n",
      "2019-10-21 14:38:58,968 - 6689 - root - INFO - .......assigning values of diagnosis\n",
      "2019-10-21 14:38:58,997 - 6689 - root - INFO - ..............diagnosis values found\n",
      "2019-10-21 14:38:59,002 - 6689 - root - INFO - TextHpo of interest established, size: 28\n",
      "2019-10-21 14:38:59,002 - 6689 - root - INFO - LabHpo of interest established, size: 52\n",
      "2019-10-21 14:38:59,005 - 6689 - root - INFO - starting batch queries for 428\n",
      "2019-10-21 14:38:59,137 - 6689 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 28, labHpo_size = 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 1/3 [00:00<00:00,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-21 14:38:59,152 - 6689 - root - INFO - start analyzing disease 584\n",
      "2019-10-21 14:38:59,153 - 6689 - root - INFO - .......assigning values of diagnosis\n",
      "2019-10-21 14:38:59,168 - 6689 - root - INFO - ..............diagnosis values found\n",
      "2019-10-21 14:38:59,172 - 6689 - root - INFO - TextHpo of interest established, size: 9\n",
      "2019-10-21 14:38:59,173 - 6689 - root - INFO - LabHpo of interest established, size: 29\n",
      "2019-10-21 14:38:59,175 - 6689 - root - INFO - starting batch queries for 584\n",
      "2019-10-21 14:38:59,241 - 6689 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 9, labHpo_size = 29\n",
      "2019-10-21 14:38:59,246 - 6689 - root - INFO - start analyzing disease 038\n",
      "2019-10-21 14:38:59,247 - 6689 - root - INFO - .......assigning values of diagnosis\n",
      "2019-10-21 14:38:59,269 - 6689 - root - INFO - ..............diagnosis values found\n",
      "2019-10-21 14:38:59,274 - 6689 - root - INFO - TextHpo of interest established, size: 14\n",
      "2019-10-21 14:38:59,274 - 6689 - root - INFO - LabHpo of interest established, size: 25\n",
      "2019-10-21 14:38:59,277 - 6689 - root - INFO - starting batch queries for 038\n",
      "2019-10-21 14:38:59,357 - 6689 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 14, labHpo_size = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  6.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# how to run this\n",
    "\n",
    "# Again, it take either too long or too much memory space to run\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# 1. build the temp tables for Lab converted HPO, Text convert HPO\n",
    "# Read the comments within the method!\n",
    "initTables(debug=True)\n",
    "\n",
    "# 2. iterate throw the dataset\n",
    "primary_diagnosis_only = True\n",
    "diagnosis_threshold_min = 5\n",
    "textHpo_occurrance_min, labHpo_occurrance_min = 1, 3\n",
    "textHpo_threshold_min, textHpo_threshold_max = 7, 100\n",
    "labHpo_threshold_min, labHpo_threshold_max = 7, 100\n",
    "\n",
    "summaries_diag_textHpo_labHpo, summaries_diag_textHpo_textHpo, summaries_diag_labHpo_labHpo = summarize_diagnosis_textHpo_labHpo(primary_diagnosis_only, textHpo_occurrance_min, labHpo_occurrance_min, diagnosis_threshold_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 25, 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_diag_textHpo_labHpo['038'].m2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --PRODUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [32:12<00:00, 641.69s/it]\n"
     ]
    }
   ],
   "source": [
    "# how to run this\n",
    "# Again, it take either too long or too much memory space to run\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.WARN)\n",
    "\n",
    "# 1. build the temp tables for Lab converted HPO, Text convert HPO\n",
    "# Read the comments within the method!\n",
    "initTables(debug=False)\n",
    "\n",
    "# 2. iterate throw the dataset\n",
    "primary_diagnosis_only = False\n",
    "diagnosis_threshold_min = 3000\n",
    "textHpo_threshold_min, textHpo_threshold_max = 500, 100000\n",
    "labHpo_threshold_min, labHpo_threshold_max = 1000, 100000\n",
    "textHpo_occurrance_min, labHpo_occurrance_min = 1, 3\n",
    "\n",
    "summaries_diag_textHpo_labHpo, summaries_diag_textHpo_textHpo, summaries_diag_labHpo_labHpo = summarize_diagnosis_textHpo_labHpo(primary_diagnosis_only, textHpo_occurrance_min, labHpo_occurrance_min, diagnosis_threshold_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if primary_diagnosis_only:\n",
    "    fName_diag_textHpo_labHpo = '../../../data/mf_regarding_diseases/primary_only/summaries_diagnosis_textHpo_labHpo.obj'\n",
    "    fName_diag_textHpo_textHpo = '../../../data/mf_regarding_diseases/primary_only/summaries_diagnosis_textHpo_textHpo.obj'\n",
    "    fName_diag_labHpo_labHpo = '../../../data/mf_regarding_diseases/primary_only/summaries_diagnosis_labHpo_labHpo.obj'\n",
    "else:\n",
    "    fName_diag_textHpo_labHpo = '../../../data/mf_regarding_diseases/primary_and_secondary/summaries_diagnosis_textHpo_labHpo.obj'\n",
    "    fName_diag_textHpo_textHpo = '../../../data/mf_regarding_diseases/primary_and_secondary/summaries_diagnosis_textHpo_textHpo.obj'\n",
    "    fName_diag_labHpo_labHpo = '../../../data/mf_regarding_diseases/primary_and_secondary/summaries_diagnosis_labHpo_labHpo.obj'\n",
    "\n",
    "with open(fName_diag_textHpo_labHpo, 'wb') as f:\n",
    "    pickle.dump(summaries_diag_textHpo_labHpo, f)\n",
    "with open(fName_diag_textHpo_textHpo, 'wb') as f:\n",
    "    pickle.dump(summaries_diag_textHpo_textHpo, f)\n",
    "with open(fName_diag_labHpo_labHpo, 'wb') as f:\n",
    "    pickle.dump(summaries_diag_labHpo_labHpo, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'428': <mf.SummaryXYz at 0xa1aef1dd8>,\n",
       " '584': <mf.SummaryXYz at 0xa1ae5d358>,\n",
       " '038': <mf.SummaryXYz at 0x1083c4cf8>}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_diag_textHpo_labHpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mutual information among radiology phenotypes or among lab phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_intra_textHpo_or_intra_labHpo(primary_diagnosis_only, textHpo_occurrance_min, labHpo_occurrance_min, diagnosis_threshold_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max, logger):\n",
    "    logger.info('starting iterate_in_batch()')\n",
    "    batch_size = 100\n",
    "    \n",
    "    # define a set of diseases that we want to analyze\n",
    "    rankICD()\n",
    "    \n",
    "    diseaseOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_diagFrequencyRank WHERE N > {}\".format(diagnosis_threshold_min), mydb).ICD9_CODE.values\n",
    "    diseaseOfInterest = ['428', '584', '038']\n",
    "    logger.info('diagnosis of interest: {}'.format(len(diseaseOfInterest)))\n",
    "    \n",
    "    summaries_text_text = {}\n",
    "    summaries_lab_lab = {}\n",
    "    \n",
    "    pbar = tqdm(total=len(diseaseOfInterest))\n",
    "    for diagnosis in diseaseOfInterest:\n",
    "        logger.info(\"start analyzing disease {}\".format(diagnosis))\n",
    "        \n",
    "        logger.info(\".......assigning values of diagnosis\")\n",
    "        # assign each encounter whether a diagnosis code is observed\n",
    "        # create a table j1 (joint 1)\n",
    "        createDiagnosisTable(diagnosis, primary_diagnosis_only)\n",
    "        indexDiagnosisTable()\n",
    "        # for every diagnosis, find phenotypes of interest to look at from radiology reports\n",
    "        # for every diagnosis, find phenotypes of interest to look at from laboratory tests\n",
    "        rankHpoFromText(diagnosis, textHpo_occurrance_min)\n",
    "        rankHpoFromLab(diagnosis, labHpo_occurrance_min)\n",
    "        logger.info(\"..............diagnosis values found\")\n",
    "        \n",
    "        textHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_textHpoFrequencyRank WHERE N BETWEEN {} AND {}\".format(textHpo_threshold_min, textHpo_threshold_max), mydb).MAP_TO.values\n",
    "        labHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_labHpoFrequencyRank WHERE N BETWEEN {} AND {}\".format(labHpo_threshold_min, labHpo_threshold_max), mydb).MAP_TO.values\n",
    "        logger.info(\"TextHpo of interest established, size: {}\".format(len(textHpoOfInterest)))\n",
    "        logger.info(\"LabHpo of interest established, size: {}\".format(len(labHpoOfInterest)))\n",
    "\n",
    "        ## find the start and end ROW_ID for patient*encounter\n",
    "        ADM_ID_START, ADM_ID_END = pd.read_sql_query('SELECT MIN(ROW_ID) AS min, MAX(ROW_ID) AS max FROM JAX_mf_diag', mydb).iloc[0]\n",
    "        batch_N = ADM_ID_END - ADM_ID_START + 1\n",
    "        TOTAL_BATCH = math.ceil(batch_N / batch_size) # total number of batches\n",
    "        \n",
    "        summaries_text_text[diagnosis] = mf.SummaryXYz(textHpoOfInterest, textHpoOfInterest, diagnosis)\n",
    "        summaries_lab_lab[diagnosis] = mf.SummaryXYz(labHpoOfInterest, labHpoOfInterest, diagnosis)\n",
    "        \n",
    "        logger.info('starting batch queries for {}'.format(diagnosis))\n",
    "        for i in np.arange(TOTAL_BATCH):\n",
    "            start_index = i * batch_size + ADM_ID_START\n",
    "            if i < TOTAL_BATCH - 1:\n",
    "                end_index = start_index + batch_size - 1\n",
    "            else:\n",
    "                end_index = batch_N\n",
    "\n",
    "            diagnosisFlat, textHpoFlat, labHpoFlat =  batch_query(start_index, end_index, textHpo_occurrance_min, labHpo_occurrance_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max)\n",
    "\n",
    "            batch_size_actual = len(diagnosisFlat)\n",
    "            textHpoOfInterest_size = len(textHpoOfInterest)\n",
    "            labHpoOfInterest_size = len(labHpoOfInterest)\n",
    "            assert(len(textHpoFlat) == batch_size_actual * textHpoOfInterest_size)\n",
    "            assert(len(labHpoFlat) == batch_size_actual * labHpoOfInterest_size)\n",
    "            \n",
    "            if batch_size_actual > 0:\n",
    "                diagnosisVector = diagnosisFlat.DIAGNOSIS.values.astype(int)\n",
    "                # reformat the flat vector into N x M matrix, N is batch size, i.e. number of encounters, M is the length of HPO terms  \n",
    "                textHpoMatrix = textHpoFlat.VALUE.values.astype(int).reshape([batch_size_actual, textHpoOfInterest_size], order='F')\n",
    "                labHpoMatrix = labHpoFlat.VALUE.values.astype(int).reshape([batch_size_actual, labHpoOfInterest_size], order='F')\n",
    "                # check the matrix formatting is correct\n",
    "                # disable the following 4 lines to speed things up\n",
    "                textHpoLabelsMatrix = textHpoFlat.MAP_TO.values.reshape([batch_size_actual, textHpoOfInterest_size], order='F')\n",
    "                labHpoLabelsMatrix = labHpoFlat.MAP_TO.values.reshape([batch_size_actual, labHpoOfInterest_size], order='F')\n",
    "                assert (textHpoLabelsMatrix[0, :] == textHpoOfInterest).all()\n",
    "                assert (labHpoLabelsMatrix[0, :] == labHpoOfInterest).all()\n",
    "                if i % 100 == 0:\n",
    "                    logger.info('new batch: start_index={}, end_index={}, batch_size= {}, textHpo_size = {}, labHpo_size = {}'.format(start_index, end_index, batch_size_actual, textHpoMatrix.shape[1], labHpoMatrix.shape[1]))\n",
    "                \n",
    "                summaries_text_text[diagnosis].add_batch(textHpoMatrix,textHpoMatrix, diagnosisVector)\n",
    "                summaries_lab_lab[diagnosis].add_batch(labHpoMatrix, labHpoMatrix, diagnosisVector)\n",
    "         \n",
    "        pbar.update(1)\n",
    "        \n",
    "    pbar.close()\n",
    "    \n",
    "    return summaries_text_text, summaries_lab_lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-16 15:43:03,917 - 2538 - root - INFO - starting iterate_in_batch()\n",
      "2019-10-16 15:43:03,923 - 2538 - root - INFO - diagnosis of interest: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-16 15:43:03,926 - 2538 - root - INFO - start analyzing disease 428\n",
      "2019-10-16 15:43:03,927 - 2538 - root - INFO - .......assigning values of diagnosis\n",
      "2019-10-16 15:43:03,960 - 2538 - root - INFO - ..............diagnosis values found\n",
      "2019-10-16 15:43:03,966 - 2538 - root - INFO - TextHpo of interest established, size: 28\n",
      "2019-10-16 15:43:03,967 - 2538 - root - INFO - LabHpo of interest established, size: 52\n",
      "2019-10-16 15:43:03,970 - 2538 - root - INFO - starting batch queries for 428\n",
      "2019-10-16 15:43:04,111 - 2538 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 28, labHpo_size = 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  5.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-16 15:43:04,128 - 2538 - root - INFO - start analyzing disease 584\n",
      "2019-10-16 15:43:04,129 - 2538 - root - INFO - .......assigning values of diagnosis\n",
      "2019-10-16 15:43:04,147 - 2538 - root - INFO - ..............diagnosis values found\n",
      "2019-10-16 15:43:04,151 - 2538 - root - INFO - TextHpo of interest established, size: 9\n",
      "2019-10-16 15:43:04,152 - 2538 - root - INFO - LabHpo of interest established, size: 29\n",
      "2019-10-16 15:43:04,155 - 2538 - root - INFO - starting batch queries for 584\n",
      "2019-10-16 15:43:04,225 - 2538 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 9, labHpo_size = 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  5.86it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-16 15:43:04,230 - 2538 - root - INFO - start analyzing disease 038\n",
      "2019-10-16 15:43:04,231 - 2538 - root - INFO - .......assigning values of diagnosis\n",
      "2019-10-16 15:43:04,255 - 2538 - root - INFO - ..............diagnosis values found\n",
      "2019-10-16 15:43:04,260 - 2538 - root - INFO - TextHpo of interest established, size: 14\n",
      "2019-10-16 15:43:04,261 - 2538 - root - INFO - LabHpo of interest established, size: 25\n",
      "2019-10-16 15:43:04,264 - 2538 - root - INFO - starting batch queries for 038\n",
      "2019-10-16 15:43:04,346 - 2538 - root - INFO - new batch: start_index=1, end_index=100, batch_size= 100, textHpo_size = 14, labHpo_size = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:00<00:00,  6.41it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "# how to run this\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# 1. build the temp tables for Lab converted HPO, Text convert HPO\n",
    "# Read the comments within the method!\n",
    "initTables(debug=True)\n",
    "\n",
    "# 2. iterate throw the dataset\n",
    "primary_diagnosis_only = True\n",
    "diagnosis_threshold_min = 5\n",
    "textHpo_threshold_min, textHpo_threshold_max = 7, 100\n",
    "labHpo_threshold_min, labHpo_threshold_max = 7, 100\n",
    "textHpo_occurrance_min, labHpo_occurrance_min = 1, 3\n",
    "\n",
    "summaries_text_text, summaries_lab_lab = summarize_intra_textHpo_or_intra_labHpo(primary_diagnosis_only, textHpo_occurrance_min, labHpo_occurrance_min, diagnosis_threshold_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max, logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [10:00<20:01, 600.98s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [21:15<10:23, 623.08s/it]\u001b[A\n",
      "100%|██████████| 3/3 [27:51<00:00, 555.06s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "# how to run this\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.WARN)\n",
    "\n",
    "# 1. build the temp tables for Lab converted HPO, Text convert HPO\n",
    "# Read the comments within the method!\n",
    "initTables(debug=False)\n",
    "\n",
    "# 2. iterate throw the dataset\n",
    "primary_diagnosis_only = True\n",
    "diagnosis_threshold_min = 3000\n",
    "textHpo_threshold_min, textHpo_threshold_max = 500, 100000\n",
    "labHpo_threshold_min, labHpo_threshold_max = 1000, 100000\n",
    "textHpo_occurrance_min, labHpo_occurrance_min = 1, 3\n",
    "\n",
    "summaries_text_text, summaries_lab_lab = summarize_intra_textHpo_or_intra_labHpo(primary_diagnosis_only, textHpo_occurrance_min, labHpo_occurrance_min, diagnosis_threshold_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('summaries-intra-textHpo-primary_only.obj', 'wb') as summaries_file:\n",
    "    pickle.dump(summaries_text_text, summaries_file)\n",
    "    \n",
    "with open('summaries-intra-labHpo-primary_only.obj', 'wb') as summaries_file:\n",
    "    pickle.dump(summaries_lab_lab, summaries_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual information between phenotypes of radiology and lab tests regardless of diseases\n",
    "Without considering diseases, we want to determine the mutual information between pairs of phenotypes from radiology reports and lab tests. The algorithm:\n",
    "\n",
    "    * find phenotypes of interest from radiology reports\n",
    "    * find phenotypes of interest from lab tests\n",
    "    * in batches, create a matrix of text phenotype profiles and a matrix of lab phenotype profiles, update summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_query_lab_text(start_index, end_index, textHpo_occurrance_min, labHpo_occurrance_min, textHpo_min, textHpo_max, labHpo_min, labHpo_max):\n",
    "    \n",
    "    textHpo_flat = pd.read_sql_query('''\n",
    "        WITH encounters AS (\n",
    "                SELECT *\n",
    "                FROM JAX_encounterOfInterest\n",
    "                WHERE ROW_ID BETWEEN {} AND {}),\n",
    "            phenotypes AS (\n",
    "                SELECT MAP_TO\n",
    "                FROM JAX_textHpoFrequencyRank\n",
    "                WHERE N BETWEEN {} AND {}\n",
    "            ), \n",
    "            temp AS (\n",
    "                SELECT * \n",
    "                FROM encounters \n",
    "                JOIN phenotypes)\n",
    "\n",
    "            SELECT L.SUBJECT_ID, L.HADM_ID, L.MAP_TO AS PHEN_TEXT, IF(R.dummy IS NULL, 0, 1) AS PHEN_TEXT_VALUE\n",
    "            FROM temp AS L\n",
    "            LEFT JOIN \n",
    "                (SELECT * FROM JAX_textHpoProfile WHERE OCCURRANCE >= {}) AS R\n",
    "            ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.MAP_TO = R.MAP_TO\n",
    "        '''.format(start_index, end_index, textHpo_min, textHpo_max, textHpo_occurrance_min), mydb)\n",
    "    \n",
    "    labHpo_flat = pd.read_sql_query('''\n",
    "        WITH encounters AS (\n",
    "                SELECT *\n",
    "                FROM JAX_encounterOfInterest\n",
    "                WHERE ROW_ID BETWEEN {} AND {}),\n",
    "            phenotypes AS (\n",
    "                SELECT MAP_TO\n",
    "                FROM JAX_labHpoFrequencyRank\n",
    "                WHERE N BETWEEN {} AND {}\n",
    "            ), \n",
    "            temp AS (\n",
    "                SELECT * \n",
    "                FROM encounters \n",
    "                JOIN phenotypes)\n",
    "\n",
    "            SELECT L.SUBJECT_ID, L.HADM_ID, L.MAP_TO AS PHEN_LAB, IF(R.dummy IS NULL, 0, 1) AS PHEN_LAB_VALUE\n",
    "            FROM temp AS L\n",
    "            LEFT JOIN \n",
    "                (SELECT * FROM JAX_labHpoProfile WHERE OCCURRANCE >= {}) AS R\n",
    "            ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID AND L.MAP_TO = R.MAP_TO\n",
    "        '''.format(start_index, end_index, labHpo_min, labHpo_max, labHpo_occurrance_min), mydb)\n",
    "    \n",
    "    return textHpo_flat, labHpo_flat \n",
    "    \n",
    "\n",
    "def summary_textHpo_labHpo(batch_size, textHpo_occurrance_min, labHpo_occurrance_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max):\n",
    "    \n",
    "    textHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_textHpoFrequencyRank WHERE N BETWEEN {} AND {}\".format(textHpo_threshold_min, textHpo_threshold_max), mydb).MAP_TO.values\n",
    "    labHpoOfInterest = pd.read_sql_query(\"SELECT * FROM JAX_labHpoFrequencyRank WHERE N BETWEEN {} AND {}\".format(labHpo_threshold_min, labHpo_threshold_max), mydb).MAP_TO.values\n",
    "    M1 = len(textHpoOfInterest)\n",
    "    M2 = len(labHpoOfInterest)\n",
    "    \n",
    "    summary_rad_lab = mf.SummaryXY(textHpoOfInterest, labHpoOfInterest)\n",
    "    summary_rad_rad = mf.SummaryXY(textHpoOfInterest, textHpoOfInterest)\n",
    "    summary_lab_lab = mf.SummaryXY(labHpoOfInterest, labHpoOfInterest)\n",
    "    \n",
    "    ## find the start and end ROW_ID for patient*encounter\n",
    "    \n",
    "    ADM_ID_START, ADM_ID_END = pd.read_sql_query('SELECT MIN(ROW_ID) AS min, MAX(ROW_ID) AS max FROM JAX_encounterOfInterest', mydb).iloc[0]\n",
    "    batch_N = ADM_ID_END - ADM_ID_START + 1\n",
    "    TOTAL_BATCH = math.ceil(batch_N / batch_size) # total number of batches\n",
    "\n",
    "    print('total batches: ' + str(batch_N))\n",
    "    pbar = tqdm(total=TOTAL_BATCH)\n",
    "    for i in np.arange(TOTAL_BATCH):\n",
    "        start_index = i * batch_size + ADM_ID_START\n",
    "        if i < TOTAL_BATCH - 1:\n",
    "            end_index = start_index + batch_size - 1\n",
    "        else:\n",
    "            end_index = batch_N\n",
    "        actual_batch_size = end_index - start_index + 1\n",
    "        textHpo, labHpo = batch_query_lab_text(start_index, end_index, textHpo_occurrance_min, labHpo_occurrance_min, textHpo_threshold_min, textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max)\n",
    "        textHpo_matrix = textHpo.PHEN_TEXT_VALUE.values.astype(int).reshape([actual_batch_size, M1], order='F')\n",
    "        labHpo_matrix = labHpo.PHEN_LAB_VALUE.values.astype(int).reshape([actual_batch_size, M2], order='F')\n",
    "        summary_rad_lab.add_batch(textHpo_matrix, labHpo_matrix)\n",
    "        summary_rad_rad.add_batch(textHpo_matrix, textHpo_matrix)\n",
    "        summary_lab_lab.add_batch(labHpo_matrix, labHpo_matrix)\n",
    "        pbar.update(1)\n",
    "        \n",
    "    pbar.close()\n",
    "    \n",
    "    return summary_rad_lab, summary_rad_rad, summary_lab_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 169.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total batches: 100\n",
      "(8, 2, 4)\n",
      "(8, 8, 4)\n",
      "(2, 2, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encounterOfInterest(debug=True)\n",
    "indexEncounterOfInterest()\n",
    "diagnosisProfile()\n",
    "rankHpoFromText('', hpo_min_occurrence_per_encounter=1)\n",
    "rankHpoFromLab('', hpo_min_occurrence_per_encounter=3)\n",
    "\n",
    "batch_size = 11\n",
    "textHpo_threshold_min = 45\n",
    "textHpo_threshold_max = 65\n",
    "labHpo_threshold_min = 75\n",
    "labHpo_threshold_max = 85\n",
    "textHpo_occurrance_min = 1\n",
    "labHpo_occurrance_min = 3\n",
    "\n",
    "summary_rad_lab, summary_rad_rad, summary_lab_lab = summary_textHpo_labHpo(batch_size, textHpo_occurrance_min, labHpo_occurrance_min, textHpo_threshold_min,textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max)\n",
    "\n",
    "print(summary_rad_lab.m.shape)\n",
    "print(summary_rad_rad.m.shape)\n",
    "print(summary_lab_lab.m.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/590 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total batches: 58976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 590/590 [32:42<00:00,  3.08s/it]\n"
     ]
    }
   ],
   "source": [
    "encounterOfInterest(debug=False)\n",
    "indexEncounterOfInterest()\n",
    "diagnosisProfile()\n",
    "rankHpoFromText('', hpo_min_occurrence_per_encounter=1)\n",
    "rankHpoFromLab('', hpo_min_occurrence_per_encounter=3)\n",
    "\n",
    "batch_size = 100\n",
    "textHpo_threshold_min = 500\n",
    "textHpo_threshold_max = 100000\n",
    "labHpo_threshold_min = 1000\n",
    "labHpo_threshold_max = 100000\n",
    "textHpo_occurrance_min = 1\n",
    "labHpo_occurrance_min = 3\n",
    "\n",
    "summary_rad_lab, summary_rad_rad, summary_lab_lab = summary_textHpo_labHpo(batch_size, textHpo_occurrance_min, labHpo_occurrance_min, textHpo_threshold_min,textHpo_threshold_max, labHpo_threshold_min, labHpo_threshold_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../data/mf_regardless_of_diseases/summary_textHpo_labHpo.obj', 'wb') as file:\n",
    "    pickle.dump(summary_rad_lab, file)\n",
    "    \n",
    "with open('../../../data/mf_regardless_of_diseases/summary_textHpo_textHpo.obj', 'wb') as file:\n",
    "    pickle.dump(summary_rad_rad, file)\n",
    "    \n",
    "with open('../../../data/mf_regardless_of_diseases/summary_labHpo_labHpo.obj', 'wb') as file:\n",
    "    pickle.dump(summary_lab_lab, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_all=mf.MutualInfoXY(summary_all)\n",
    "textHpo_labels = mf_all.X_names\n",
    "labHpo_labels = mf_all.Y_names\n",
    "M1 = len(mf_all.X_names)\n",
    "M2 = len(mf_all.Y_names)\n",
    "entropy_x, entropy_y = mf_all.entropies().values()\n",
    "mf_all_df = pd.DataFrame(data={'P1': np.repeat(textHpo_labels, M2), 'P2': np.tile(labHpo_labels, [M1]),'entropy_P1': np.repeat(entropy_x, M2), 'entropy_P2': np.tile(entropy_y, [M1]), 'mf_P1_P2': mf_all.mf().flat})\n",
    "mf_all_df.head()\n",
    "mf_all_df.to_csv('mutual_info_textHpo_labHpo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_all_df.head()\n",
    "mf_all_df.sort_values(by='mf_P1_P2', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: move the following section to the machine learning notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature generation for phenotype-based disease prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare phenotypes for machine learning tasks. For specified disease of interest, find the patient info (gender, DOB), find the diagnosis info (case or control, date), and phenotype terms.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encounterOfInterest(debug=False, N=100)\n",
    "indexEncounterOfInterest()\n",
    "diagnosisProfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = pd.read_sql_query('''\n",
    "        SELECT \n",
    "            PATIENTS.SUBJECT_ID, PATIENTS.GENDER, PATIENTS.DOB\n",
    "        FROM \n",
    "            PATIENTS\n",
    "        WHERE \n",
    "            SUBJECT_ID IN (SELECT SUBJECT_ID FROM JAX_encounterOfInterest) \n",
    "    ''', mydb)\n",
    "\n",
    "len(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createDiagnosisTable(diagnosis='038', primary_diagnosis_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_diag_time(diagnosis):\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_first_diag_time')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_first_diag_time\n",
    "        WITH diag_time AS (\n",
    "            SELECT L.*, R.ADMITTIME \n",
    "            FROM JAX_mf_diag AS L\n",
    "            JOIN ADMISSIONS AS R\n",
    "            ON \n",
    "                L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID\n",
    "        ), \n",
    "        overallDiagnosis AS (\n",
    "            SELECT *, IF(SUM(DIAGNOSIS) OVER (PARTITION BY SUBJECT_ID) > 0, 1, 0) AS everDiagnosed\n",
    "            FROM diag_time\n",
    "        )\n",
    "        \n",
    "        SELECT \n",
    "            *, MIN(IF(everDiagnosed = 1, ADMITTIME, NULL) ) OVER (PARTITION BY SUBJECT_ID) AS first_diag, \n",
    "            MAX(IF(everDiagnosed = 0, ADMITTIME, NULL)) OVER (PARTITION BY SUBJECT_ID) AS last_visit_if_not_diagnosed\n",
    "        FROM \n",
    "            overallDiagnosis  \n",
    "    '''.format(diagnosis))\n",
    "\n",
    "first_diag_time('038')\n",
    "pd.read_sql_query('SELECT * FROM JAX_first_diag_time LIMIT 5', mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encountersAfterDiagnosis():\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_encounters_after_diagnosis')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_encounters_after_diagnosis\n",
    "            SELECT *, 1 AS toIgnore\n",
    "            FROM JAX_first_diag_time\n",
    "            WHERE DIAGNOSIS = 1 AND ADMITTIME > first_diag\n",
    "    ''')\n",
    "    cursor.execute('CREATE INDEX JAX_encounters_after_diagnosis_idx01 ON JAX_encounters_after_diagnosis (SUBJECT_ID, HADM_ID)')\n",
    "    \n",
    "encountersAfterDiagnosis() \n",
    "pd.read_sql_query(\"SELECT * FROM JAX_encounters_after_diagnosis LIMIT 5\", mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_vector = pd.read_sql_query('''\n",
    "        SELECT\n",
    "            SUBJECT_ID, IF(SUM(DIAGNOSIS)>0, 1, 0) AS DIAGNOSED, MAX(IF(everDiagnosed = 1, first_diag, last_visit_if_not_diagnosed)) AS LAST_VISIT\n",
    "        FROM\n",
    "            JAX_first_diag_time\n",
    "        GROUP BY SUBJECT_ID\n",
    "    ''', mydb)\n",
    "diagnosis_vector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab_phenotype_before_diagnosis():\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_phen_lab_before_diag')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_phen_lab_before_diag\n",
    "        WITH temp as (\n",
    "            SELECT L.*, W.toIgnore\n",
    "            FROM JAX_LABHPOPROFILE AS L\n",
    "            JOIN JAX_mf_diag AS R ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID\n",
    "            LEFT JOIN JAX_encounters_after_diagnosis W on  L.SUBJECT_ID = W.SUBJECT_ID AND L.HADM_ID = W.HADM_ID\n",
    "            WHERE L.OCCURRANCE >= 1\n",
    "        )\n",
    "        SELECT SUBJECT_ID, MAP_TO, COUNT(*) as N\n",
    "        FROM temp\n",
    "        WHERE toIgnore IS NULL\n",
    "        GROUP BY SUBJECT_ID, MAP_TO\n",
    "    ''')\n",
    "    cursor.execute('CREATE INDEX JAX_phen_lab_before_diag_idx01 ON JAX_phen_lab_before_diag (N)')\n",
    "    \n",
    "\n",
    "def text_phenotype_before_diagnosis():\n",
    "    cursor.execute('DROP TEMPORARY TABLE IF EXISTS JAX_phen_text_before_diag')\n",
    "    cursor.execute('''\n",
    "        CREATE TEMPORARY TABLE JAX_phen_text_before_diag\n",
    "        WITH temp as (\n",
    "            SELECT L.*, W.toIgnore\n",
    "            FROM JAX_TEXTHPOPROFILE AS L\n",
    "            JOIN JAX_mf_diag AS R ON L.SUBJECT_ID = R.SUBJECT_ID AND L.HADM_ID = R.HADM_ID\n",
    "            LEFT JOIN JAX_encounters_after_diagnosis W on  L.SUBJECT_ID = W.SUBJECT_ID AND L.HADM_ID = W.HADM_ID\n",
    "        )\n",
    "        SELECT SUBJECT_ID, MAP_TO, COUNT(*) as N\n",
    "        FROM temp\n",
    "        WHERE toIgnore IS NULL\n",
    "        GROUP BY SUBJECT_ID, MAP_TO\n",
    "    ''')\n",
    "    cursor.execute('CREATE INDEX JAX_phen_text_before_diag_idx01 ON JAX_phen_text_before_diag (N)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lab_phenotype_before_diagnosis()\n",
    "lab_phenotype_vector = pd.read_sql_query('''\n",
    "    SELECT * FROM JAX_phen_lab_before_diag\n",
    "'''.format(1), mydb)\n",
    "lab_phenotype_vector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_phenotype_before_diagnosis()\n",
    "text_phenotype_vector = pd.read_sql_query('''\n",
    "    SELECT * FROM JAX_phen_text_before_diag WHERE N >= {}\n",
    "'''.format(1), mydb)\n",
    "text_phenotype_vector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes = lab_phenotype_vector.merge(text_phenotype_vector, on = ['SUBJECT_ID', 'MAP_TO'], how = 'outer').fillna(value = 0)\n",
    "phenotypes['N'] = phenotypes['N_x'] + phenotypes['N_y']\n",
    "phenotypes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes_matrix = merged.loc[:, ['SUBJECT_ID', 'MAP_TO', 'N']].pivot_table(values='N', index='SUBJECT_ID', columns='MAP_TO', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = patients.merge(diagnosis_vector, on = 'SUBJECT_ID')\n",
    "df['AGE'] = (pd.to_datetime(df.LAST_VISIT, format='%Y-%m-%d %H:%M:%S').dt.year - pd.to_datetime(df.DOB, format='%Y-%m-%d %H:%M:%S').dt.year)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, ['SUBJECT_ID', 'GENDER', 'AGE', 'DIAGNOSED']].merge(phenotypes_matrix, on = 'SUBJECT_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ml_df_038_primary_only.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = patients.merge(m, on = 'SUBJECT_ID', how = 'left').sort_values(by = 'SUBJECT_ID').set_index('SUBJECT_ID')\n",
    "X = X.drop('DOB', axis=1).fillna(value=0)\n",
    "X.head(n = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diagnosis_vector.sort_values(by = 'SUBJECT_ID').set_index('SUBJECT_ID')\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = X.dtypes == object\n",
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = pd.get_dummies(X.GENDER)\n",
    "X = X.drop('GENDER', axis=1).merge(sex, left_index=True, right_index=True).drop('F', axis=1)\n",
    "X.M = X.M.astype(float)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_test.IsDiagnosed)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "mydb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
