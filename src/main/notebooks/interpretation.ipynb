{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPRECATED -> see analysis_pipeline.py\n",
    "# Phenotype Synergy Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook contains code to interprete results from the synergy score analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "mf_module_path = os.path.abspath(os.path.join('../python'))\n",
    "if mf_module_path not in sys.path:\n",
    "    sys.path.append(mf_module_path)\n",
    "import mf\n",
    "import mf_random\n",
    "from ontology import Ontology\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use hp.obo from online or your local file system\n",
    "#hpo = Ontology('http://purl.obolibrary.org/obo/hp.obo')\n",
    "hpo = Ontology('/Users/zhangx/git/human-phenotype-ontology/hp.obo')\n",
    "hpo_term_map = hpo.term_id_2_label_map()\n",
    "\n",
    "# base dir: path to the MIMIC_HPO repo on your machine\n",
    "base_dir = '../../..'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual information without considering diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section analyzes the mutual information between phenotype pairs (labHpo-labHpo, textHpo-labHpo, textHpo-textHpo) in regardless of diagnosis. \n",
    "\n",
    "Note that the same information is also produced as a side product when we calculate mutual information in respect to a disease. Because we run simulations in the latter case, we additionally get their p values for the observed value.\n",
    "\n",
    "Processing steps: \n",
    "For each type of summary statistics, we can map them into a MutualInfoXY instance. From there, we can get the mutual information matrix (or dataframe), and then do necessary filtering. In the last, we save the dataframe to a file.\n",
    "\n",
    "**Filter 1:**\n",
    "\n",
    "If P1 and P2 are both from labHpo or textHpo, then remove rows where P1 is identical to P2\n",
    "\n",
    "**Filter 2:**\n",
    "\n",
    "If P1 and P2 are both from labHpo or textHpo, then a row for (a, b) is identical to (b, a). So one row is removed. \n",
    "\n",
    "**Filter 3:**\n",
    "\n",
    "Because we automatically added ancestors terms if a child term is observed, P1 and P2 are expected to have high mutual information if they have dependency in HPO hierarchy. Such pairs are removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mf_dataframe_regardless_of_diagnosis(p1_source, p2_source, hpo_term_map):\n",
    "    summary_file_name = 'summary_{}_{}.obj'.format(p1_source, p2_source)\n",
    "    summary_file_path = os.path.join(base_dir, 'data', 'mf_regardless_of_diseases', summary_file_name)\n",
    "    with open(summary_file_path, 'rb') as f:\n",
    "        summary_statistics = pickle.load(f)\n",
    "    \n",
    "    # convert to a MutualInfoXY object from summary statistics\n",
    "    mf_XY = mf.MutualInfoXY(summary_statistics)\n",
    "    \n",
    "    # get a dataframe\n",
    "    df_mf_XY = mf_XY.mf_labeled()\n",
    "    \n",
    "    # label termid with names\n",
    "    df_mf_XY['P1_label'] = np.array([hpo_term_map.get(termid) for termid in df_mf_XY.P1])\n",
    "    df_mf_XY['P2_label'] = np.array([hpo_term_map.get(termid) for termid in df_mf_XY.P2])\n",
    "    \n",
    "    return df_mf_XY\n",
    "\n",
    "def filter_mf_dataframe_regardless_of_diagnosis(df_mf_XY, hpo,\n",
    "                                         remove_pairs_with_same_terms, \n",
    "                                         remove_reflective_pairs, \n",
    "                                         remove_pairs_with_dependency,\n",
    "                                        sort_by='mf'):\n",
    "    # remove pairs where P1, P2 are the same\n",
    "    if remove_pairs_with_same_terms:\n",
    "        df_mf_XY = df_mf_XY.loc[df_mf_XY.P1 != df_mf_XY.P2, :].reset_index(drop=True)\n",
    "    \n",
    "    # remove reflective pairs: (a, b) and (b, a) are considered reflective pairs\n",
    "    # the method is to use string comparison: always require P1 <= P2\n",
    "    if remove_reflective_pairs:\n",
    "        df_mf_XY = df_mf_XY.loc[df_mf_XY.P1 <= df_mf_XY.P2, :].reset_index(drop=True)\n",
    "    \n",
    "    # remove pairs with dependency\n",
    "    has_dependency = np.repeat(False, len(df_mf_XY))\n",
    "    for i in np.arange(len(df_mf_XY)):\n",
    "        x = df_mf_XY.P1[i]\n",
    "        y = df_mf_XY.P2[i]\n",
    "        has_dependency[i] = x != y and (hpo.exists_path(x, y) or hpo.exists_path(y, x))\n",
    "        \n",
    "    if remove_pairs_with_dependency:\n",
    "        # when does two terms in a pair has dependency: different, but there is path from one to another\n",
    "        df_mf_XY = df_mf_XY.loc[np.logical_not(has_dependency), :]\n",
    "        \n",
    "    df_mf_XY = df_mf_XY.sort_values(by=sort_by, ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return df_mf_XY\n",
    "\n",
    "def save_mf_dataframe_regardless_of_diagnosis(df_mf_XY, p1_source, p2_source):\n",
    "    # save to csv file\n",
    "    output_file_name = 'mf_{}_{}.csv'.format(p1_source, p2_source)\n",
    "    output_file_parent_dir = os.path.join(base_dir, 'data', 'mf_regardless_of_diseases')\n",
    "    if not os.path.exists(output_file_parent_dir):\n",
    "        os.mkdir(output_file_parent_dir)\n",
    "    output_file_path = os.path.join(base_dir, 'data', 'mf_regardless_of_diseases', output_file_name)\n",
    "    df_mf_XY.to_csv(output_file_path)\n",
    "    \n",
    "def process_mf_regardless_of_diagnosis(p1_source, p2_source, hpo, \n",
    "                            remove_pairs_with_same_terms, remove_reflective_pairs, remove_pairs_with_dependency):\n",
    "    # step 1: make a labeled dataframe\n",
    "    hpo_term_map = hpo.term_id_2_label_map()\n",
    "    df_mf_XY = mf_dataframe_regardless_of_diagnosis(p1_source, p2_source, hpo_term_map)\n",
    "    # step 2: filter unnecessary rows\n",
    "    df_mf_XY = filter_mf_dataframe_regardless_of_diagnosis(df_mf_XY, hpo, remove_pairs_with_same_terms, \n",
    "                                                           remove_reflective_pairs, remove_pairs_with_dependency)\n",
    "    # step 3: save to csv\n",
    "    save_mf_dataframe_regardless_of_diagnosis(df_mf_XY, p1_source, p2_source)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### textHpo-labHpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_mf_regardless_of_diagnosis('textHpo', 'labHpo', hpo, \n",
    "                                   remove_pairs_with_same_terms=False, \n",
    "                                   remove_reflective_pairs=False, \n",
    "                                   remove_pairs_with_dependency=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### textHpo-textHpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_mf_regardless_of_diagnosis('textHpo', 'textHpo', hpo, \n",
    "                                   remove_pairs_with_same_terms=True, \n",
    "                                   remove_reflective_pairs=True, \n",
    "                                   remove_pairs_with_dependency=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### labHpo-labHpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_mf_regardless_of_diagnosis('labHpo', 'labHpo', hpo, \n",
    "                                   remove_pairs_with_same_terms=True, \n",
    "                                   remove_reflective_pairs=True, \n",
    "                                   remove_pairs_with_dependency=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Mutual information between phenotypes in respect to diagnoses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each admission, patients could receive multiple diagnosis codes. One of them is designated as \"primary\" (in MIMIC, it has a rank of 1) and others secondary (rank 2, 3...). Therefore, the analysis was run under two scenerios: \n",
    "1. Only primary diagnosis is considered. \n",
    "2. All diagnoses are considered equally. \n",
    "\n",
    "Under the first scenerio, a patient is considered to be a case only if the corresponding billing code is listed as \"primary\". While in the second case, a patient is considered to be a case when the corresponding billing code is listed as primary or secondary.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_statistics_to_mutualInfoXY_z(p1_source, p2_source, primary_only, diag_code):\n",
    "    if primary_only:\n",
    "        diag_dir = \"primary_only\"\n",
    "    else:\n",
    "        diag_dir = \"primary_and_secondary\"\n",
    "        \n",
    "    summaries_file_name = 'summaries_diagnosis_{}_{}.obj'.format(p1_source, p2_source)\n",
    "    summaries_file_path = os.path.join(base_dir, 'data', 'mf_regarding_diseases', diag_dir, summaries_file_name)\n",
    "    \n",
    "    with open(summaries_file_path, 'rb') as f:\n",
    "        summaries = pickle.load(f)\n",
    "    \n",
    "    summary_statistics_for_diag_code = summaries.get(diag_code)\n",
    "    mutualInfoXYz = mf.MutualInfoXYz(summary_statistics_for_diag_code)\n",
    "    \n",
    "    return mutualInfoXYz\n",
    "\n",
    "def mf_dataframes_regarding_diagnosis(mutualInfoXYz, **p_values):\n",
    "    \"\"\"\n",
    "    @param p_values: output from simulation\n",
    "    \"\"\"\n",
    "    assert isinstance(mutualInfoXYz, mf.MutualInfoXYz)\n",
    "    # unpack p values\n",
    "    p_mf_Xz = p_values.get('mf_Xz')\n",
    "    p_mf_Yz = p_values.get('mf_Yz')\n",
    "    p_mf_XY_z = p_values.get('mf_XY_z')\n",
    "    p_mf_XY_given_z = p_values.get('mf_XY_given_z')\n",
    "    p_synergy = p_values.get('synergy')\n",
    "    p_mf_XY_omit_z = p_values.get('mf_XY_omit_z')\n",
    "    \n",
    "    X_labels, Y_labels = mutualInfoXYz.vars_labels.values()\n",
    "    M1 = len(X_labels)\n",
    "    M2 = len(Y_labels)\n",
    "\n",
    "    mf_Xz = mutualInfoXYz.mutual_info_Xz()\n",
    "    mf_Yz = mutualInfoXYz.mutual_info_Yz()\n",
    "\n",
    "    # mutual information between single phenotypes and diagnosis\n",
    "    df_mf_Xz = pd.DataFrame(data={'X': X_labels, 'mf_Xz': mf_Xz})\n",
    "    df_mf_Yz = pd.DataFrame(data={'Y': Y_labels, 'mf_Yz': mf_Yz})\n",
    "    # add p values\n",
    "    df_mf_Xz['p_mf_Xz'] = p_mf_Xz if p_mf_Xz is not None else np.repeat(-1, M1)\n",
    "    df_mf_Yz['p_mf_Yz'] = p_mf_Yz if p_mf_Yz is not None else np.repeat(-1, M2)\n",
    "    \n",
    "    # joint and conditional mutual information, and synergy\n",
    "    mf_XY_z = mutualInfoXYz.mutual_info_XY_z()\n",
    "    mf_XY_given_z = mutualInfoXYz.mutual_info_XY_given_z()\n",
    "    mf_synergy = mutualInfoXYz.synergy_XY2z()\n",
    "    \n",
    "    # mutual information between phenotypes without considering diagnosis\n",
    "    mf_XY_omit_z = mutualInfoXYz.mutual_info_XY_omit_z()\n",
    "    \n",
    "    # mutual information between phenotype pairs and diagnosis\n",
    "    df_mf_XY_z = pd.DataFrame()\n",
    "    df_mf_XY_z['X'] = np.repeat(X_labels, M2)\n",
    "    df_mf_XY_z['Y'] = np.tile(Y_labels, [M1])\n",
    "    df_mf_XY_z['mf_Xz'] = np.repeat(mf_Xz, M2)\n",
    "    df_mf_XY_z['mf_Yz'] = np.tile(mf_Yz, [M1])\n",
    "    df_mf_XY_z['mf_XY_z'] = mf_XY_z.flat\n",
    "    df_mf_XY_z['synergy'] = mf_synergy.flat   # synergy = mf_XY_z - mf_Xz - mf_Yz\n",
    "    \n",
    "    # mutual information between phenotypes after omiting diagnosis or conditioned on diagnosis\n",
    "    df_mf_XY_z['mf_XY_omit_z'] = mf_XY_omit_z.flat\n",
    "    df_mf_XY_z['mf_XY_given_z'] = mf_XY_given_z.flat\n",
    "    \n",
    "    # ratio of conditional mutual information / mutual information without considering diagnosis\n",
    "    # synergy is also equal to mf_XY_given_z - mf_XY_omit_z\n",
    "    # here we use ratio, which can be considered as an alternative of the above definition of synergy\n",
    "    df_mf_XY_z['mf_ratio'] = df_mf_XY_z['mf_XY_given_z'] / df_mf_XY_z['mf_XY_omit_z']\n",
    "    \n",
    "    # add p values; otherwise, assign -1\n",
    "    df_mf_XY_z['p_mf_Xz'] = np.repeat(p_mf_Xz, M2) if p_mf_Xz is not None else np.repeat(-1, M1*M2)\n",
    "    df_mf_XY_z['p_mf_Yz'] = np.tile(p_mf_Yz, [M1]) if p_mf_Yz is not None else np.repeat(-1, M1*M2)\n",
    "    df_mf_XY_z['p_mf_XY_z'] = p_mf_XY_z.flat if p_mf_XY_z is not None else np.repeat(-1, M1*M2)\n",
    "    df_mf_XY_z['p_synergy'] = p_synergy.flat if p_synergy is not None else np.repeat(-1, M1*M2)\n",
    "    df_mf_XY_z['p_mf_XY_omit_z'] = p_mf_XY_omit_z.flat if p_mf_XY_omit_z is not None else np.repeat(-1, M1*M2)\n",
    "    df_mf_XY_z['p_mf_XY_given_z'] = p_mf_XY_given_z.flat if p_mf_XY_given_z is not None else np.repeat(-1, M1*M2)\n",
    "    \n",
    "    \n",
    "    # add raw counts: 8 additional columns\n",
    "    joint_dist_keys = ['+++', '++-', '+-+', '+--', '-++', '-+-', '--+', '---']\n",
    "    joint_dist_values = mutualInfoXYz.m2.reshape([-1, 8]).astype(int)\n",
    "    raw_counts = {joint_dist_keys[i]: joint_dist_values[:,i] for i in np.arange(8)}\n",
    "    df_mf_XY_z = df_mf_XY_z.assign(**raw_counts)\n",
    "    df_mf_XY_z['sum'] = np.sum(joint_dist_values, axis=-1) # it's a constant for all rows\n",
    "    \n",
    "    return df_mf_Xz, df_mf_Yz, df_mf_XY_z\n",
    "\n",
    "\n",
    "def rename_mf_dataframes(df_mf_Xz, df_mf_Yz, df_mf_XY_z):\n",
    "    # map column names to more meaningful name for this context\n",
    "    name_dict = {\n",
    "        'X': 'P1', \n",
    "        'Y': 'P2', \n",
    "        'mf_Xz': 'mf_P1_diag',\n",
    "        'mf_Yz': 'mf_P2_diag',\n",
    "        'mf_XY_z': 'mf_P1P2_diag',\n",
    "        'mf_XY_given_z': 'mf_P1P2_given_diag',\n",
    "        'mf_XY_omit_z': 'mf_P1P2_omit_diag',\n",
    "        'p_mf_XY_z': 'p_mf_P1P2_diag',\n",
    "        'p_mf_XY_given_z': 'p_mf_P1P2_given_diag',\n",
    "        'p_mf_XY_omit_z': 'p_mf_P1P2_omit_diag',\n",
    "        'mf_Xz': 'mf_P1_diag', \n",
    "        'mf_Yz': 'mf_P2_diag',  \n",
    "        'p_mf_Xz': 'p_mf_P1_diag', \n",
    "        'p_mf_Yz': 'p_mf_P2_diag'   \n",
    "    }\n",
    "\n",
    "    df_mf_Xz = df_mf_Xz.rename(columns=name_dict, errors='ignore') \n",
    "    df_mf_Yz = df_mf_Yz.rename(columns=name_dict, errors='ignore') \n",
    "    df_mf_XY_z = df_mf_XY_z.rename(columns=name_dict, errors='ignore')\n",
    "    \n",
    "    return df_mf_Xz, df_mf_Yz, df_mf_XY_z\n",
    "\n",
    "\n",
    "def filter_mf_dataframe_regarding_diagnosis(df_mf_XY_z, hpo, \n",
    "                                            remove_pairs_with_same_terms, \n",
    "                                            remove_reflective_pairs, \n",
    "                                            remove_pairs_with_dependency,\n",
    "                                           sort_by='synergy'):\n",
    "    # use the same method as the one defined above, except to sort by a different column\n",
    "    return filter_mf_dataframe_regardless_of_diagnosis(df_mf_XY_z, hpo,\n",
    "                                         remove_pairs_with_same_terms, \n",
    "                                         remove_reflective_pairs, \n",
    "                                         remove_pairs_with_dependency,\n",
    "                                         sort_by)\n",
    "\n",
    "def entropy(case, control):\n",
    "    total = case + control \n",
    "    h = -(case / total * np.log2(case/total) + control/total * np.log2(control/total))\n",
    "    return h\n",
    "    \n",
    "\n",
    "def load_p_values(p1_source, p2_source, diag_code, primary_only):\n",
    "    if primary_only:\n",
    "        p_values_file_name = 'p_value_{}_{}_{}_{}.obj'.format(p1_source, p2_source, diag_code, 'primary_only')\n",
    "    else:\n",
    "        p_values_file_name = 'p_value_{}_{}_{}_{}.obj'.format(p1_source, p2_source, diag_code, 'primary_and_secondary')\n",
    "    \n",
    "    p_values_file_path = os.path.join(base_dir, 'data', 'mf_regarding_diseases', 'primary_only', diag_code, p_values_file_name)\n",
    "    with open(p_values_file_path, 'rb') as f:\n",
    "        p = pickle.load(f)\n",
    "    return p\n",
    "\n",
    "convert_to_percent = np.vectorize(lambda x: ' {:.2f}%'.format(x * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirs_if_necessary(primary_only, diag_code):\n",
    "    \"\"\"\n",
    "    Create necessary directories for the diagnosis type and diagnosis code. \n",
    "    There should be the following directories in the repo:\n",
    "    data -> mf_regarding_diseases -> primary_only or primary_and_secondary -> diagnosis_code\n",
    "    \"\"\"\n",
    "    # create a data folder under the repo\n",
    "    data_dir = os.path.join(base_dir, 'data')\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.path.mkdir(data_dir)\n",
    "    \n",
    "    # create parent dir for all outputs related to mutual information in regarding to a disease\n",
    "    mf_regarding_disease_dir = os.path.join(data_dir, 'mf_regarding_diseases')\n",
    "    if not os.path.exists(mf_regarding_disease_dir):\n",
    "        os.mkdir(mf_regarding_disease_dir)\n",
    "        \n",
    "    # create dir for the diagnosis type (primary_only or primary_and_secondary)\n",
    "    if primary_only:\n",
    "        diag_type = 'primary_only'\n",
    "    else:\n",
    "        diag_type = 'primary_and_secondary'\n",
    "    diag_type_dir = os.path.join(mf_regarding_disease_dir, diag_type)\n",
    "    if not os.path.exists(diag_type_dir):\n",
    "        os.mkdir(diag_type_dir)\n",
    "    \n",
    "    # create dir for the disease\n",
    "    diag_dir = os.path.join(diag_type_dir, diag_code)\n",
    "    if not os.path.exists(diag_dir):\n",
    "        os.mkdir(diag_dir)\n",
    "        \n",
    "    # create dir for cytoscape data\n",
    "    cytoscape_dir = os.path.join(diag_dir, 'cytoscape')\n",
    "    if not os.path.exists(cytoscape_dir):\n",
    "        os.mkdir(cytoscape_dir)\n",
    "    \n",
    "\n",
    "def process_mf_df_regarding_diseases(p1_source, p2_source, primary_only, diag_code, hpo, \n",
    "                                     remove_pairs_with_same_terms,\n",
    "                                     remove_reflective_pairs, \n",
    "                                     remove_pairs_with_dependency,\n",
    "                                     sort_by='synergy',\n",
    "                                    percentile_for_cytoscape=0.01):\n",
    "    # calculate mutual information from summary statistics \n",
    "    mutualInfoXYz = summary_statistics_to_mutualInfoXY_z(p1_source, p2_source, primary_only, diag_code)\n",
    "    # load p values (calculated from simulation on Helix)\n",
    "    p_values = load_p_values(p1_source, p2_source, diag_code, primary_only)\n",
    "    # create dataframes\n",
    "    df_mf_Xz, df_mf_Yz, df_mf_XY_z = mf_dataframes_regarding_diagnosis(mutualInfoXYz, **p_values)\n",
    "    # rename columns according to this medical context \n",
    "    df_mf_Xz, df_mf_Yz, df_mf_XY_z = rename_mf_dataframes(df_mf_Xz, df_mf_Yz, df_mf_XY_z)\n",
    "    # label HPO term ids with their names\n",
    "    df_mf_Xz['P1_label'] = [hpo_term_map.get(termid) for termid in df_mf_Xz.P1]\n",
    "    df_mf_Yz['P2_label'] = [hpo_term_map.get(termid) for termid in df_mf_Yz.P2]\n",
    "    df_mf_XY_z['P1_label'] = [hpo_term_map.get(termid) for termid in df_mf_XY_z.P1]\n",
    "    df_mf_XY_z['P2_label'] = [hpo_term_map.get(termid) for termid in df_mf_XY_z.P2]\n",
    "    # filter synergy dataframe\n",
    "    df_mf_XY_z = filter_mf_dataframe_regarding_diagnosis(df_mf_XY_z, hpo, \n",
    "                                                               remove_pairs_with_same_terms, \n",
    "                                                               remove_reflective_pairs, \n",
    "                                                               remove_pairs_with_dependency,\n",
    "                                                               sort_by)\n",
    "    # sort by desired columns\n",
    "    df_mf_Xz = df_mf_Xz.sort_values(by='mf_P1_diag', ascending=False).reset_index(drop=True)\n",
    "    df_mf_Yz = df_mf_Yz.sort_values(by='mf_P2_diag', ascending=False).reset_index(drop=True)\n",
    "    df_mf_XY_z = df_mf_XY_z.sort_values(by=sort_by, ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # output to csv file\n",
    "    # make sure the parent folders all exists\n",
    "    create_dirs_if_necessary(primary_only, diag_code)\n",
    "    # just save df_mf_XY_z_filtered as it contains data in df_mf_Xz and df_mf_Yz\n",
    "    csv_file_name = 'df_synergy_{}_{}_{}.csv'.format(p1_source, p2_source, diag_code)\n",
    "    if primary_only:\n",
    "        diag_dir = 'primary_only'\n",
    "    else:\n",
    "        diag_dir = 'primary_and_secondary'    \n",
    "    csv_parent_dir = os.path.join(base_dir, 'data', 'mf_regarding_diseases', diag_dir, diag_code)\n",
    "    csv_file_path = os.path.join(csv_parent_dir, csv_file_name)\n",
    "    \n",
    "    df_mf_XY_z.to_csv(csv_file_path)\n",
    "    \n",
    "    # output cytoscape files\n",
    "    # Note: only show a small fraction for cytoscape rendering\n",
    "    percentile = percentile_for_cytoscape\n",
    "    n = math.floor(len(df_mf_XY_z) * percentile)\n",
    "\n",
    "    df_4_cytoscape = df_mf_XY_z \\\n",
    "        .assign(P1 = lambda x: 'Rad_' + x['P1']) \\\n",
    "        .assign(P2 = lambda x: 'Lab_' + x['P2']) \\\n",
    "        .head(n = n)\n",
    "\n",
    "    cytoscape_dir = os.path.join(base_dir, 'data', 'mf_regarding_diseases', diag_dir, diag_code, 'cytoscape')\n",
    "    # edges\n",
    "    edges_path = os.path.join(cytoscape_dir, 'edges_{}_{}_{}.csv'.format(p1_source, p2_source, diag_code))\n",
    "    df_4_cytoscape.loc[:, ['P1', 'P2', 'synergy', 'p_synergy']].to_csv(edges_path)\n",
    "\n",
    "    # nodes\n",
    "    nodes = pd.DataFrame(data={'term_id': np.concatenate([df_4_cytoscape.P1, df_4_cytoscape.P2]), \n",
    "                               'term_label': np.concatenate([df_4_cytoscape.P1_label, df_4_cytoscape.P2_label]),\n",
    "                              'type': np.repeat(['Rad', 'Lab'], len(df_4_cytoscape))}).drop_duplicates()\n",
    "    nodes_path = os.path.join(cytoscape_dir, 'nodes_{}_{}_{}.csv'.format(p1_source, p2_source, diag_code))\n",
    "    nodes.to_csv(nodes_path)\n",
    "    \n",
    "    # return this one for html rendering\n",
    "    return csv_parent_dir, csv_file_path\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_code='038'\n",
    "primary_only=True\n",
    "\n",
    "# for any disease, calculate their synergy, and output a CSV\n",
    "p1_source='textHpo'\n",
    "p2_source='labHpo'\n",
    "remove_pairs_with_same_terms=False\n",
    "remove_reflective_pairs=False\n",
    "remove_pairs_with_dependency=True\n",
    "\n",
    "csv_dir, csv_textHpo_labHpo_path = process_mf_df_regarding_diseases(p1_source, p2_source, primary_only, diag_code, hpo, \n",
    "                                     remove_pairs_with_same_terms,\n",
    "                                     remove_reflective_pairs, \n",
    "                                     remove_pairs_with_dependency,\n",
    "                                     sort_by='synergy',\n",
    "                                percentile_for_cytoscape=0.01)\n",
    "\n",
    "p1_source='labHpo'\n",
    "p2_source='labHpo'\n",
    "remove_pairs_with_same_terms=True\n",
    "remove_reflective_pairs=True\n",
    "remove_pairs_with_dependency=True\n",
    "\n",
    "_, csv_labHpo_labHpo_path = process_mf_df_regarding_diseases(p1_source, p2_source, primary_only, diag_code, hpo, \n",
    "                                     remove_pairs_with_same_terms,\n",
    "                                     remove_reflective_pairs, \n",
    "                                     remove_pairs_with_dependency,\n",
    "                                     sort_by='synergy',\n",
    "                                percentile_for_cytoscape=0.01)\n",
    "\n",
    "\n",
    "p1_source='textHpo'\n",
    "p2_source='textHpo'\n",
    "remove_pairs_with_same_terms=True\n",
    "remove_reflective_pairs=True\n",
    "remove_pairs_with_dependency=True\n",
    "\n",
    "_, csv_labHpo_labHpo_path = process_mf_df_regarding_diseases(p1_source, p2_source, primary_only, diag_code, hpo, \n",
    "                                     remove_pairs_with_same_terms,\n",
    "                                     remove_reflective_pairs, \n",
    "                                     remove_pairs_with_dependency,\n",
    "                                     sort_by='synergy',\n",
    "                                percentile_for_cytoscape=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call displaySynergy.jar to render html file\n",
    "\n",
    "Note: maven install displaySynergy on your machine first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return 0 for inputfile: ../../../data/mf_regarding_diseases/primary_only/038/df_synergy_textHpo_labHpo_038.csv\n",
      "return 0 for inputfile: ../../../data/mf_regarding_diseases/primary_only/038/df_synergy_textHpo_textHpo_038.csv\n",
      "return 0 for inputfile: ../../../data/mf_regarding_diseases/primary_only/038/df_synergy_textHpo_textHpo_038.csv\n"
     ]
    }
   ],
   "source": [
    "display_jar_path = '/Users/zhangx/git/displaySynergy/target/displaySynergy-0.0.3.jar'\n",
    "input_files = [csv_textHpo_labHpo_path, csv_labHpo_labHpo_path, csv_labHpo_labHpo_path]\n",
    "for input_file in input_files:\n",
    "    shell_command = 'java -jar {} renderSynergyHtml -i {} -o {}'.format(display_jar_path, input_file, csv_dir)\n",
    "    returncode = os.system(shell_command)\n",
    "    print('return {} for inputfile: {}'.format(returncode, input_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  .   ____          _            __ _ _\n",
      " /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\n",
      "( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\n",
      " \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\n",
      "  '  |____| .__|_| |_|_| |_\\__, | / / / /\n",
      " =========|_|==============|___/=/_/_/_/\n",
      "\u001b[32m :: Spring Boot :: \u001b[39m      \u001b[2m (v2.1.3.RELEASE)\u001b[0;39m\n",
      "\n",
      "\u001b[2m2019-12-20 13:39:03.800\u001b[0;39m \u001b[32m INFO\u001b[0;39m \u001b[35m9827\u001b[0;39m \u001b[2m---\u001b[0;39m \u001b[2m[           main]\u001b[0;39m \u001b[36morg.jax.displaysynergy.Main             \u001b[0;39m \u001b[2m:\u001b[0;39m Starting Main v0.0.3 on MLG-JGM218.local with PID 9827 (/Users/zhangx/git/displaySynergy/target/displaySynergy-0.0.3.jar started by zhangx in /Users/zhangx/git/MIMIC_HPO/src/main/notebooks)\n",
      "\u001b[2m2019-12-20 13:39:03.803\u001b[0;39m \u001b[32m INFO\u001b[0;39m \u001b[35m9827\u001b[0;39m \u001b[2m---\u001b[0;39m \u001b[2m[           main]\u001b[0;39m \u001b[36morg.jax.displaysynergy.Main             \u001b[0;39m \u001b[2m:\u001b[0;39m No active profile set, falling back to default profiles: default\n",
      "\u001b[2m2019-12-20 13:39:04.480\u001b[0;39m \u001b[32m INFO\u001b[0;39m \u001b[35m9827\u001b[0;39m \u001b[2m---\u001b[0;39m \u001b[2m[           main]\u001b[0;39m \u001b[36morg.jax.displaysynergy.Main             \u001b[0;39m \u001b[2m:\u001b[0;39m Started Main in 1.274 seconds (JVM running for 1.754)\n",
      "\u001b[2m2019-12-20 13:39:04.481\u001b[0;39m \u001b[32m INFO\u001b[0;39m \u001b[35m9827\u001b[0;39m \u001b[2m---\u001b[0;39m \u001b[2m[           main]\u001b[0;39m \u001b[36morg.jax.displaysynergy.Main             \u001b[0;39m \u001b[2m:\u001b[0;39m EXECUTING : command line runner\n",
      "Starting command renderSynergyHtml\n",
      "output html file\n",
      "input path: /Users/zhangx/git/MIMIC_HPO/data/mf_regarding_diseases/primary_only/038/df_synergy_labHpo_labHpo_038.csv\n",
      "output dir: /Users/zhangx/Desktop\n",
      "output file path: /Users/zhangx/Desktop/df_synergy_labHpo_labHpo_038.html\n"
     ]
    }
   ],
   "source": [
    "!java -jar /Users/zhangx/git/displaySynergy/target/displaySynergy-0.0.3.jar renderSynergyHtml -i /Users/zhangx/git/MIMIC_HPO/data/mf_regarding_diseases/primary_only/038/df_synergy_labHpo_labHpo_038.csv -o ~/Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
