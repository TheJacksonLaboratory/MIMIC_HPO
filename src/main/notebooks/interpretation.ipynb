{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phenotype Synergy Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook contains code to interprete results from the synergy score analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "mf_module_path = os.path.abspath(os.path.join('../python'))\n",
    "if mf_module_path not in sys.path:\n",
    "    sys.path.append(mf_module_path)\n",
    "import mf\n",
    "import mf_random\n",
    "from ontology import Ontology\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use hp.obo from online or your local file system\n",
    "#hpo = Ontology('http://purl.obolibrary.org/obo/hp.obo')\n",
    "hpo = Ontology('/Users/zhangx/git/human-phenotype-ontology/hp.obo')\n",
    "hpo_term_map = hpo.term_id_2_label_map()\n",
    "\n",
    "# base dir: path to the MIMIC_HPO repo on your machine\n",
    "base_dir = '../../..'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual information without considering diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section analyzes the mutual information between phenotype pairs (labHpo-labHpo, textHpo-labHpo, textHpo-textHpo) in regardless of diagnosis. \n",
    "\n",
    "Note that the same information is also produced as a side product when we calculate mutual information in respect to a disease. Because we run simulations in the latter case, we additionally get their p values for the observed value.\n",
    "\n",
    "Processing steps: \n",
    "For each type of summary statistics, we can map them into a MutualInfoXY instance. From there, we can get the mutual information matrix (or dataframe), and then do necessary filtering. In the last, we save the dataframe to a file.\n",
    "\n",
    "**Filter 1:**\n",
    "\n",
    "If P1 and P2 are both from labHpo or textHpo, then remove rows where P1 is identical to P2\n",
    "\n",
    "**Filter 2:**\n",
    "\n",
    "If P1 and P2 are both from labHpo or textHpo, then a row for (a, b) is identical to (b, a). So one row is removed. \n",
    "\n",
    "**Filter 3:**\n",
    "\n",
    "Because we automatically added ancestors terms if a child term is observed, P1 and P2 are expected to have high mutual information if they have dependency in HPO hierarchy. Such pairs are removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mf_dataframe_regardless_of_diagnosis(p1_source, p2_source, hpo_term_map):\n",
    "    summary_file_name = 'summary_{}_{}.obj'.format(p1_source, p2_source)\n",
    "    summary_file_path = os.path.join(base_dir, 'data', 'mf_regardless_of_diseases', summary_file_name)\n",
    "    with open(summary_file_path, 'rb') as f:\n",
    "        summary_statistics = pickle.load(f)\n",
    "    \n",
    "    # convert to a MutualInfoXY object from summary statistics\n",
    "    mf_XY = mf.MutualInfoXY(summary_statistics)\n",
    "    \n",
    "    # get a dataframe\n",
    "    df_mf_XY = mf_XY.mf_labeled()\n",
    "    \n",
    "    # label termid with names\n",
    "    df_mf_XY['P1_label'] = np.array([hpo_term_map.get(termid) for termid in df_mf_XY.P1])\n",
    "    df_mf_XY['P2_label'] = np.array([hpo_term_map.get(termid) for termid in df_mf_XY.P2])\n",
    "    \n",
    "    return df_mf_XY\n",
    "\n",
    "def filter_mf_dataframe_regardless_of_diagnosis(df_mf_XY, hpo,\n",
    "                                         remove_pairs_with_same_terms, \n",
    "                                         remove_reflective_pairs, \n",
    "                                         remove_pairs_with_dependency,\n",
    "                                        sort_by='mf'):\n",
    "    # remove pairs where P1, P2 are the same\n",
    "    if remove_pairs_with_same_terms:\n",
    "        df_mf_XY = df_mf_XY.loc[df_mf_XY.P1 != df_mf_XY.P2, :].reset_index(drop=True)\n",
    "    \n",
    "    # remove reflective pairs: (a, b) and (b, a) are considered reflective pairs\n",
    "    # the method is to use string comparison: always require P1 <= P2\n",
    "    if remove_reflective_pairs:\n",
    "        df_mf_XY = df_mf_XY.loc[df_mf_XY.P1 <= df_mf_XY.P2, :].reset_index(drop=True)\n",
    "    \n",
    "    # remove pairs with dependency\n",
    "    has_dependency = np.repeat(False, len(df_mf_XY))\n",
    "    for i in np.arange(len(df_mf_XY)):\n",
    "        x = df_mf_XY.P1[i]\n",
    "        y = df_mf_XY.P2[i]\n",
    "        has_dependency[i] = x != y and (hpo.exists_path(x, y) or hpo.exists_path(y, x))\n",
    "        \n",
    "    if remove_pairs_with_dependency:\n",
    "        # when does two terms in a pair has dependency: different, but there is path from one to another\n",
    "        df_mf_XY = df_mf_XY.loc[np.logical_not(has_dependency), :]\n",
    "        \n",
    "    df_mf_XY = df_mf_XY.sort_values(by=sort_by, ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return df_mf_XY\n",
    "\n",
    "def save_mf_dataframe_regardless_of_diagnosis(df_mf_XY, p1_source, p2_source):\n",
    "    # save to csv file\n",
    "    output_file_name = 'mf_{}_{}.csv'.format(p1_source, p2_source)\n",
    "    output_file_path = os.path.join(base_dir, 'data', 'mf_regardless_of_diseases', output_file_name)\n",
    "    df_mf_XY.to_csv(output_file_path)\n",
    "    \n",
    "def process_mf_regardless_of_diagnosis(p1_source, p2_source, hpo, \n",
    "                            remove_pairs_with_same_terms, remove_reflective_pairs, remove_pairs_with_dependency):\n",
    "    # step 1: make a labeled dataframe\n",
    "    hpo_term_map = hpo.term_id_2_label_map()\n",
    "    df_mf_XY = mf_dataframe_regardless_of_diagnosis(p1_source, p2_source, hpo_term_map)\n",
    "    # step 2: filter unnecessary rows\n",
    "    df_mf_XY = filter_mf_dataframe_regardless_of_diagnosis(df_mf_XY, hpo, remove_pairs_with_same_terms, \n",
    "                                                           remove_reflective_pairs, remove_pairs_with_dependency)\n",
    "    # step 3: save to csv\n",
    "    save_mf_dataframe_regardless_of_diagnosis(df_mf_XY, p1_source, p2_source)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### textHpo-labHpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_mf_regardless_of_diagnosis('textHpo', 'labHpo', hpo, \n",
    "                                   remove_pairs_with_same_terms=False, \n",
    "                                   remove_reflective_pairs=False, \n",
    "                                   remove_pairs_with_dependency=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### textHpo-textHpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_mf_regardless_of_diagnosis('textHpo', 'textHpo', hpo, \n",
    "                                   remove_pairs_with_same_terms=True, \n",
    "                                   remove_reflective_pairs=True, \n",
    "                                   remove_pairs_with_dependency=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### labHpo-labHpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_mf_regardless_of_diagnosis('labHpo', 'labHpo', hpo, \n",
    "                                   remove_pairs_with_same_terms=True, \n",
    "                                   remove_reflective_pairs=True, \n",
    "                                   remove_pairs_with_dependency=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Mutual information between textHpo and labHpo in respect to diagnoses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each admission, patients could receive multiple diagnosis codes. One of them is designated as \"primary\" (in MIMIC, it has a rank of 1) and others secondary (rank 2, 3...). Therefore, the analysis was run under two scenerios: \n",
    "1. Only primary diagnosis is considered. \n",
    "2. All diagnoses are considered equally. \n",
    "\n",
    "Under the first scenerio, a patient is considered to be a case only if the corresponding billing code is listed as \"primary\". While in the second case, a patient is considered to be a case when the corresponding billing code is listed as primary or secondary.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_statistics_to_mutualInfoXY_z(p1_source, p2_source, primary_only, diag_code):\n",
    "    if primary_only:\n",
    "        diag_dir = \"primary_only\"\n",
    "    else:\n",
    "        diag_dir = \"primary_and_secondary\"\n",
    "        \n",
    "    summaries_file_name = 'summaries_diagnosis_{}_{}.obj'.format(p1_source, p2_source)\n",
    "    summaries_file_path = os.path.join(base_dir, 'data', 'mf_regarding_diseases', diag_dir, summaries_file_name)\n",
    "    \n",
    "    with open(summaries_file_path, 'rb') as f:\n",
    "        summaries = pickle.load(f)\n",
    "    \n",
    "    summary_statistics_for_diag_code = summaries.get(diag_code)\n",
    "    mutualInfoXYz = mf.MutualInfoXYz(summary_statistics_for_diag_code)\n",
    "    \n",
    "    return mutualInfoXYz\n",
    "\n",
    "def mf_dataframes_regarding_diagnosis(mutualInfoXYz, **p_values):\n",
    "    \"\"\"\n",
    "    @param p_values: output from simulation\n",
    "    \"\"\"\n",
    "    assert isinstance(mutualInfoXYz, mf.MutualInfoXYz)\n",
    "    # unpack p values\n",
    "    p_mf_Xz = p_values.get('mf_Xz')\n",
    "    p_mf_Yz = p_values.get('mf_Yz')\n",
    "    p_mf_XY_z = p_values.get('mf_XY_z')\n",
    "    p_mf_XY_given_z = p_values.get('mf_XY_given_z')\n",
    "    p_synergy = p_values.get('synergy')\n",
    "    p_mf_XY_omit_z = p_values.get('mf_XY_omit_z')\n",
    "    \n",
    "    X_labels, Y_labels = mutualInfoXYz.vars_labels.values()\n",
    "    M1 = len(X_labels)\n",
    "    M2 = len(Y_labels)\n",
    "\n",
    "    mf_Xz = mutualInfoXYz.mutual_info_Xz()\n",
    "    mf_Yz = mutualInfoXYz.mutual_info_Yz()\n",
    "\n",
    "    # mutual information between single phenotypes and diagnosis\n",
    "    df_mf_Xz = pd.DataFrame(data={'X': X_labels, 'mf_Xz': mf_Xz})\n",
    "    df_mf_Yz = pd.DataFrame(data={'Y': Y_labels, 'mf_Yz': mf_Yz})\n",
    "    # add p values\n",
    "    df_mf_Xz['p_mf_Xz'] = p_mf_Xz if p_mf_Xz is not None else np.repeat(-1, M1)\n",
    "    df_mf_Yz['p_mf_Yz'] = p_mf_Yz if p_mf_Yz is not None else np.repeat(-1, M2)\n",
    "    \n",
    "    # joint and conditional mutual information, and synergy\n",
    "    mf_XY_z = mutualInfoXYz.mutual_info_XY_z()\n",
    "    mf_XY_given_z = mutualInfoXYz.mutual_info_XY_given_z()\n",
    "    mf_synergy = mutualInfoXYz.synergy_XY2z()\n",
    "    \n",
    "    # mutual information between phenotypes without considering diagnosis\n",
    "    mf_XY_omit_z = mutualInfoXYz.mutual_info_XY_omit_z()\n",
    "    \n",
    "    # mutual information between phenotype pairs and diagnosis\n",
    "    df_mf_XY_z = pd.DataFrame()\n",
    "    df_mf_XY_z['X'] = np.repeat(X_labels, M2)\n",
    "    df_mf_XY_z['Y'] = np.tile(Y_labels, [M1])\n",
    "    df_mf_XY_z['mf_Xz'] = np.repeat(mf_Xz, M2)\n",
    "    df_mf_XY_z['mf_Yz'] = np.tile(mf_Yz, [M1])\n",
    "    df_mf_XY_z['mf_XY_z'] = mf_XY_z.flat\n",
    "    df_mf_XY_z['synergy'] = mf_synergy.flat   # synergy = mf_XY_z - mf_Xz - mf_Yz\n",
    "    \n",
    "    # mutual information between phenotypes after omiting diagnosis or conditioned on diagnosis\n",
    "    df_mf_XY_z['mf_XY_omit_z'] = mf_XY_omit_z.flat\n",
    "    df_mf_XY_z['mf_XY_given_z'] = mf_XY_given_z.flat\n",
    "    \n",
    "    # ratio of conditional mutual information / mutual information without considering diagnosis\n",
    "    # synergy is also equal to mf_XY_given_z - mf_XY_omit_z\n",
    "    # here we use ratio, which can be considered as an alternative of the above definition of synergy\n",
    "    df_mf_XY_z['mf_ratio'] = df_mf_XY_z['mf_XY_given_z'] / df_mf_XY_z['mf_XY_omit_z']\n",
    "    \n",
    "    # add p values; otherwise, assign -1\n",
    "    df_mf_XY_z['p_mf_Xz'] = np.repeat(p_mf_Xz, M2) if p_mf_Xz is not None else np.repeat(-1, M1*M2)\n",
    "    df_mf_XY_z['p_mf_Yz'] = np.tile(p_mf_Yz, [M1]) if p_mf_Yz is not None else np.repeat(-1, M1*M2)\n",
    "    df_mf_XY_z['p_mf_XY_z'] = p_mf_XY_z.flat if p_mf_XY_z is not None else np.repeat(-1, M1*M2)\n",
    "    df_mf_XY_z['p_synergy'] = p_synergy.flat if p_synergy is not None else np.repeat(-1, M1*M2)\n",
    "    df_mf_XY_z['p_mf_XY_omit_z'] = p_mf_XY_omit_z.flat if p_mf_XY_omit_z is not None else np.repeat(-1, M1*M2)\n",
    "    df_mf_XY_z['p_mf_XY_given_z'] = p_mf_XY_given_z.flat if p_mf_XY_given_z is not None else np.repeat(-1, M1*M2)\n",
    "    \n",
    "    \n",
    "    # add raw counts: 8 additional columns\n",
    "    joint_dist_keys = ['+++', '++-', '+-+', '+--', '-++', '-+-', '--+', '---']\n",
    "    joint_dist_values = mutualInfoXYz.m2.reshape([-1, 8]).astype(int)\n",
    "    raw_counts = {joint_dist_keys[i]: joint_dist_values[:,i] for i in np.arange(8)}\n",
    "    df_mf_XY_z = df_mf_XY_z.assign(**raw_counts)\n",
    "    df_mf_XY_z['sum'] = np.sum(joint_dist_values, axis=-1) # it's a constant for all rows\n",
    "    \n",
    "    return df_mf_Xz, df_mf_Yz, df_mf_XY_z\n",
    "\n",
    "\n",
    "def rename_mf_dataframes(df_mf_Xz, df_mf_Yz, df_mf_XY_z):\n",
    "    # map column names to more meaningful name for this context\n",
    "    name_dict = {\n",
    "        'X': 'P1', \n",
    "        'Y': 'P2', \n",
    "        'mf_Xz': 'mf_P1_diag',\n",
    "        'mf_Yz': 'mf_P2_diag',\n",
    "        'mf_XY_z': 'mf_P1P2_diag',\n",
    "        'mf_XY_given_z': 'mf_P1P2_given_diag',\n",
    "        'mf_XY_omit_z': 'mf_P1P2_omit_diag',\n",
    "        'p_mf_XY_z': 'p_mf_P1P2_diag',\n",
    "        'p_mf_XY_given_z': 'p_mf_P1P2_given_diag',\n",
    "        'p_mf_XY_omit_z': 'p_mf_P1P2_omit_diag',\n",
    "        'mf_Xz': 'mf_P1_diag', \n",
    "        'mf_Yz': 'mf_P2_diag',  \n",
    "        'p_mf_Xz': 'p_mf_P1_diag', \n",
    "        'p_mf_Yz': 'p_mf_P2_diag'   \n",
    "    }\n",
    "\n",
    "    df_mf_Xz = df_mf_Xz.rename(columns=name_dict, errors='ignore') \n",
    "    df_mf_Yz = df_mf_Yz.rename(columns=name_dict, errors='ignore') \n",
    "    df_mf_XY_z = df_mf_XY_z.rename(columns=name_dict, errors='ignore')\n",
    "    \n",
    "    return df_mf_Xz, df_mf_Yz, df_mf_XY_z\n",
    "\n",
    "\n",
    "def filter_mf_dataframe_regarding_diagnosis(df_mf_XY_z, hpo, \n",
    "                                            remove_pairs_with_same_terms, \n",
    "                                            remove_reflective_pairs, \n",
    "                                            remove_pairs_with_dependency,\n",
    "                                           sort_by='synergy'):\n",
    "    # use the same method as the one defined above, except to sort by a different column\n",
    "    return filter_mf_dataframe_regardless_of_diagnosis(df_mf_XY_z, hpo,\n",
    "                                         remove_pairs_with_same_terms, \n",
    "                                         remove_reflective_pairs, \n",
    "                                         remove_pairs_with_dependency,\n",
    "                                         sort_by)\n",
    "\n",
    "def entropy(case, control):\n",
    "    total = case + control \n",
    "    h = -(case / total * np.log2(case/total) + control/total * np.log2(control/total))\n",
    "    return h\n",
    "    \n",
    "\n",
    "def load_p_values(p1_source, p2_source, diag_code, primary_only):\n",
    "    if primary_only:\n",
    "        p_values_file_name = 'p_value_{}_{}_{}_{}.obj'.format(p1_source, p2_source, diag_code, 'primary_only')\n",
    "    else:\n",
    "        p_values_file_name = 'p_value_{}_{}_{}_{}.obj'.format(p1_source, p2_source, diag_code, 'primary_and_secondary')\n",
    "    \n",
    "    p_values_file_path = os.path.join(base_dir, 'data', 'mf_regarding_diseases', 'primary_only', diag_code, p_values_file_name)\n",
    "    with open(p_values_file_path, 'rb') as f:\n",
    "        p = pickle.load(f)\n",
    "    return p\n",
    "\n",
    "convert_to_percent = np.vectorize(lambda x: ' {:.2f}%'.format(x * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mf_df_regarding_diseases(p1_source, p2_source, primary_only, diag_code, hpo, \n",
    "                                     remove_pairs_with_same_terms,\n",
    "                                     remove_reflective_pairs, \n",
    "                                     remove_pairs_with_dependency,\n",
    "                                     sort_by='synergy'):\n",
    "    # calculate mutual information from summary statistics \n",
    "    mutualInfoXYz = summary_statistics_to_mutualInfoXY_z(p1_source, p2_source, primary_only, diag_code=disease)\n",
    "    # load p values (calculated from simulation on Helix)\n",
    "    p_values = load_p_values(p1_source, p2_source, disease, primary_only)\n",
    "    # create dataframes\n",
    "    df_mf_Xz, df_mf_Yz, df_mf_XY_z = mf_dataframes_regarding_diagnosis(mutualInfoXYz, **p_values)\n",
    "    # rename dataframes \n",
    "    df_mf_Xz, df_mf_Yz, df_mf_XY_z = rename_mf_dataframes(df_mf_Xz, df_mf_Yz, df_mf_XY_z)\n",
    "    # label HPO term ids with their names\n",
    "    df_mf_Xz['P1_label'] = [hpo_term_map.get(termid) for termid in df_mf_Xz.P1]\n",
    "    df_mf_Yz['P2_label'] = [hpo_term_map.get(termid) for termid in df_mf_Yz.P2]\n",
    "    df_mf_XY_z['P1_label'] = [hpo_term_map.get(termid) for termid in df_mf_XY_z.P1]\n",
    "    df_mf_XY_z['P2_label'] = [hpo_term_map.get(termid) for termid in df_mf_XY_z.P2]\n",
    "    # filter synergy dataframe\n",
    "    df_mf_XY_z = filter_mf_dataframe_regarding_diagnosis(df_mf_XY_z, hpo, \n",
    "                                                               remove_pairs_with_same_terms, \n",
    "                                                               remove_reflective_pairs, \n",
    "                                                               remove_pairs_with_dependency,\n",
    "                                                               sort_by)\n",
    "    # sort by desired columns\n",
    "    df_mf_Xz = df_mf_Xz.sort_values(by='mf_P1_diag', ascending=False).reset_index(drop=True)\n",
    "    df_mf_Yz = df_mf_Yz.sort_values(by='mf_P2_diag', ascending=False).reset_index(drop=True)\n",
    "    df_mf_XY_z = df_mf_XY_z.sort_values(by=sort_by, ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # output to csv file\n",
    "    # just save df_mf_XY_z_filtered as it contains data in df_mf_Xz and df_mf_Yz\n",
    "    csv_file_name = 'df_synergy_{}_{}_{}.csv'.format(p1_source, p2_source, disease)\n",
    "    if primary_only:\n",
    "        diag_dir = 'primary_only'\n",
    "    else:\n",
    "        diag_dir = 'primary_and_secondary'    \n",
    "    csv_parent_dir = os.path.join(base_dir, 'data', 'mf_regarding_diseases', diag_dir)\n",
    "    if not os.path.exists(csv_parent_dir):\n",
    "        os.mkdir(csv_parent_dir)\n",
    "    csv_file_path = os.path.join(csv_parent_dir, csv_file_name)\n",
    "    \n",
    "    df_mf_XY_z.to_csv(csv_file_path)\n",
    "    \n",
    "    # output cytoscape files\n",
    "    percentile = 0.01\n",
    "    n = math.floor(len(df_mf_XY_z) * percentile)\n",
    "\n",
    "    df_4_cytoscape = df_mf_XY_z \\\n",
    "        .assign(P1 = lambda x: 'Rad_' + x['P1']) \\\n",
    "        .assign(P2 = lambda x: 'Lab_' + x['P2']) \\\n",
    "        .head(n = n)\n",
    "\n",
    "    cytoscape_dir = os.path.join(base_dir, 'data', 'mf_regarding_diseases', diag_dir, disease, 'cytoscape')\n",
    "    if not os.path.exists(cytoscape_dir):\n",
    "        os.mkdir(cytoscape_dir)\n",
    "    # edges\n",
    "    edges_path = os.path.join(cytoscape_dir, 'edges_{}_{}_{}.csv'.format(p1_source, p2_source, disease))\n",
    "    df_4_cytoscape.loc[:, ['P1', 'P2', 'synergy', 'p_synergy']].to_csv(edges_path)\n",
    "\n",
    "    # nodes\n",
    "    nodes = pd.DataFrame(data={'term_id': np.concatenate([df_4_cytoscape.P1, df_4_cytoscape.P2]), \n",
    "                               'term_label': np.concatenate([df_4_cytoscape.P1_label, df_4_cytoscape.P2_label]),\n",
    "                              'type': np.repeat(['Rad', 'Lab'], len(df_4_cytoscape))}).drop_duplicates()\n",
    "    nodes_path = os.path.join(cytoscape_dir, 'nodes_textHpo_labHpo_{}.csv'.format( disease))\n",
    "    nodes.to_csv(nodes_path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_source='textHpo'\n",
    "p2_source='labHpo'\n",
    "primary_only=True\n",
    "diag_code='493' \n",
    "remove_pairs_with_same_terms=False\n",
    "remove_reflective_pairs=False\n",
    "remove_pairs_with_dependency=True\n",
    "\n",
    "process_mf_df_regarding_diseases(p1_source, p2_source, primary_only, diag_code, hpo, \n",
    "                                     remove_pairs_with_same_terms,\n",
    "                                     remove_reflective_pairs, \n",
    "                                     remove_pairs_with_dependency,\n",
    "                                     sort_by='synergy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>mf_P1_diag</th>\n",
       "      <th>mf_P2_diag</th>\n",
       "      <th>mf_P1P2_diag</th>\n",
       "      <th>synergy</th>\n",
       "      <th>mf_P1P2_omit_diag</th>\n",
       "      <th>mf_P1P2_given_diag</th>\n",
       "      <th>mf_ratio</th>\n",
       "      <th>p_mf_P1_diag</th>\n",
       "      <th>...</th>\n",
       "      <th>p_mf_P1P2_given_diag</th>\n",
       "      <th>+++</th>\n",
       "      <th>++-</th>\n",
       "      <th>+-+</th>\n",
       "      <th>+--</th>\n",
       "      <th>-++</th>\n",
       "      <th>-+-</th>\n",
       "      <th>--+</th>\n",
       "      <th>---</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>HP:0002098</td>\n",
       "      <td>HP:0004364</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.022870</td>\n",
       "      <td>0.023336</td>\n",
       "      <td>1.020365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>6872</td>\n",
       "      <td>58</td>\n",
       "      <td>2710</td>\n",
       "      <td>46</td>\n",
       "      <td>23473</td>\n",
       "      <td>82</td>\n",
       "      <td>25707</td>\n",
       "      <td>58976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>HP:0002098</td>\n",
       "      <td>HP:0002157</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.023635</td>\n",
       "      <td>0.024078</td>\n",
       "      <td>1.018772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>6338</td>\n",
       "      <td>61</td>\n",
       "      <td>3244</td>\n",
       "      <td>45</td>\n",
       "      <td>20425</td>\n",
       "      <td>83</td>\n",
       "      <td>28755</td>\n",
       "      <td>58976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>HP:0002098</td>\n",
       "      <td>HP:0003138</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.023997</td>\n",
       "      <td>0.024419</td>\n",
       "      <td>1.017581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>6185</td>\n",
       "      <td>61</td>\n",
       "      <td>3397</td>\n",
       "      <td>45</td>\n",
       "      <td>19553</td>\n",
       "      <td>83</td>\n",
       "      <td>29627</td>\n",
       "      <td>58976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>HP:0002098</td>\n",
       "      <td>HP:0010929</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.002477</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.011807</td>\n",
       "      <td>0.012220</td>\n",
       "      <td>1.034901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33</td>\n",
       "      <td>7717</td>\n",
       "      <td>53</td>\n",
       "      <td>1865</td>\n",
       "      <td>39</td>\n",
       "      <td>31765</td>\n",
       "      <td>89</td>\n",
       "      <td>17415</td>\n",
       "      <td>58976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>HP:0002098</td>\n",
       "      <td>HP:0031970</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.023358</td>\n",
       "      <td>0.023766</td>\n",
       "      <td>1.017466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>6424</td>\n",
       "      <td>59</td>\n",
       "      <td>3158</td>\n",
       "      <td>45</td>\n",
       "      <td>20951</td>\n",
       "      <td>83</td>\n",
       "      <td>28229</td>\n",
       "      <td>58976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           P1          P2  mf_P1_diag  mf_P2_diag  mf_P1P2_diag   synergy  \\\n",
       "0  HP:0002098  HP:0004364    0.000842    0.000308      0.001615  0.000466   \n",
       "1  HP:0002098  HP:0002157    0.000842    0.000178      0.001463  0.000444   \n",
       "2  HP:0002098  HP:0003138    0.000842    0.000134      0.001398  0.000422   \n",
       "3  HP:0002098  HP:0010929    0.000842    0.001223      0.002477  0.000412   \n",
       "4  HP:0002098  HP:0031970    0.000842    0.000180      0.001429  0.000408   \n",
       "\n",
       "   mf_P1P2_omit_diag  mf_P1P2_given_diag  mf_ratio  p_mf_P1_diag  ...  \\\n",
       "0           0.022870            0.023336  1.020365           0.0  ...   \n",
       "1           0.023635            0.024078  1.018772           0.0  ...   \n",
       "2           0.023997            0.024419  1.017581           0.0  ...   \n",
       "3           0.011807            0.012220  1.034901           0.0  ...   \n",
       "4           0.023358            0.023766  1.017466           0.0  ...   \n",
       "\n",
       "   p_mf_P1P2_given_diag  +++   ++-  +-+   +--  -++    -+-  --+    ---    sum  \n",
       "0                   0.0   28  6872   58  2710   46  23473   82  25707  58976  \n",
       "1                   0.0   25  6338   61  3244   45  20425   83  28755  58976  \n",
       "2                   0.0   25  6185   61  3397   45  19553   83  29627  58976  \n",
       "3                   0.0   33  7717   53  1865   39  31765   89  17415  58976  \n",
       "4                   0.0   27  6424   59  3158   45  20951   83  28229  58976  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1_source='textHpo'\n",
    "p2_source='labHpo'\n",
    "disease='493'\n",
    "mutualInfoXYz = summary_statistics_to_mutualInfoXY_z(p1_source, p2_source, primary_only=True, diag_code=disease)\n",
    "\n",
    "p_values = load_p_values(p1_source, p2_source, disease, primary_only=True)\n",
    "\n",
    "df_mf_Xz, df_mf_Yz, df_mf_XY_z = mf_dataframes_regarding_diagnosis(mutualInfoXYz, **p_values)\n",
    "\n",
    "df_mf_Xz, df_mf_Yz, df_mf_XY_z = rename_mf_dataframes(df_mf_Xz, df_mf_Yz, df_mf_XY_z)\n",
    "\n",
    "df_XY_z_filtered = filter_mf_dataframe_regarding_diagnosis(df_mf_XY_z, hpo, \n",
    "                                            remove_pairs_with_same_terms=False, \n",
    "                                            remove_reflective_pairs=False, \n",
    "                                            remove_pairs_with_dependency=True)\n",
    "df_XY_z_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_only = True\n",
    "if primary_only:\n",
    "    diag_dir = \"primary_only\"\n",
    "else:\n",
    "    diag_dir = \"primary_and_secondary\"\n",
    "\n",
    "    \n",
    "with open('../../../data/mf_regarding_diseases/{}/summaries_diagnosis_textHpo_labHpo.obj'.format(diag_dir), 'rb') as f:\n",
    "    summaries_diagnosis_textHpo_labHpo = pickle.load(f)\n",
    "with open('../../../data/mf_regarding_diseases/{}/summaries_diagnosis_textHpo_textHpo.obj'.format(diag_dir), 'rb') as f:\n",
    "    summaries_diagnosis_textHpo_textHpo = pickle.load(f)\n",
    "with open('../../../data/mf_regarding_diseases/{}/summaries_diagnosis_labHpo_labHpo.obj'.format(diag_dir), 'rb') as f:\n",
    "    summaries_diagnosis_labHpo_labHpo = pickle.load(f)\n",
    "summaries = {('textHpo', 'labHpo'): summaries_diagnosis_textHpo_labHpo,\n",
    "             ('textHpo', 'textHpo'): summaries_diagnosis_textHpo_textHpo,\n",
    "            ('labHpo', 'labHpo'): summaries_diagnosis_labHpo_labHpo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map column names to more meaningful name for this context\n",
    "name_dict = {\n",
    "        'X': 'P1', \n",
    "        'Y': 'P2', \n",
    "        'mf_Xz': 'mf_P1_diag',\n",
    "        'mf_Yz': 'mf_P2_diag',\n",
    "        'mf_XY_z': 'mf_P1P2_diag',\n",
    "        'mf_XY_given_z': 'mf_P1P2_given_diag',\n",
    "        'mf_XY_omit_z': 'mf_P1P2_omit_diag',\n",
    "        'p_mf_XY_z': 'p_mf_P1P2_diag',\n",
    "        'p_mf_XY_given_z': 'p_mf_P1P2_given_diag',\n",
    "        'p_mf_XY_omit_z': 'p_mf_P1P2_omit_diag',\n",
    "        'mf_Xz': 'mf_P1_diag', \n",
    "        'mf_Yz': 'mf_P2_diag',  \n",
    "        'p_mf_Xz': 'p_mf_P1_diag', \n",
    "        'p_mf_Yz': 'p_mf_P2_diag'   \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output rendered csv and html files for selected diseases and phenotype sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the following variables to analyze\n",
    "disease = '493'\n",
    "p1_source = 'textHpo'\n",
    "p2_source = 'labHpo'\n",
    "\n",
    "\n",
    "# calculate mutual information from summary statistics\n",
    "summaries_p1_p2 = summaries.get((p1_source, p2_source))\n",
    "summary_statistics = summaries_p1_p2[disease]\n",
    "mf_diagnosis_phenotypes = mf.MutualInfoXYz(summary_statistics)\n",
    "\n",
    "# calculate p value on Helix for disease of interest: input-summary statistics; output-a dictionary of p values\n",
    "# TODO: get script \n",
    "\n",
    "# load p values\n",
    "p_values_file_name = 'p_value_{}_{}_{}_{}.obj'.format(p1_source, p2_source, disease, diag_dir)\n",
    "p_values_file_path = os.path.join('../../../data/mf_regarding_diseases/', diag_dir, disease, p_values_file_name)\n",
    "p_values = load_p_values(p_values_file_path)\n",
    "\n",
    "df_mf_Xz, df_mf_Yz, df_mf_XY_z = mf_dataframes(mf_diagnosis_phenotypes, **p_values)\n",
    "\n",
    "df_mf_XY_z_filtered = filter_df(df_mf_Xz, df_mf_Yz, df_mf_XY_z)\n",
    "\n",
    "# rename column names for this context using the dictionary defined above\n",
    "df_mf_Xz = df_mf_Xz.rename(columns=name_dict, errors='ignore') \n",
    "df_mf_Yz = df_mf_Yz.rename(columns=name_dict, errors='ignore') \n",
    "df_mf_XY_z_filtered = df_mf_XY_z_filtered.rename(columns=name_dict, errors='ignore')\n",
    "\n",
    "# label HPO term ids with their names\n",
    "df_mf_Xz['P1_label'] = [hpo_term_map.get(termid) for termid in df_mf_Xz.P1]\n",
    "df_mf_Yz['P2_label'] = [hpo_term_map.get(termid) for termid in df_mf_Yz.P2]\n",
    "df_mf_XY_z_filtered['P1_label'] = [hpo_term_map.get(termid) for termid in df_mf_XY_z_filtered.P1]\n",
    "df_mf_XY_z_filtered['P2_label'] = [hpo_term_map.get(termid) for termid in df_mf_XY_z_filtered.P2]\n",
    "\n",
    "# sort by desired columns\n",
    "df_mf_Xz = df_mf_Xz.sort_values(by='mf_P1_diag', ascending=False).reset_index(drop=True)\n",
    "df_mf_Yz = df_mf_Yz.sort_values(by='mf_P2_diag', ascending=False).reset_index(drop=True)\n",
    "df_mf_XY_z_filtered = df_mf_XY_z_filtered.sort_values(by='synergy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# output to csv file\n",
    "# just save df_mf_XY_z_filtered as it contains data in df_mf_Xz and df_mf_Yz\n",
    "csv_file_name = 'df_synergy_{}_{}_{}.csv'.format(p1_source, p2_source, disease)\n",
    "csv_file_path = os.path.join('../../../data/mf_regarding_diseases/', diag_dir, csv_file_name)\n",
    "df_mf_XY_z_filtered.head(n = 20)\n",
    "df_mf_XY_z_filtered.to_csv(csv_file_path)\n",
    "\n",
    "# render html\n",
    "\n",
    "\n",
    "# output cytoscape files\n",
    "percentile = 0.01\n",
    "n = math.floor(len(df_mf_XY_z_filtered) * percentile)\n",
    "\n",
    "df_4_cytoscape = df_mf_XY_z_filtered \\\n",
    "    .assign(P1 = lambda x: 'Rad_' + x['P1']) \\\n",
    "    .assign(P2 = lambda x: 'Lab_' + x['P2']) \\\n",
    "    .head(n = n)\n",
    "\n",
    "\n",
    "# edges\n",
    "edges_path = os.path.join('../../../data/mf_regarding_diseases', diag_dir, 'cytoscape', 'edges_{}_{}_{}.csv'.format(p1_source, p2_source, disease))\n",
    "df_4_cytoscape.loc[:, ['P1', 'P2', 'synergy', 'p_synergy']].to_csv(edges_path)\n",
    "\n",
    "# nodes\n",
    "nodes = pd.DataFrame(data={'term_id': np.concatenate([df_4_cytoscape.P1, df_4_cytoscape.P2]), \n",
    "                           'term_label': np.concatenate([df_4_cytoscape.P1_label, df_4_cytoscape.P2_label]),\n",
    "                          'type': np.repeat(['Rad', 'Lab'], len(df_4_cytoscape))}).drop_duplicates()\n",
    "nodes_path = os.path.join('../../../data/mf_regarding_diseases', diag_dir, 'cytoscape', 'nodes_textHpo_labHpo_{}.csv'.format( disease))\n",
    "nodes.to_csv(nodes_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
