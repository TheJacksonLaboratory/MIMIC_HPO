{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phenotype Synergy Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook contains code to interprete results from the synergy score analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "mf_module_path = os.path.abspath(os.path.join('../python'))\n",
    "if mf_module_path not in sys.path:\n",
    "    sys.path.append(mf_module_path)\n",
    "import mf\n",
    "import mf_random\n",
    "from ontology import Ontology\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use hp.obo from online or your local file system\n",
    "#hpo = Ontology('http://purl.obolibrary.org/obo/hp.obo')\n",
    "hpo = Ontology('/Users/zhangx/git/human-phenotype-ontology/hp.obo')\n",
    "hpo_term_map = hpo.term_id_2_label_map()\n",
    "\n",
    "# base dir: path to the MIMIC_HPO repo on your machine\n",
    "base_dir = '../../..'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual information without considering diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section analyzes the mutual information between phenotype pairs (labHpo-labHpo, textHpo-labHpo, textHpo-textHpo) in regardless of diagnosis. \n",
    "\n",
    "Note that the same information is also produced as a side product when we calculate mutual information in respect to a disease. Because we run simulations in the latter case, we additionally get their p values for the observed value.\n",
    "\n",
    "Processing steps: \n",
    "For each type of summary statistics, we can map them into a MutualInfoXY instance. From there, we can get the mutual information matrix (or dataframe), and then do necessary filtering. In the last, we save the dataframe to a file.\n",
    "\n",
    "**Filter 1:**\n",
    "\n",
    "If P1 and P2 are both from labHpo or textHpo, then remove rows where P1 is identical to P2\n",
    "\n",
    "**Filter 2:**\n",
    "\n",
    "If P1 and P2 are both from labHpo or textHpo, then a row for (a, b) is identical to (b, a). So one row is removed. \n",
    "\n",
    "**Filter 3:**\n",
    "\n",
    "Because we automatically added ancestors terms if a child term is observed, P1 and P2 are expected to have high mutual information if they have dependency in HPO hierarchy. Such pairs are removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mf_dataframe_regardless_of_diagnosis(p1_source, p2_source, hpo_term_map):\n",
    "    summary_file_name = 'summary_{}_{}.obj'.format(p1_source, p2_source)\n",
    "    summary_file_path = os.path.join(base_dir, 'data', 'mf_regardless_of_diseases', summary_file_name)\n",
    "    with open(summary_file_path, 'rb') as f:\n",
    "        summary_statistics = pickle.load(f)\n",
    "    \n",
    "    # convert to a MutualInfoXY object from summary statistics\n",
    "    mf_XY = mf.MutualInfoXY(summary_statistics)\n",
    "    \n",
    "    # get a dataframe\n",
    "    df_mf_XY = mf_XY.mf_labeled()\n",
    "    \n",
    "    # label termid with names\n",
    "    df_mf_XY['P1_label'] = np.array([hpo_term_map.get(termid) for termid in df_mf_XY.P1])\n",
    "    df_mf_XY['P2_label'] = np.array([hpo_term_map.get(termid) for termid in df_mf_XY.P2])\n",
    "    \n",
    "    return df_mf_XY\n",
    "\n",
    "def filter_mf_dataframe_regardless_of_diagnosis(df_mf_XY, hpo,\n",
    "                                         remove_pairs_with_same_terms, \n",
    "                                         remove_reflective_pairs, \n",
    "                                         remove_pairs_with_dependency):\n",
    "    # remove pairs where P1, P2 are the same\n",
    "    if remove_pairs_with_same_terms:\n",
    "        df_mf_XY = df_mf_XY.loc[df_mf_XY.P1 != df_mf_XY.P2, :].reset_index(drop=True)\n",
    "    \n",
    "    # remove reflective pairs: (a, b) and (b, a) are considered reflective pairs\n",
    "    # the method is to use string comparison: always require P1 <= P2\n",
    "    if remove_reflective_pairs:\n",
    "        df_mf_XY = df_mf_XY.loc[df_mf_XY.P1 <= df_mf_XY.P2, :].reset_index(drop=True)\n",
    "    \n",
    "    # remove pairs with dependency\n",
    "    has_dependency = np.repeat(False, len(df_mf_XY))\n",
    "    for i in np.arange(len(df_mf_XY)):\n",
    "        x = df_mf_XY.P1[i]\n",
    "        y = df_mf_XY.P2[i]\n",
    "        has_dependency[i] = x != y and (hpo.exists_path(x, y) or hpo.exists_path(y, x))\n",
    "        \n",
    "    if remove_pairs_with_dependency:\n",
    "        # when does two terms in a pair has dependency: different, but there is path from one to another\n",
    "        df_mf_XY = df_mf_XY.loc[np.logical_not(has_dependency), :]\n",
    "        \n",
    "    df_mf_XY = df_mf_XY.sort_values(by='mf', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return df_mf_XY\n",
    "\n",
    "def save_mf_dataframe_regardless_of_diagnosis(df_mf_XY, p1_source, p2_source):\n",
    "    # save to csv file\n",
    "    output_file_name = 'mf_{}_{}.csv'.format(p1_source, p2_source)\n",
    "    output_file_path = os.path.join(base_dir, 'data', 'mf_regardless_of_diseases', output_file_name)\n",
    "    df_mf_XY.to_csv(output_file_path)\n",
    "    \n",
    "def process_mf_regardless_of_diagnosis(p1_source, p2_source, hpo, \n",
    "                            remove_pairs_with_same_terms, remove_reflective_pairs, remove_pairs_with_dependency):\n",
    "    # step 1: make a labeled dataframe\n",
    "    hpo_term_map = hpo.term_id_2_label_map()\n",
    "    df_mf_XY = mf_dataframe_regardless_of_diagnosis(p1_source, p2_source, hpo_term_map)\n",
    "    # step 2: filter unnecessary rows\n",
    "    df_mf_XY = filter_mf_dataframe_regardless_of_diagnosis(df_mf_XY, hpo, remove_pairs_with_same_terms, \n",
    "                                                           remove_reflective_pairs, remove_pairs_with_dependency)\n",
    "    # step 3: save to csv\n",
    "    save_mf_dataframe_regardless_of_diagnosis(df_mf_XY, p1_source, p2_source)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### textHpo-labHpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_mf_regardless_of_diagnosis('textHpo', 'labHpo', hpo, \n",
    "                                   remove_pairs_with_same_terms=False, \n",
    "                                   remove_reflective_pairs=False, \n",
    "                                   remove_pairs_with_dependency=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### textHpo-textHpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_mf_regardless_of_diagnosis('textHpo', 'textHpo', hpo, \n",
    "                                   remove_pairs_with_same_terms=True, \n",
    "                                   remove_reflective_pairs=True, \n",
    "                                   remove_pairs_with_dependency=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### labHpo-labHpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_mf_regardless_of_diagnosis('labHpo', 'labHpo', hpo, \n",
    "                                   remove_pairs_with_same_terms=True, \n",
    "                                   remove_reflective_pairs=True, \n",
    "                                   remove_pairs_with_dependency=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Mutual information between textHpo and labHpo in respect to diagnoses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each admission, patients could receive multiple diagnosis codes. One of them is designated as \"primary\" (in MIMIC, it has a rank of 1) and others secondary (rank 2, 3...). Therefore, the analysis was run under two scenerios: \n",
    "1. Only primary diagnosis is considered. \n",
    "2. All diagnoses are considered equally. \n",
    "\n",
    "Under the first scenerio, a patient is considered to be a case only if the corresponding billing code is listed as \"primary\". While in the second case, a patient is considered to be a case when the corresponding billing code is listed as primary or secondary.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mf_dataframes(mf_diagnosis_phenotypes, **p_values):\n",
    "    \"\"\"\n",
    "    @param p_values: output from simulation\n",
    "    \"\"\"\n",
    "    assert isinstance(mf_diagnosis_phenotypes, mf.MutualInfoXYz)\n",
    "    # unpack p values\n",
    "    p_mf_Xz = p_values.get('mf_Xz')\n",
    "    p_mf_Yz = p_values.get('mf_Yz')\n",
    "    p_mf_XY_z = p_values.get('mf_XY_z')\n",
    "    p_mf_XY_given_z = p_values.get('mf_XY_given_z')\n",
    "    p_synergy = p_values.get('synergy')\n",
    "    p_mf_XY_omit_z = p_values.get('mf_XY_omit_z')\n",
    "    \n",
    "    X_labels, Y_labels = mf_diagnosis_phenotypes.vars_labels.values()\n",
    "    M1 = len(X_labels)\n",
    "    M2 = len(Y_labels)\n",
    "\n",
    "    mf_Xz = mf_diagnosis_phenotypes.mutual_info_Xz()\n",
    "    mf_Yz = mf_diagnosis_phenotypes.mutual_info_Yz()\n",
    "\n",
    "    # mutual information between single phenotypes and diagnosis\n",
    "    df_mf_Xz = pd.DataFrame(data={'X': X_labels, 'mf_Xz': mf_Xz})\n",
    "    df_mf_Yz = pd.DataFrame(data={'Y': Y_labels, 'mf_Yz': mf_Yz})\n",
    "    # add p values\n",
    "    df_mf_Xz['p_mf_Xz'] = p_mf_Xz if p_mf_Xz is not None else np.repeat(-1, M1)\n",
    "    df_mf_Yz['p_mf_Yz'] = p_mf_Yz if p_mf_Yz is not None else np.repeat(-1, M2)\n",
    "    \n",
    "    # joint and conditional mutual information, and synergy\n",
    "    mf_XY_z = mf_diagnosis_phenotypes.mutual_info_XY_z()\n",
    "    mf_XY_given_z = mf_diagnosis_phenotypes.mutual_info_XY_given_z()\n",
    "    mf_synergy = mf_diagnosis_phenotypes.synergy_XY2z()\n",
    "    \n",
    "    # mutual information between phenotypes without considering diagnosis\n",
    "    mf_XY_omit_z = mf_diagnosis_phenotypes.mutual_info_XY_omit_z()\n",
    "    \n",
    "    # mutual information between phenotype pairs and diagnosis\n",
    "    df_mf_XY_z = pd.DataFrame()\n",
    "    df_mf_XY_z['X'] = np.repeat(X_labels, M2)\n",
    "    df_mf_XY_z['Y'] = np.tile(Y_labels, [M1])\n",
    "    df_mf_XY_z['mf_Xz'] = np.repeat(mf_Xz, M2)\n",
    "    df_mf_XY_z['mf_Yz'] = np.tile(mf_Yz, [M1])\n",
    "    df_mf_XY_z['mf_XY_z'] = mf_XY_z.flat\n",
    "    df_mf_XY_z['synergy'] = mf_synergy.flat   # synergy = mf_XY_z - mf_Xz - mf_Yz\n",
    "    \n",
    "    # mutual information between phenotypes after omiting diagnosis or conditioned on diagnosis\n",
    "    df_mf_XY_z['mf_XY_omit_z'] = mf_XY_omit_z.flat\n",
    "    df_mf_XY_z['mf_XY_given_z'] = mf_XY_given_z.flat\n",
    "    \n",
    "    # ratio of conditional mutual information / mutual information without considering diagnosis\n",
    "    # synergy is also equal to mf_XY_given_z - mf_XY_omit_z\n",
    "    # here we use ratio, which can be considered as an alternative of the above definition of synergy\n",
    "    df_mf_XY_z['mf_ratio'] = df_mf_XY_z['mf_XY_given_z'] / df_mf_XY_z['mf_XY_omit_z']\n",
    "    \n",
    "    # add p values; otherwise, assign -1\n",
    "    df_mf_XY_z['p_mf_Xz'] = np.repeat(p_mf_Xz, M2) if p_mf_Xz is not None else np.repeat(-1, M1*M2)\n",
    "    df_mf_XY_z['p_mf_Yz'] = np.tile(p_mf_Yz, [M1]) if p_mf_Yz is not None else np.repeat(-1, M1*M2)\n",
    "    df_mf_XY_z['p_mf_XY_z'] = p_mf_XY_z.flat if p_mf_XY_z is not None else np.repeat(-1, M1*M2)\n",
    "    df_mf_XY_z['p_synergy'] = p_synergy.flat if p_synergy is not None else np.repeat(-1, M1*M2)\n",
    "    df_mf_XY_z['p_mf_XY_omit_z'] = p_mf_XY_omit_z.flat if p_mf_XY_omit_z is not None else np.repeat(-1, M1*M2)\n",
    "    df_mf_XY_z['p_mf_XY_given_z'] = p_mf_XY_given_z.flat if p_mf_XY_given_z is not None else np.repeat(-1, M1*M2)\n",
    "    \n",
    "    \n",
    "    # add raw counts: 8 additional columns\n",
    "    joint_dist_keys = ['+++', '++-', '+-+', '+--', '-++', '-+-', '--+', '---']\n",
    "    joint_dist_values = mf_diagnosis_phenotypes.m2.reshape([-1, 8]).astype(int)\n",
    "    raw_counts = {joint_dist_keys[i]: joint_dist_values[:,i] for i in np.arange(8)}\n",
    "    df_mf_XY_z = df_mf_XY_z.assign(**raw_counts)\n",
    "    df_mf_XY_z['sum'] = np.sum(joint_dist_values, axis=-1) # it's a constant for all rows\n",
    "    \n",
    "\n",
    "    return df_mf_Xz, df_mf_Yz, df_mf_XY_z\n",
    "    \n",
    "\n",
    "def filter_df(df_mf_Xz, df_mf_Yz, df_mf_XY_z):\n",
    "    df_merged = df_mf_XY_z\n",
    "\n",
    "    ## filter out identifical pairs: a, b is the same as b, a\n",
    "    df_filtered = df_merged.loc[df_merged.X < df_merged.Y, :].reset_index(drop=True)\n",
    "    mask = np.array([hpo.exists_path(df_filtered.X[i], df_filtered.Y[i]) or \n",
    "                     hpo.exists_path(df_filtered.Y[i], df_filtered.X[i]) for i in np.arange(len(df_filtered))])\n",
    "    df_filtered = df_filtered.loc[np.logical_not(mask), ].reset_index(drop=True)\n",
    "    return df_filtered\n",
    "\n",
    "def entropy(case, control):\n",
    "    total = case + control \n",
    "    h = -(case / total * np.log2(case/total) + control/total * np.log2(control/total))\n",
    "    return h\n",
    "    \n",
    "\n",
    "def load_p_values(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        p = pickle.load(f)\n",
    "    return p\n",
    "\n",
    "convert_to_percent = np.vectorize(lambda x: ' {:.2f}%'.format(x * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_only = True\n",
    "if primary_only:\n",
    "    diag_dir = \"primary_only\"\n",
    "else:\n",
    "    diag_dir = \"primary_and_secondary\"\n",
    "\n",
    "    \n",
    "with open('../../../data/mf_regarding_diseases/{}/summaries_diagnosis_textHpo_labHpo.obj'.format(diag_dir), 'rb') as f:\n",
    "    summaries_diagnosis_textHpo_labHpo = pickle.load(f)\n",
    "with open('../../../data/mf_regarding_diseases/{}/summaries_diagnosis_textHpo_textHpo.obj'.format(diag_dir), 'rb') as f:\n",
    "    summaries_diagnosis_textHpo_textHpo = pickle.load(f)\n",
    "with open('../../../data/mf_regarding_diseases/{}/summaries_diagnosis_labHpo_labHpo.obj'.format(diag_dir), 'rb') as f:\n",
    "    summaries_diagnosis_labHpo_labHpo = pickle.load(f)\n",
    "summaries = {('textHpo', 'labHpo'): summaries_diagnosis_textHpo_labHpo,\n",
    "             ('textHpo', 'textHpo'): summaries_diagnosis_textHpo_textHpo,\n",
    "            ('labHpo', 'labHpo'): summaries_diagnosis_labHpo_labHpo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map column names to more meaningful name for this context\n",
    "name_dict = {\n",
    "        'X': 'P1', \n",
    "        'Y': 'P2', \n",
    "        'mf_Xz': 'mf_P1_diag',\n",
    "        'mf_Yz': 'mf_P2_diag',\n",
    "        'mf_XY_z': 'mf_P1P2_diag',\n",
    "        'mf_XY_given_z': 'mf_P1P2_given_diag',\n",
    "        'mf_XY_omit_z': 'mf_P1P2_omit_diag',\n",
    "        'p_mf_XY_z': 'p_mf_P1P2_diag',\n",
    "        'p_mf_XY_given_z': 'p_mf_P1P2_given_diag',\n",
    "        'p_mf_XY_omit_z': 'p_mf_P1P2_omit_diag',\n",
    "        'mf_Xz': 'mf_P1_diag', \n",
    "        'mf_Yz': 'mf_P2_diag',  \n",
    "        'p_mf_Xz': 'p_mf_P1_diag', \n",
    "        'p_mf_Yz': 'p_mf_P2_diag'   \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output rendered csv and html files for selected diseases and phenotype sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the following variables to analyze\n",
    "disease = '493'\n",
    "p1_source = 'textHpo'\n",
    "p2_source = 'labHpo'\n",
    "\n",
    "\n",
    "# calculate mutual information from summary statistics\n",
    "summaries_p1_p2 = summaries.get((p1_source, p2_source))\n",
    "summary_statistics = summaries_p1_p2[disease]\n",
    "mf_diagnosis_phenotypes = mf.MutualInfoXYz(summary_statistics)\n",
    "\n",
    "# calculate p value on Helix for disease of interest: input-summary statistics; output-a dictionary of p values\n",
    "# TODO: get script \n",
    "\n",
    "# load p values\n",
    "p_values_file_name = 'p_value_{}_{}_{}_{}.obj'.format(p1_source, p2_source, disease, diag_dir)\n",
    "p_values_file_path = os.path.join('../../../data/mf_regarding_diseases/', diag_dir, disease, p_values_file_name)\n",
    "p_values = load_p_values(p_values_file_path)\n",
    "\n",
    "df_mf_Xz, df_mf_Yz, df_mf_XY_z = mf_dataframes(mf_diagnosis_phenotypes, **p_values)\n",
    "\n",
    "df_mf_XY_z_filtered = filter_df(df_mf_Xz, df_mf_Yz, df_mf_XY_z)\n",
    "\n",
    "# rename column names for this context using the dictionary defined above\n",
    "df_mf_Xz = df_mf_Xz.rename(columns=name_dict, errors='ignore') \n",
    "df_mf_Yz = df_mf_Yz.rename(columns=name_dict, errors='ignore') \n",
    "df_mf_XY_z_filtered = df_mf_XY_z_filtered.rename(columns=name_dict, errors='ignore')\n",
    "\n",
    "# label HPO term ids with their names\n",
    "df_mf_Xz['P1_label'] = [hpo_term_map.get(termid) for termid in df_mf_Xz.P1]\n",
    "df_mf_Yz['P2_label'] = [hpo_term_map.get(termid) for termid in df_mf_Yz.P2]\n",
    "df_mf_XY_z_filtered['P1_label'] = [hpo_term_map.get(termid) for termid in df_mf_XY_z_filtered.P1]\n",
    "df_mf_XY_z_filtered['P2_label'] = [hpo_term_map.get(termid) for termid in df_mf_XY_z_filtered.P2]\n",
    "\n",
    "# sort by desired columns\n",
    "df_mf_Xz = df_mf_Xz.sort_values(by='mf_P1_diag', ascending=False).reset_index(drop=True)\n",
    "df_mf_Yz = df_mf_Yz.sort_values(by='mf_P2_diag', ascending=False).reset_index(drop=True)\n",
    "df_mf_XY_z_filtered = df_mf_XY_z_filtered.sort_values(by='synergy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# output to csv file\n",
    "# just save df_mf_XY_z_filtered as it contains data in df_mf_Xz and df_mf_Yz\n",
    "csv_file_name = 'df_synergy_{}_{}_{}.csv'.format(p1_source, p2_source, disease)\n",
    "csv_file_path = os.path.join('../../../data/mf_regarding_diseases/', diag_dir, csv_file_name)\n",
    "df_mf_XY_z_filtered.head(n = 20)\n",
    "df_mf_XY_z_filtered.to_csv(csv_file_path)\n",
    "\n",
    "# render html\n",
    "\n",
    "\n",
    "# output cytoscape files\n",
    "percentile = 0.01\n",
    "n = math.floor(len(df_mf_XY_z_filtered) * percentile)\n",
    "\n",
    "df_4_cytoscape = df_mf_XY_z_filtered \\\n",
    "    .assign(P1 = lambda x: 'Rad_' + x['P1']) \\\n",
    "    .assign(P2 = lambda x: 'Lab_' + x['P2']) \\\n",
    "    .head(n = n)\n",
    "\n",
    "\n",
    "# edges\n",
    "edges_path = os.path.join('../../../data/mf_regarding_diseases', diag_dir, 'cytoscape', 'edges_{}_{}_{}.csv'.format(p1_source, p2_source, disease))\n",
    "df_4_cytoscape.loc[:, ['P1', 'P2', 'synergy', 'p_synergy']].to_csv(edges_path)\n",
    "\n",
    "# nodes\n",
    "nodes = pd.DataFrame(data={'term_id': np.concatenate([df_4_cytoscape.P1, df_4_cytoscape.P2]), \n",
    "                           'term_label': np.concatenate([df_4_cytoscape.P1_label, df_4_cytoscape.P2_label]),\n",
    "                          'type': np.repeat(['Rad', 'Lab'], len(df_4_cytoscape))}).drop_duplicates()\n",
    "nodes_path = os.path.join('../../../data/mf_regarding_diseases', diag_dir, 'cytoscape', 'nodes_textHpo_labHpo_{}.csv'.format( disease))\n",
    "nodes.to_csv(nodes_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
